warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z35__device_stub__tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, i32, i32, i32, i32) -> ()
    return
  }
  func.func private @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c16_i32 = arith.constant 16 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %c15_i32 = arith.constant 15 : i32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = arith.index_cast %arg5 : i32 to index
    %2 = arith.index_cast %arg6 : i32 to index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %3 = gpu.block_id  x
    %4 = arith.index_cast %3 : index to i32
    %5 = gpu.block_id  y
    %6 = arith.index_cast %5 : index to i32
    %7 = gpu.block_id  z
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.muli %8, %arg4 : i32
    %10 = arith.muli %9, %arg6 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = gpu.thread_id  x
    %13 = arith.index_cast %12 : index to i32
    %14 = gpu.thread_id  y
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %6, %c16_i32 : i32
    %17 = arith.addi %16, %15 : i32
    %18 = arith.index_cast %17 : i32 to index
    %19 = arith.muli %17, %arg6 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = arith.muli %4, %c16_i32 : i32
    %22 = arith.addi %21, %13 : i32
    %23 = arith.index_cast %22 : i32 to index
    %24 = arith.index_cast %22 : i32 to index
    %25 = arith.addi %arg5, %c15_i32 : i32
    %26 = arith.divsi %25, %c16_i32 : i32
    %27 = arith.index_cast %26 : i32 to index
    %28 = arith.cmpi slt, %8, %arg3 : i32
    %29 = arith.muli %8, %arg4 : i32
    %30 = arith.muli %29, %arg5 : i32
    %31 = arith.muli %17, %arg5 : i32
    %32 = arith.addi %30, %31 : i32
    %33 = arith.index_cast %32 : i32 to index
    %34 = arith.cmpi slt, %22, %arg6 : i32
    %35 = affine.for %arg7 = 0 to %27 iter_args(%arg8 = %cst) -> (f32) {
      %41 = affine.if affine_set<(d0)[s0, s1, s2, s3] : (-s0 + s1 - 1 >= 0, d0 * -16 - s2 + s3 - 1 >= 0)>(%arg7)[%18, %0, %12, %1] -> i1 {
        affine.yield %28 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %41 {
        %44 = affine.load %arg0[%arg7 * 16 + symbol(%33) + symbol(%12)] : memref<?xf32>
        affine.store %44, %alloca_0[symbol(%14), symbol(%12)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%14), symbol(%12)] : memref<16x16xf32, 5>
      }
      %42 = affine.if affine_set<(d0)[s0, s1] : (d0 * -16 - s0 + s1 - 1 >= 0)>(%arg7)[%14, %1] -> i1 {
        affine.yield %34 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %42 {
        %44 = affine.load %arg1[(%arg7 * 16 + symbol(%14)) * symbol(%2) + symbol(%23)] : memref<?xf32>
        affine.store %44, %alloca[symbol(%14), symbol(%12)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca[symbol(%14), symbol(%12)] : memref<16x16xf32, 5>
      }
      nvvm.barrier0
      %43 = affine.for %arg9 = 0 to 16 iter_args(%arg10 = %arg8) -> (f32) {
        %44 = affine.load %alloca_0[symbol(%14), %arg9] : memref<16x16xf32, 5>
        %45 = affine.load %alloca[%arg9, symbol(%12)] : memref<16x16xf32, 5>
        %46 = arith.mulf %44, %45 : f32
        %47 = arith.addf %arg10, %46 : f32
        affine.yield %47 : f32
      }
      nvvm.barrier0
      affine.yield %43 : f32
    }
    %36 = arith.cmpi slt, %17, %arg4 : i32
    %37 = arith.cmpi slt, %22, %arg6 : i32
    %38 = arith.cmpi slt, %8, %arg3 : i32
    %39 = arith.andi %37, %38 : i1
    %40 = arith.andi %36, %39 : i1
    scf.if %40 {
      affine.store %35, %arg2[symbol(%11) + symbol(%20) + symbol(%24)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c15_i32 = arith.constant 15 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c16_i32 = arith.constant 16 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %2 = arith.index_cast %arg5 : i32 to index
    %3 = arith.index_cast %arg6 : i32 to index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %4 = gpu.block_id  x
    %5 = arith.index_cast %4 : index to i32
    %6 = gpu.block_id  y
    %7 = arith.index_cast %6 : index to i32
    %8 = gpu.block_id  z
    %9 = arith.index_cast %8 : index to i32
    %10 = arith.muli %9, %arg4 : i32
    %11 = arith.muli %10, %arg6 : i32
    %12 = arith.index_cast %11 : i32 to index
    %13 = gpu.thread_id  x
    %14 = arith.index_cast %13 : index to i32
    %15 = gpu.thread_id  y
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.muli %7, %c16_i32 : i32
    %18 = arith.addi %17, %16 : i32
    %19 = arith.index_cast %18 : i32 to index
    %20 = arith.muli %18, %arg6 : i32
    %21 = arith.index_cast %20 : i32 to index
    %22 = arith.muli %5, %c16_i32 : i32
    %23 = arith.addi %22, %14 : i32
    %24 = arith.index_cast %23 : i32 to index
    %25 = arith.addi %arg5, %c15_i32 : i32
    %26 = arith.divsi %25, %c16_i32 : i32
    %27 = arith.index_cast %26 : i32 to index
    %28 = arith.cmpi slt, %9, %arg3 : i32
    %29 = arith.muli %10, %arg5 : i32
    %30 = arith.muli %18, %arg5 : i32
    %31 = arith.addi %29, %30 : i32
    %32 = arith.index_cast %31 : i32 to index
    %33 = arith.cmpi slt, %23, %arg6 : i32
    %34 = affine.for %arg7 = 0 to %27 iter_args(%arg8 = %cst) -> (f32) {
      affine.if affine_set<(d0)[s0, s1, s2, s3, s4, s5] : (-s0 + s1 - 1 >= 0, s2 - s3 - 1 >= 0, d0 * -16 - s4 + s5 - 1 >= 0)>(%arg7)[%8, %0, %1, %19, %13, %2] {
        %39 = affine.load %arg0[%arg7 * 16 + symbol(%32) + symbol(%13)] : memref<?xf32>
        affine.store %39, %alloca_0[symbol(%15), symbol(%13)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%15), symbol(%13)] : memref<16x16xf32, 5>
      }
      affine.if affine_set<(d0)[s0, s1, s2, s3] : (d0 * -16 - s0 + s1 - 1 >= 0, -s2 + s3 - 1 >= 0)>(%arg7)[%15, %2, %24, %3] {
        %39 = affine.load %arg1[(%arg7 * 16 + symbol(%15)) * symbol(%3) + symbol(%24)] : memref<?xf32>
        affine.store %39, %alloca[symbol(%15), symbol(%13)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca[symbol(%15), symbol(%13)] : memref<16x16xf32, 5>
      }
      nvvm.barrier0
      %38 = affine.for %arg9 = 0 to 16 iter_args(%arg10 = %arg8) -> (f32) {
        %39 = affine.load %alloca_0[symbol(%15), %arg9] : memref<16x16xf32, 5>
        %40 = affine.load %alloca[%arg9, symbol(%13)] : memref<16x16xf32, 5>
        %41 = arith.mulf %39, %40 : f32
        %42 = arith.addf %arg10, %41 : f32
        affine.yield %42 : f32
      }
      nvvm.barrier0
      affine.yield %38 : f32
    }
    %35 = arith.cmpi slt, %18, %arg4 : i32
    %36 = arith.andi %33, %28 : i1
    %37 = arith.andi %35, %36 : i1
    scf.if %37 {
      affine.store %34, %arg2[symbol(%12) + symbol(%21) + symbol(%24)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c16 = arith.constant 16 : index
    %c-16 = arith.constant -16 : index
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c15_i32 = arith.constant 15 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c16_i32 = arith.constant 16 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %2 = arith.index_cast %arg5 : i32 to index
    %3 = arith.index_cast %arg6 : i32 to index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %4 = gpu.block_id  x
    %5 = arith.index_cast %4 : index to i32
    %6 = gpu.block_id  y
    %7 = arith.index_cast %6 : index to i32
    %8 = gpu.block_id  z
    %9 = arith.index_cast %8 : index to i32
    %10 = arith.muli %9, %arg4 : i32
    %11 = arith.muli %10, %arg6 : i32
    %12 = arith.index_cast %11 : i32 to index
    %13 = gpu.thread_id  x
    %14 = arith.index_cast %13 : index to i32
    %15 = gpu.thread_id  y
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.muli %7, %c16_i32 : i32
    %18 = arith.addi %17, %16 : i32
    %19 = arith.index_cast %18 : i32 to index
    %20 = arith.muli %18, %arg6 : i32
    %21 = arith.index_cast %20 : i32 to index
    %22 = arith.muli %5, %c16_i32 : i32
    %23 = arith.addi %22, %14 : i32
    %24 = arith.index_cast %23 : i32 to index
    %25 = arith.addi %arg5, %c15_i32 : i32
    %26 = arith.divsi %25, %c16_i32 : i32
    %27 = arith.index_cast %26 : i32 to index
    %28 = arith.cmpi slt, %9, %arg3 : i32
    %29 = arith.muli %10, %arg5 : i32
    %30 = arith.muli %18, %arg5 : i32
    %31 = arith.addi %29, %30 : i32
    %32 = arith.index_cast %31 : i32 to index
    %33 = arith.cmpi slt, %23, %arg6 : i32
    %34 = scf.for %arg7 = %c0 to %27 step %c1 iter_args(%arg8 = %cst) -> (f32) {
      %38 = arith.subi %0, %8 : index
      %39 = arith.addi %38, %c-1 : index
      %40 = arith.cmpi sge, %39, %c0 : index
      %41 = arith.subi %1, %19 : index
      %42 = arith.addi %41, %c-1 : index
      %43 = arith.cmpi sge, %42, %c0 : index
      %44 = arith.andi %40, %43 : i1
      %45 = arith.muli %arg7, %c-16 : index
      %46 = arith.subi %45, %13 : index
      %47 = arith.addi %46, %2 : index
      %48 = arith.addi %47, %c-1 : index
      %49 = arith.cmpi sge, %48, %c0 : index
      %50 = arith.andi %44, %49 : i1
      scf.if %50 {
        %60 = arith.muli %arg7, %c16 : index
        %61 = arith.addi %60, %32 : index
        %62 = arith.addi %61, %13 : index
        %63 = memref.load %arg0[%62] : memref<?xf32>
        memref.store %63, %alloca_0[%15, %13] : memref<16x16xf32, 5>
      } else {
        memref.store %cst, %alloca_0[%15, %13] : memref<16x16xf32, 5>
      }
      %51 = arith.subi %45, %15 : index
      %52 = arith.addi %51, %2 : index
      %53 = arith.addi %52, %c-1 : index
      %54 = arith.cmpi sge, %53, %c0 : index
      %55 = arith.subi %3, %24 : index
      %56 = arith.addi %55, %c-1 : index
      %57 = arith.cmpi sge, %56, %c0 : index
      %58 = arith.andi %54, %57 : i1
      scf.if %58 {
        %60 = arith.muli %arg7, %c16 : index
        %61 = arith.addi %60, %15 : index
        %62 = arith.muli %61, %3 : index
        %63 = arith.addi %62, %24 : index
        %64 = memref.load %arg1[%63] : memref<?xf32>
        memref.store %64, %alloca[%15, %13] : memref<16x16xf32, 5>
      } else {
        memref.store %cst, %alloca[%15, %13] : memref<16x16xf32, 5>
      }
      nvvm.barrier0
      %59 = scf.for %arg9 = %c0 to %c16 step %c1 iter_args(%arg10 = %arg8) -> (f32) {
        %60 = memref.load %alloca_0[%15, %arg9] : memref<16x16xf32, 5>
        %61 = memref.load %alloca[%arg9, %13] : memref<16x16xf32, 5>
        %62 = arith.mulf %60, %61 : f32
        %63 = arith.addf %arg10, %62 : f32
        scf.yield %63 : f32
      }
      nvvm.barrier0
      scf.yield %59 : f32
    }
    %35 = arith.cmpi slt, %18, %arg4 : i32
    %36 = arith.andi %33, %28 : i1
    %37 = arith.andi %35, %36 : i1
    scf.if %37 {
      %38 = arith.addi %12, %21 : index
      %39 = arith.addi %38, %24 : index
      memref.store %34, %arg2[%39] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
      %c1_1 = arith.constant 1 : index
      %0 = arith.remui %arg7, %c1_1 : index
      %c1_2 = arith.constant 1 : index
      %1 = arith.divui %arg7, %c1_2 : index
      %c16 = arith.constant 16 : index
      %c-16 = arith.constant -16 : index
      %c-1 = arith.constant -1 : index
      %c1_3 = arith.constant 1 : index
      %c0_4 = arith.constant 0 : index
      %c15_i32 = arith.constant 15 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c16_i32 = arith.constant 16 : i32
      %2 = arith.index_cast %arg3 : i32 to index
      %3 = arith.index_cast %arg4 : i32 to index
      %4 = arith.index_cast %arg5 : i32 to index
      %5 = arith.index_cast %arg6 : i32 to index
      %6 = gpu.block_id  x
      %7 = arith.index_cast %6 : index to i32
      %8 = gpu.block_id  y
      %9 = arith.index_cast %8 : index to i32
      %10 = gpu.block_id  z
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.muli %11, %arg4 : i32
      %13 = arith.muli %12, %arg6 : i32
      %14 = arith.index_cast %13 : i32 to index
      %15 = arith.index_cast %1 : index to i32
      %16 = arith.index_cast %0 : index to i32
      %17 = arith.muli %9, %c16_i32 : i32
      %18 = arith.addi %17, %16 : i32
      %19 = arith.index_cast %18 : i32 to index
      %20 = arith.muli %18, %arg6 : i32
      %21 = arith.index_cast %20 : i32 to index
      %22 = arith.muli %7, %c16_i32 : i32
      %23 = arith.addi %22, %15 : i32
      %24 = arith.index_cast %23 : i32 to index
      %25 = arith.addi %arg5, %c15_i32 : i32
      %26 = arith.divsi %25, %c16_i32 : i32
      %27 = arith.index_cast %26 : i32 to index
      %28 = arith.cmpi slt, %11, %arg3 : i32
      %29 = arith.muli %12, %arg5 : i32
      %30 = arith.muli %18, %arg5 : i32
      %31 = arith.addi %29, %30 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.cmpi slt, %23, %arg6 : i32
      %34 = scf.for %arg8 = %c0_4 to %27 step %c1_3 iter_args(%arg9 = %cst) -> (f32) {
        %38 = arith.subi %2, %10 : index
        %39 = arith.addi %38, %c-1 : index
        %40 = arith.cmpi sge, %39, %c0_4 : index
        %41 = arith.subi %3, %19 : index
        %42 = arith.addi %41, %c-1 : index
        %43 = arith.cmpi sge, %42, %c0_4 : index
        %44 = arith.andi %40, %43 : i1
        %45 = arith.muli %arg8, %c-16 : index
        %46 = arith.subi %45, %1 : index
        %47 = arith.addi %46, %4 : index
        %48 = arith.addi %47, %c-1 : index
        %49 = arith.cmpi sge, %48, %c0_4 : index
        %50 = arith.andi %44, %49 : i1
        scf.if %50 {
          %60 = arith.muli %arg8, %c16 : index
          %61 = arith.addi %60, %32 : index
          %62 = arith.addi %61, %1 : index
          %63 = memref.load %arg0[%62] : memref<?xf32>
          memref.store %63, %alloca_0[%0, %1] : memref<16x16xf32, 5>
        } else {
          memref.store %cst, %alloca_0[%0, %1] : memref<16x16xf32, 5>
        }
        %51 = arith.subi %45, %0 : index
        %52 = arith.addi %51, %4 : index
        %53 = arith.addi %52, %c-1 : index
        %54 = arith.cmpi sge, %53, %c0_4 : index
        %55 = arith.subi %5, %24 : index
        %56 = arith.addi %55, %c-1 : index
        %57 = arith.cmpi sge, %56, %c0_4 : index
        %58 = arith.andi %54, %57 : i1
        scf.if %58 {
          %60 = arith.muli %arg8, %c16 : index
          %61 = arith.addi %60, %0 : index
          %62 = arith.muli %61, %5 : index
          %63 = arith.addi %62, %24 : index
          %64 = memref.load %arg1[%63] : memref<?xf32>
          memref.store %64, %alloca[%0, %1] : memref<16x16xf32, 5>
        } else {
          memref.store %cst, %alloca[%0, %1] : memref<16x16xf32, 5>
        }
        "polygeist.barrier"(%arg7) : (index) -> ()
        %59 = scf.for %arg10 = %c0_4 to %c16 step %c1_3 iter_args(%arg11 = %arg9) -> (f32) {
          %60 = memref.load %alloca_0[%0, %arg10] : memref<16x16xf32, 5>
          %61 = memref.load %alloca[%arg10, %1] : memref<16x16xf32, 5>
          %62 = arith.mulf %60, %61 : f32
          %63 = arith.addf %arg11, %62 : f32
          scf.yield %63 : f32
        }
        "polygeist.barrier"(%arg7) : (index) -> ()
        scf.yield %59 : f32
      }
      %35 = arith.cmpi slt, %18, %arg4 : i32
      %36 = arith.andi %33, %28 : i1
      %37 = arith.andi %35, %36 : i1
      scf.if %37 {
        %38 = arith.addi %14, %21 : index
        %39 = arith.addi %38, %24 : index
        memref.store %34, %arg2[%39] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
      %c1_1 = arith.constant 1 : index
      %0 = arith.remui %arg7, %c1_1 : index
      %c1_2 = arith.constant 1 : index
      %1 = arith.divui %arg7, %c1_2 : index
      %c16 = arith.constant 16 : index
      %c-16 = arith.constant -16 : index
      %c-1 = arith.constant -1 : index
      %c1_3 = arith.constant 1 : index
      %c0_4 = arith.constant 0 : index
      %c15_i32 = arith.constant 15 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c16_i32 = arith.constant 16 : i32
      %2 = arith.index_cast %arg3 : i32 to index
      %3 = arith.index_cast %arg4 : i32 to index
      %4 = arith.index_cast %arg5 : i32 to index
      %5 = arith.index_cast %arg6 : i32 to index
      %6 = gpu.block_id  x
      %7 = arith.index_cast %6 : index to i32
      %8 = gpu.block_id  y
      %9 = arith.index_cast %8 : index to i32
      %10 = gpu.block_id  z
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.muli %11, %arg4 : i32
      %13 = arith.muli %12, %arg6 : i32
      %14 = arith.index_cast %13 : i32 to index
      %15 = arith.index_cast %1 : index to i32
      %16 = arith.index_cast %0 : index to i32
      %17 = arith.muli %9, %c16_i32 : i32
      %18 = arith.addi %17, %16 : i32
      %19 = arith.index_cast %18 : i32 to index
      %20 = arith.muli %18, %arg6 : i32
      %21 = arith.index_cast %20 : i32 to index
      %22 = arith.muli %7, %c16_i32 : i32
      %23 = arith.addi %22, %15 : i32
      %24 = arith.index_cast %23 : i32 to index
      %25 = arith.addi %arg5, %c15_i32 : i32
      %26 = arith.divsi %25, %c16_i32 : i32
      %27 = arith.index_cast %26 : i32 to index
      %28 = arith.cmpi slt, %11, %arg3 : i32
      %29 = arith.muli %12, %arg5 : i32
      %30 = arith.muli %18, %arg5 : i32
      %31 = arith.addi %29, %30 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.cmpi slt, %23, %arg6 : i32
      %34 = scf.for %arg8 = %c0_4 to %27 step %c1_3 iter_args(%arg9 = %cst) -> (f32) {
        %38 = arith.subi %2, %10 : index
        %39 = arith.addi %38, %c-1 : index
        %40 = arith.cmpi sge, %39, %c0_4 : index
        %41 = arith.subi %3, %19 : index
        %42 = arith.addi %41, %c-1 : index
        %43 = arith.cmpi sge, %42, %c0_4 : index
        %44 = arith.andi %40, %43 : i1
        %45 = arith.muli %arg8, %c-16 : index
        %46 = arith.subi %45, %1 : index
        %47 = arith.addi %46, %4 : index
        %48 = arith.addi %47, %c-1 : index
        %49 = arith.cmpi sge, %48, %c0_4 : index
        %50 = arith.andi %44, %49 : i1
        scf.if %50 {
          %60 = arith.muli %arg8, %c16 : index
          %61 = arith.addi %60, %32 : index
          %62 = arith.addi %61, %1 : index
          %63 = memref.load %arg0[%62] : memref<?xf32>
          memref.store %63, %alloca_0[%0, %1] : memref<16x16xf32, 5>
        } else {
          memref.store %cst, %alloca_0[%0, %1] : memref<16x16xf32, 5>
        }
        %51 = arith.subi %45, %0 : index
        %52 = arith.addi %51, %4 : index
        %53 = arith.addi %52, %c-1 : index
        %54 = arith.cmpi sge, %53, %c0_4 : index
        %55 = arith.subi %5, %24 : index
        %56 = arith.addi %55, %c-1 : index
        %57 = arith.cmpi sge, %56, %c0_4 : index
        %58 = arith.andi %54, %57 : i1
        scf.if %58 {
          %60 = arith.muli %arg8, %c16 : index
          %61 = arith.addi %60, %0 : index
          %62 = arith.muli %61, %5 : index
          %63 = arith.addi %62, %24 : index
          %64 = memref.load %arg1[%63] : memref<?xf32>
          memref.store %64, %alloca[%0, %1] : memref<16x16xf32, 5>
        } else {
          memref.store %cst, %alloca[%0, %1] : memref<16x16xf32, 5>
        }
        "polygeist.barrier"(%arg7) : (index) -> ()
        %59 = scf.for %arg10 = %c0_4 to %c16 step %c1_3 iter_args(%arg11 = %arg9) -> (f32) {
          %60 = memref.load %alloca_0[%0, %arg10] : memref<16x16xf32, 5>
          %61 = memref.load %alloca[%arg10, %1] : memref<16x16xf32, 5>
          %62 = arith.mulf %60, %61 : f32
          %63 = arith.addf %arg11, %62 : f32
          scf.yield %63 : f32
        }
        "polygeist.barrier"(%arg7) : (index) -> ()
        scf.yield %59 : f32
      }
      %35 = arith.cmpi slt, %18, %arg4 : i32
      %36 = arith.andi %33, %28 : i1
      %37 = arith.andi %35, %36 : i1
      scf.if %37 {
        %38 = arith.addi %14, %21 : index
        %39 = arith.addi %38, %24 : index
        memref.store %34, %arg2[%39] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c16_i32 = arith.constant 16 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c15_i32 = arith.constant 15 : i32
    %c-1 = arith.constant -1 : index
    %c-16 = arith.constant -16 : index
    %c16 = arith.constant 16 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %alloca_1 = memref.alloca() : memref<32xf32>
    scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
      memref.store %cst, %alloca_1[%arg7] : memref<32xf32>
      scf.yield
    }
    %0 = arith.addi %arg5, %c15_i32 : i32
    %1 = arith.divsi %0, %c16_i32 : i32
    %2 = arith.index_cast %1 : i32 to index
    %3 = gpu.block_id  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %4, %c16_i32 : i32
    %6 = gpu.block_id  z
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.muli %7, %arg4 : i32
    %9 = arith.muli %8, %arg5 : i32
    %10 = gpu.block_id  y
    %11 = arith.index_cast %10 : index to i32
    %12 = arith.muli %11, %c16_i32 : i32
    %13 = arith.muli %12, %arg5 : i32
    %14 = arith.addi %9, %13 : i32
    %15 = arith.index_cast %14 : i32 to index
    %16 = arith.index_cast %12 : i32 to index
    %17 = arith.index_cast %arg6 : i32 to index
    %18 = arith.index_cast %arg5 : i32 to index
    %19 = arith.index_cast %arg4 : i32 to index
    %20 = arith.index_cast %arg3 : i32 to index
    %21 = arith.subi %20, %6 : index
    %22 = arith.addi %21, %c-1 : index
    %23 = arith.cmpi sge, %22, %c0 : index
    %24 = arith.subi %19, %16 : index
    %25 = arith.addi %24, %c-1 : index
    %26 = arith.cmpi sge, %25, %c0 : index
    %27 = arith.andi %23, %26 : i1
    scf.for %arg7 = %c0 to %2 step %c1 {
      %44 = arith.muli %arg7, %c-16 : index
      %45 = arith.addi %44, %18 : index
      %46 = arith.addi %45, %c-1 : index
      %47 = arith.cmpi sge, %46, %c0 : index
      %48 = arith.muli %arg7, %c16 : index
      %49 = arith.addi %48, %15 : index
      %50 = arith.muli %arg7, %c16 : index
      %51 = arith.muli %50, %17 : index
      scf.parallel (%arg8) = (%c0) to (%c32) step (%c1) {
        %52 = arith.index_cast %arg8 : index to i32
        %53 = arith.addi %5, %52 : i32
        %54 = arith.index_cast %53 : i32 to index
        %55 = arith.subi %44, %arg8 : index
        %56 = arith.addi %55, %18 : index
        %57 = arith.addi %56, %c-1 : index
        %58 = arith.cmpi sge, %57, %c0 : index
        %59 = arith.andi %27, %58 : i1
        scf.if %59 {
          %64 = arith.addi %49, %arg8 : index
          %65 = memref.load %arg0[%64] : memref<?xf32>
          memref.store %65, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
        } else {
          memref.store %cst, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
        }
        %60 = arith.subi %17, %54 : index
        %61 = arith.addi %60, %c-1 : index
        %62 = arith.cmpi sge, %61, %c0 : index
        %63 = arith.andi %47, %62 : i1
        scf.if %63 {
          %64 = arith.addi %51, %54 : index
          %65 = memref.load %arg1[%64] : memref<?xf32>
          memref.store %65, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
        } else {
          memref.store %cst, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
        }
        scf.yield
      }
      scf.parallel (%arg8) = (%c0) to (%c32) step (%c1) {
        %52 = memref.load %alloca_1[%arg8] : memref<32xf32>
        %53 = scf.for %arg9 = %c0 to %c16 step %c1 iter_args(%arg10 = %52) -> (f32) {
          %54 = memref.load %alloca_0[%c0, %arg9] : memref<16x16xf32, 5>
          %55 = memref.load %alloca[%arg9, %arg8] : memref<16x16xf32, 5>
          %56 = arith.mulf %54, %55 : f32
          %57 = arith.addf %arg10, %56 : f32
          scf.yield %57 : f32
        }
        memref.store %53, %alloca_1[%arg8] : memref<32xf32>
        scf.yield
      }
    }
    %28 = gpu.block_id  z
    %29 = arith.index_cast %28 : index to i32
    %30 = arith.muli %29, %arg4 : i32
    %31 = arith.muli %30, %arg6 : i32
    %32 = arith.index_cast %31 : i32 to index
    %33 = gpu.block_id  y
    %34 = arith.index_cast %33 : index to i32
    %35 = arith.muli %34, %c16_i32 : i32
    %36 = arith.muli %35, %arg6 : i32
    %37 = arith.index_cast %36 : i32 to index
    %38 = gpu.block_id  x
    %39 = arith.index_cast %38 : index to i32
    %40 = arith.muli %39, %c16_i32 : i32
    %41 = arith.cmpi slt, %29, %arg3 : i32
    %42 = arith.cmpi slt, %35, %arg4 : i32
    %43 = arith.addi %32, %37 : index
    scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
      %44 = arith.index_cast %arg7 : index to i32
      %45 = arith.addi %40, %44 : i32
      %46 = arith.index_cast %45 : i32 to index
      %47 = arith.cmpi slt, %45, %arg6 : i32
      %48 = memref.load %alloca_1[%arg7] : memref<32xf32>
      %49 = arith.andi %47, %41 : i1
      %50 = arith.andi %42, %49 : i1
      scf.if %50 {
        %51 = arith.addi %43, %46 : index
        memref.store %48, %arg2[%51] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20tensor_matmul_kernelPKfS0_Pfiiii_0 {
    gpu.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %c16_i32 = arith.constant 16 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c15_i32 = arith.constant 15 : i32
      %c-1 = arith.constant -1 : index
      %c-16 = arith.constant -16 : index
      %c16 = arith.constant 16 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<16x16xf32, 5>
      %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32>
      scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
        memref.store %cst, %alloca_1[%arg7] : memref<32xf32>
        scf.yield
      }
      %0 = arith.addi %arg5, %c15_i32 : i32
      %1 = arith.divsi %0, %c16_i32 : i32
      %2 = arith.index_cast %1 : i32 to index
      %3 = gpu.block_id  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %4, %c16_i32 : i32
      %6 = gpu.block_id  z
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.muli %7, %arg4 : i32
      %9 = arith.muli %8, %arg5 : i32
      %10 = gpu.block_id  y
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.muli %11, %c16_i32 : i32
      %13 = arith.muli %12, %arg5 : i32
      %14 = arith.addi %9, %13 : i32
      %15 = arith.index_cast %14 : i32 to index
      %16 = arith.index_cast %12 : i32 to index
      %17 = arith.index_cast %arg6 : i32 to index
      %18 = arith.index_cast %arg5 : i32 to index
      %19 = arith.index_cast %arg4 : i32 to index
      %20 = arith.index_cast %arg3 : i32 to index
      %21 = arith.subi %20, %6 : index
      %22 = arith.addi %21, %c-1 : index
      %23 = arith.cmpi sge, %22, %c0 : index
      %24 = arith.subi %19, %16 : index
      %25 = arith.addi %24, %c-1 : index
      %26 = arith.cmpi sge, %25, %c0 : index
      %27 = arith.andi %23, %26 : i1
      scf.for %arg7 = %c0 to %2 step %c1 {
        %35 = arith.muli %arg7, %c-16 : index
        %36 = arith.addi %35, %18 : index
        %37 = arith.addi %36, %c-1 : index
        %38 = arith.cmpi sge, %37, %c0 : index
        %39 = arith.muli %arg7, %c16 : index
        %40 = arith.addi %39, %15 : index
        %41 = arith.muli %39, %17 : index
        scf.parallel (%arg8) = (%c0) to (%c32) step (%c1) {
          %42 = arith.index_cast %arg8 : index to i32
          %43 = arith.addi %5, %42 : i32
          %44 = arith.index_cast %43 : i32 to index
          %45 = arith.subi %35, %arg8 : index
          %46 = arith.addi %45, %18 : index
          %47 = arith.addi %46, %c-1 : index
          %48 = arith.cmpi sge, %47, %c0 : index
          %49 = arith.andi %27, %48 : i1
          scf.if %49 {
            %54 = arith.addi %40, %arg8 : index
            %55 = memref.load %arg0[%54] : memref<?xf32>
            memref.store %55, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          }
          %50 = arith.subi %17, %44 : index
          %51 = arith.addi %50, %c-1 : index
          %52 = arith.cmpi sge, %51, %c0 : index
          %53 = arith.andi %38, %52 : i1
          scf.if %53 {
            %54 = arith.addi %41, %44 : index
            %55 = memref.load %arg1[%54] : memref<?xf32>
            memref.store %55, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          }
          scf.yield
        }
        scf.parallel (%arg8) = (%c0) to (%c32) step (%c1) {
          %42 = memref.load %alloca_1[%arg8] : memref<32xf32>
          %43 = scf.for %arg9 = %c0 to %c16 step %c1 iter_args(%arg10 = %42) -> (f32) {
            %44 = memref.load %alloca_0[%c0, %arg9] : memref<16x16xf32, 5>
            %45 = memref.load %alloca[%arg9, %arg8] : memref<16x16xf32, 5>
            %46 = arith.mulf %44, %45 : f32
            %47 = arith.addf %arg10, %46 : f32
            scf.yield %47 : f32
          }
          memref.store %43, %alloca_1[%arg8] : memref<32xf32>
          scf.yield
        }
      }
      %28 = arith.muli %8, %arg6 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.muli %12, %arg6 : i32
      %31 = arith.index_cast %30 : i32 to index
      %32 = arith.cmpi slt, %7, %arg3 : i32
      %33 = arith.cmpi slt, %12, %arg4 : i32
      %34 = arith.addi %29, %31 : index
      scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
        %35 = arith.index_cast %arg7 : index to i32
        %36 = arith.addi %5, %35 : i32
        %37 = arith.index_cast %36 : i32 to index
        %38 = arith.cmpi slt, %36, %arg6 : i32
        %39 = memref.load %alloca_1[%arg7] : memref<32xf32>
        %40 = arith.andi %38, %32 : i1
        %41 = arith.andi %33, %40 : i1
        scf.if %41 {
          %42 = arith.addi %34, %37 : index
          memref.store %39, %arg2[%42] : memref<?xf32>
        }
        scf.yield
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20tensor_matmul_kernelPKfS0_Pfiiii_0 {
    gpu.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %c16_i32 = arith.constant 16 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c15_i32 = arith.constant 15 : i32
      %c-1 = arith.constant -1 : index
      %c-16 = arith.constant -16 : index
      %c16 = arith.constant 16 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<16x16xf32, 5>
      %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32>
      %c1_2 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg7] : memref<32xf32>
      }
      %0 = arith.addi %arg5, %c15_i32 : i32
      %1 = arith.divsi %0, %c16_i32 : i32
      %2 = arith.index_cast %1 : i32 to index
      %3 = gpu.block_id  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %4, %c16_i32 : i32
      %6 = gpu.block_id  z
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.muli %7, %arg4 : i32
      %9 = arith.muli %8, %arg5 : i32
      %10 = gpu.block_id  y
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.muli %11, %c16_i32 : i32
      %13 = arith.muli %12, %arg5 : i32
      %14 = arith.addi %9, %13 : i32
      %15 = arith.index_cast %14 : i32 to index
      %16 = arith.index_cast %12 : i32 to index
      %17 = arith.index_cast %arg6 : i32 to index
      %18 = arith.index_cast %arg5 : i32 to index
      %19 = arith.index_cast %arg4 : i32 to index
      %20 = arith.index_cast %arg3 : i32 to index
      %21 = arith.subi %20, %6 : index
      %22 = arith.addi %21, %c-1 : index
      %23 = arith.cmpi sge, %22, %c0 : index
      %24 = arith.subi %19, %16 : index
      %25 = arith.addi %24, %c-1 : index
      %26 = arith.cmpi sge, %25, %c0 : index
      %27 = arith.andi %23, %26 : i1
      scf.for %arg7 = %c0 to %2 step %c1 {
        %35 = arith.muli %arg7, %c-16 : index
        %36 = arith.addi %35, %18 : index
        %37 = arith.addi %36, %c-1 : index
        %38 = arith.cmpi sge, %37, %c0 : index
        %39 = arith.muli %arg7, %c16 : index
        %40 = arith.addi %39, %15 : index
        %41 = arith.muli %39, %17 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_4 {
          %42 = arith.index_cast %arg8 : index to i32
          %43 = arith.addi %5, %42 : i32
          %44 = arith.index_cast %43 : i32 to index
          %45 = arith.subi %35, %arg8 : index
          %46 = arith.addi %45, %18 : index
          %47 = arith.addi %46, %c-1 : index
          %48 = arith.cmpi sge, %47, %c0 : index
          %49 = arith.andi %27, %48 : i1
          scf.if %49 {
            %54 = arith.addi %40, %arg8 : index
            %55 = memref.load %arg0[%54] : memref<?xf32>
            memref.store %55, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          }
          %50 = arith.subi %17, %44 : index
          %51 = arith.addi %50, %c-1 : index
          %52 = arith.cmpi sge, %51, %c0 : index
          %53 = arith.andi %38, %52 : i1
          scf.if %53 {
            %54 = arith.addi %41, %44 : index
            %55 = memref.load %arg1[%54] : memref<?xf32>
            memref.store %55, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_5 {
          %42 = memref.load %alloca_1[%arg8] : memref<32xf32>
          %43 = scf.for %arg9 = %c0 to %c16 step %c1 iter_args(%arg10 = %42) -> (f32) {
            %44 = memref.load %alloca_0[%c0, %arg9] : memref<16x16xf32, 5>
            %45 = memref.load %alloca[%arg9, %arg8] : memref<16x16xf32, 5>
            %46 = arith.mulf %44, %45 : f32
            %47 = arith.addf %arg10, %46 : f32
            scf.yield %47 : f32
          }
          memref.store %43, %alloca_1[%arg8] : memref<32xf32>
        }
      }
      %28 = arith.muli %8, %arg6 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.muli %12, %arg6 : i32
      %31 = arith.index_cast %30 : i32 to index
      %32 = arith.cmpi slt, %7, %arg3 : i32
      %33 = arith.cmpi slt, %12, %arg4 : i32
      %34 = arith.addi %29, %31 : index
      %c1_3 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_3 {
        %35 = arith.index_cast %arg7 : index to i32
        %36 = arith.addi %5, %35 : i32
        %37 = arith.index_cast %36 : i32 to index
        %38 = arith.cmpi slt, %36, %arg6 : i32
        %39 = memref.load %alloca_1[%arg7] : memref<32xf32>
        %40 = arith.andi %38, %32 : i1
        %41 = arith.andi %33, %40 : i1
        scf.if %41 {
          %42 = arith.addi %34, %37 : index
          memref.store %39, %arg2[%42] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca = memref.alloca() : memref<16x16xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%0 = "npu.alloca"() <{numElems = 256 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca = memref.alloca() : memref<16x16xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20tensor_matmul_kernelPKfS0_Pfiiii_0 {
    gpu.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %c16_i32 = arith.constant 16 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c15_i32 = arith.constant 15 : i32
      %c-1 = arith.constant -1 : index
      %c-16 = arith.constant -16 : index
      %c16 = arith.constant 16 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 256 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<16x16xf32, 5>
      %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32, 5>
      %c1_2 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg7] : memref<32xf32, 5>
      }
      %1 = arith.addi %arg5, %c15_i32 : i32
      %2 = arith.divsi %1, %c16_i32 : i32
      %3 = arith.index_cast %2 : i32 to index
      %4 = gpu.block_id  x
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.muli %5, %c16_i32 : i32
      %7 = gpu.block_id  z
      %8 = arith.index_cast %7 : index to i32
      %9 = arith.muli %8, %arg4 : i32
      %10 = arith.muli %9, %arg5 : i32
      %11 = gpu.block_id  y
      %12 = arith.index_cast %11 : index to i32
      %13 = arith.muli %12, %c16_i32 : i32
      %14 = arith.muli %13, %arg5 : i32
      %15 = arith.addi %10, %14 : i32
      %16 = arith.index_cast %15 : i32 to index
      %17 = arith.index_cast %13 : i32 to index
      %18 = arith.index_cast %arg6 : i32 to index
      %19 = arith.index_cast %arg5 : i32 to index
      %20 = arith.index_cast %arg4 : i32 to index
      %21 = arith.index_cast %arg3 : i32 to index
      %22 = arith.subi %21, %7 : index
      %23 = arith.addi %22, %c-1 : index
      %24 = arith.cmpi sge, %23, %c0 : index
      %25 = arith.subi %20, %17 : index
      %26 = arith.addi %25, %c-1 : index
      %27 = arith.cmpi sge, %26, %c0 : index
      %28 = arith.andi %24, %27 : i1
      scf.for %arg7 = %c0 to %3 step %c1 {
        %36 = arith.muli %arg7, %c-16 : index
        %37 = arith.addi %36, %19 : index
        %38 = arith.addi %37, %c-1 : index
        %39 = arith.cmpi sge, %38, %c0 : index
        %40 = arith.muli %arg7, %c16 : index
        %41 = arith.addi %40, %16 : index
        %42 = arith.muli %40, %18 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_4 {
          %43 = arith.index_cast %arg8 : index to i32
          %44 = arith.addi %6, %43 : i32
          %45 = arith.index_cast %44 : i32 to index
          %46 = arith.subi %36, %arg8 : index
          %47 = arith.addi %46, %19 : index
          %48 = arith.addi %47, %c-1 : index
          %49 = arith.cmpi sge, %48, %c0 : index
          %50 = arith.andi %28, %49 : i1
          scf.if %50 {
            %55 = arith.addi %41, %arg8 : index
            %56 = memref.load %arg0[%55] : memref<?xf32>
            memref.store %56, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          }
          %51 = arith.subi %18, %45 : index
          %52 = arith.addi %51, %c-1 : index
          %53 = arith.cmpi sge, %52, %c0 : index
          %54 = arith.andi %39, %53 : i1
          scf.if %54 {
            %55 = arith.addi %42, %45 : index
            %56 = memref.load %arg1[%55] : memref<?xf32>
            memref.store %56, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_5 {
          %43 = memref.load %alloca_1[%arg8] : memref<32xf32, 5>
          %44 = scf.for %arg9 = %c0 to %c16 step %c1 iter_args(%arg10 = %43) -> (f32) {
            %45 = memref.load %alloca_0[%c0, %arg9] : memref<16x16xf32, 5>
            %46 = memref.load %alloca[%arg9, %arg8] : memref<16x16xf32, 5>
            %47 = arith.mulf %45, %46 : f32
            %48 = arith.addf %arg10, %47 : f32
            scf.yield %48 : f32
          }
          memref.store %44, %alloca_1[%arg8] : memref<32xf32, 5>
        }
      }
      %29 = arith.muli %9, %arg6 : i32
      %30 = arith.index_cast %29 : i32 to index
      %31 = arith.muli %13, %arg6 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.cmpi slt, %8, %arg3 : i32
      %34 = arith.cmpi slt, %13, %arg4 : i32
      %35 = arith.addi %30, %32 : index
      %c1_3 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_3 {
        %36 = arith.index_cast %arg7 : index to i32
        %37 = arith.addi %6, %36 : i32
        %38 = arith.index_cast %37 : i32 to index
        %39 = arith.cmpi slt, %37, %arg6 : i32
        %40 = memref.load %alloca_1[%arg7] : memref<32xf32, 5>
        %41 = arith.andi %39, %33 : i1
        %42 = arith.andi %34, %41 : i1
        scf.if %42 {
          %43 = arith.addi %35, %38 : index
          memref.store %40, %arg2[%43] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_0 = memref.alloca() : memref<16x16xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%1 = "npu.alloca"() <{numElems = 256 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_0 = memref.alloca() : memref<16x16xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20tensor_matmul_kernelPKfS0_Pfiiii_0 {
    gpu.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %c16_i32 = arith.constant 16 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c15_i32 = arith.constant 15 : i32
      %c-1 = arith.constant -1 : index
      %c-16 = arith.constant -16 : index
      %c16 = arith.constant 16 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 256 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<16x16xf32, 5>
      %1 = "npu.alloca"() <{numElems = 256 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32, 5>
      %c1_2 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg7] : memref<32xf32, 5>
      }
      %2 = arith.addi %arg5, %c15_i32 : i32
      %3 = arith.divsi %2, %c16_i32 : i32
      %4 = arith.index_cast %3 : i32 to index
      %5 = gpu.block_id  x
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.muli %6, %c16_i32 : i32
      %8 = gpu.block_id  z
      %9 = arith.index_cast %8 : index to i32
      %10 = arith.muli %9, %arg4 : i32
      %11 = arith.muli %10, %arg5 : i32
      %12 = gpu.block_id  y
      %13 = arith.index_cast %12 : index to i32
      %14 = arith.muli %13, %c16_i32 : i32
      %15 = arith.muli %14, %arg5 : i32
      %16 = arith.addi %11, %15 : i32
      %17 = arith.index_cast %16 : i32 to index
      %18 = arith.index_cast %14 : i32 to index
      %19 = arith.index_cast %arg6 : i32 to index
      %20 = arith.index_cast %arg5 : i32 to index
      %21 = arith.index_cast %arg4 : i32 to index
      %22 = arith.index_cast %arg3 : i32 to index
      %23 = arith.subi %22, %8 : index
      %24 = arith.addi %23, %c-1 : index
      %25 = arith.cmpi sge, %24, %c0 : index
      %26 = arith.subi %21, %18 : index
      %27 = arith.addi %26, %c-1 : index
      %28 = arith.cmpi sge, %27, %c0 : index
      %29 = arith.andi %25, %28 : i1
      scf.for %arg7 = %c0 to %4 step %c1 {
        %37 = arith.muli %arg7, %c-16 : index
        %38 = arith.addi %37, %20 : index
        %39 = arith.addi %38, %c-1 : index
        %40 = arith.cmpi sge, %39, %c0 : index
        %41 = arith.muli %arg7, %c16 : index
        %42 = arith.addi %41, %17 : index
        %43 = arith.muli %41, %19 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_4 {
          %44 = arith.index_cast %arg8 : index to i32
          %45 = arith.addi %7, %44 : i32
          %46 = arith.index_cast %45 : i32 to index
          %47 = arith.subi %37, %arg8 : index
          %48 = arith.addi %47, %20 : index
          %49 = arith.addi %48, %c-1 : index
          %50 = arith.cmpi sge, %49, %c0 : index
          %51 = arith.andi %29, %50 : i1
          scf.if %51 {
            %56 = arith.addi %42, %arg8 : index
            %57 = memref.load %arg0[%56] : memref<?xf32>
            memref.store %57, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          }
          %52 = arith.subi %19, %46 : index
          %53 = arith.addi %52, %c-1 : index
          %54 = arith.cmpi sge, %53, %c0 : index
          %55 = arith.andi %40, %54 : i1
          scf.if %55 {
            %56 = arith.addi %43, %46 : index
            %57 = memref.load %arg1[%56] : memref<?xf32>
            memref.store %57, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_5 {
          %44 = memref.load %alloca_1[%arg8] : memref<32xf32, 5>
          %45 = scf.for %arg9 = %c0 to %c16 step %c1 iter_args(%arg10 = %44) -> (f32) {
            %46 = memref.load %alloca_0[%c0, %arg9] : memref<16x16xf32, 5>
            %47 = memref.load %alloca[%arg9, %arg8] : memref<16x16xf32, 5>
            %48 = arith.mulf %46, %47 : f32
            %49 = arith.addf %arg10, %48 : f32
            scf.yield %49 : f32
          }
          memref.store %45, %alloca_1[%arg8] : memref<32xf32, 5>
        }
      }
      %30 = arith.muli %10, %arg6 : i32
      %31 = arith.index_cast %30 : i32 to index
      %32 = arith.muli %14, %arg6 : i32
      %33 = arith.index_cast %32 : i32 to index
      %34 = arith.cmpi slt, %9, %arg3 : i32
      %35 = arith.cmpi slt, %14, %arg4 : i32
      %36 = arith.addi %31, %33 : index
      %c1_3 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_3 {
        %37 = arith.index_cast %arg7 : index to i32
        %38 = arith.addi %7, %37 : i32
        %39 = arith.index_cast %38 : i32 to index
        %40 = arith.cmpi slt, %38, %arg6 : i32
        %41 = memref.load %alloca_1[%arg7] : memref<32xf32, 5>
        %42 = arith.andi %40, %34 : i1
        %43 = arith.andi %35, %42 : i1
        scf.if %43 {
          %44 = arith.addi %36, %39 : index
          memref.store %41, %arg2[%44] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_1 = memref.alloca() : memref<32xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_1 = memref.alloca() : memref<32xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20tensor_matmul_kernelPKfS0_Pfiiii_0 {
    gpu.func @_Z20tensor_matmul_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %c16_i32 = arith.constant 16 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c15_i32 = arith.constant 15 : i32
      %c-1 = arith.constant -1 : index
      %c-16 = arith.constant -16 : index
      %c16 = arith.constant 16 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 256 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<16x16xf32, 5>
      %1 = "npu.alloca"() <{numElems = 256 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
      %2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_1 = memref.alloca() : memref<32xf32, 5>
      %c1_2 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg7] : memref<32xf32, 5>
      }
      %3 = arith.addi %arg5, %c15_i32 : i32
      %4 = arith.divsi %3, %c16_i32 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = gpu.block_id  x
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.muli %7, %c16_i32 : i32
      %9 = gpu.block_id  z
      %10 = arith.index_cast %9 : index to i32
      %11 = arith.muli %10, %arg4 : i32
      %12 = arith.muli %11, %arg5 : i32
      %13 = gpu.block_id  y
      %14 = arith.index_cast %13 : index to i32
      %15 = arith.muli %14, %c16_i32 : i32
      %16 = arith.muli %15, %arg5 : i32
      %17 = arith.addi %12, %16 : i32
      %18 = arith.index_cast %17 : i32 to index
      %19 = arith.index_cast %15 : i32 to index
      %20 = arith.index_cast %arg6 : i32 to index
      %21 = arith.index_cast %arg5 : i32 to index
      %22 = arith.index_cast %arg4 : i32 to index
      %23 = arith.index_cast %arg3 : i32 to index
      %24 = arith.subi %23, %9 : index
      %25 = arith.addi %24, %c-1 : index
      %26 = arith.cmpi sge, %25, %c0 : index
      %27 = arith.subi %22, %19 : index
      %28 = arith.addi %27, %c-1 : index
      %29 = arith.cmpi sge, %28, %c0 : index
      %30 = arith.andi %26, %29 : i1
      scf.for %arg7 = %c0 to %5 step %c1 {
        %38 = arith.muli %arg7, %c-16 : index
        %39 = arith.addi %38, %21 : index
        %40 = arith.addi %39, %c-1 : index
        %41 = arith.cmpi sge, %40, %c0 : index
        %42 = arith.muli %arg7, %c16 : index
        %43 = arith.addi %42, %18 : index
        %44 = arith.muli %42, %20 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_4 {
          %45 = arith.index_cast %arg8 : index to i32
          %46 = arith.addi %8, %45 : i32
          %47 = arith.index_cast %46 : i32 to index
          %48 = arith.subi %38, %arg8 : index
          %49 = arith.addi %48, %21 : index
          %50 = arith.addi %49, %c-1 : index
          %51 = arith.cmpi sge, %50, %c0 : index
          %52 = arith.andi %30, %51 : i1
          scf.if %52 {
            %57 = arith.addi %43, %arg8 : index
            %58 = memref.load %arg0[%57] : memref<?xf32>
            memref.store %58, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg8] : memref<16x16xf32, 5>
          }
          %53 = arith.subi %20, %47 : index
          %54 = arith.addi %53, %c-1 : index
          %55 = arith.cmpi sge, %54, %c0 : index
          %56 = arith.andi %41, %55 : i1
          scf.if %56 {
            %57 = arith.addi %44, %47 : index
            %58 = memref.load %arg1[%57] : memref<?xf32>
            memref.store %58, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg8] : memref<16x16xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg8 = %c0 to %c32 step %c1_5 {
          %45 = memref.load %alloca_1[%arg8] : memref<32xf32, 5>
          %46 = scf.for %arg9 = %c0 to %c16 step %c1 iter_args(%arg10 = %45) -> (f32) {
            %47 = memref.load %alloca_0[%c0, %arg9] : memref<16x16xf32, 5>
            %48 = memref.load %alloca[%arg9, %arg8] : memref<16x16xf32, 5>
            %49 = arith.mulf %47, %48 : f32
            %50 = arith.addf %arg10, %49 : f32
            scf.yield %50 : f32
          }
          memref.store %46, %alloca_1[%arg8] : memref<32xf32, 5>
        }
      }
      %31 = arith.muli %11, %arg6 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.muli %15, %arg6 : i32
      %34 = arith.index_cast %33 : i32 to index
      %35 = arith.cmpi slt, %10, %arg3 : i32
      %36 = arith.cmpi slt, %15, %arg4 : i32
      %37 = arith.addi %32, %34 : index
      %c1_3 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_3 {
        %38 = arith.index_cast %arg7 : index to i32
        %39 = arith.addi %8, %38 : i32
        %40 = arith.index_cast %39 : i32 to index
        %41 = arith.cmpi slt, %39, %arg6 : i32
        %42 = memref.load %alloca_1[%arg7] : memref<32xf32, 5>
        %43 = arith.andi %41, %35 : i1
        %44 = arith.andi %36, %43 : i1
        scf.if %44 {
          %45 = arith.addi %37, %40 : index
          memref.store %42, %arg2[%45] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] GPUBlockIdToNPULowering: process op: 

%6 = gpu.block_id  x
[ict-debug] GPUBlockIdToNPULowering: process op: 

%10 = gpu.block_id  z
cgeist: /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/VectorToNPU.cpp:772: virtual mlir::LogicalResult GPUBlockIdToNPULowering::matchAndRewrite(mlir::gpu::BlockIdOp, mlir::OpConversionPattern<mlir::gpu::BlockIdOp>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `blockIdOp.getDimension() == gpu::Dimension::y' failed.
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist --function=* -cuda-lower -output-intermediate-gpu -scal-rep=0 -raise-scf-to-affine --cuda-gpu-arch=sm_70 -parallel-licm=1 -gpu-kernel-structure-mode=block_thread_noops --enable-buffer-elim=0 -O2 -I /CUDA2BANG/cuda2bang/polygeist/mlir-build/projects/openmp/runtime/src/ -resource-dir=/CUDA2BANG/cuda2bang/polygeist/mlir-build/lib/clang/18/ -I /CUDA2BANG/cuda2bang/polygeist/mlir-build/projects/openmp/runtime/src/ -I /usr/local/cuda/include/ -use-original-gpu-block-size --emit-npu=distribute.mincut -use-my-pass -bang-dump-file=/CUDA2BANG/Cambricon_NaiveProfiling/cuda_ops_test/Ascend_kernels/gen_bang_results/level_1_prlblem_10_sample_0_3D_tensor_matrix_multiplication.mlu /CUDA2BANG/Cambricon_NaiveProfiling/cuda_ops_test/Ascend_kernels/gen_cuda_kernels/level_1_prlblem_10_sample_0_3D_tensor_matrix_multiplication.cu -o level_1_prlblem_10_sample_0_3D_tensor_matrix_multiplication.o
 #0 0x00005561355ecbcf llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x3391bcf)
 #1 0x00005561355ea3b4 SignalHandler(int) Signals.cpp:0:0
 #2 0x00007f1b59507420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #3 0x00007f1b58e8c00b raise /build/glibc-SzIz7B/glibc-2.31/signal/../sysdeps/unix/sysv/linux/raise.c:51:1
 #4 0x00007f1b58e6b859 abort /build/glibc-SzIz7B/glibc-2.31/stdlib/abort.c:81:7
 #5 0x00007f1b58e6b729 get_sysdep_segment_value /build/glibc-SzIz7B/glibc-2.31/intl/loadmsgcat.c:509:8
 #6 0x00007f1b58e6b729 _nl_load_domain /build/glibc-SzIz7B/glibc-2.31/intl/loadmsgcat.c:970:34
 #7 0x00007f1b58e7cfd6 (/lib/x86_64-linux-gnu/libc.so.6+0x33fd6)
 #8 0x00005561362d140c GPUBlockIdToNPULowering::matchAndRewrite(mlir::gpu::BlockIdOp, mlir::gpu::BlockIdOpAdaptor, mlir::ConversionPatternRewriter&) const /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/VectorToNPU.cpp:773:88
 #9 0x00005561362f050b mlir::OpConversionPattern<mlir::gpu::BlockIdOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/Transforms/DialectConversion.h:536:77
#10 0x00005561364640a9 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x42090a9)
#11 0x0000556139665572 mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<mlir::LogicalResult (mlir::Pattern const&)>) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x740a572)
#12 0x00005561364726bb (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#13 0x0000556136472b9f (anonymous namespace)::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>, llvm::function_ref<void (mlir::Diagnostic&)>) DialectConversion.cpp:0:0
#14 0x00005561364733b4 mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, llvm::DenseSet<mlir::Operation*, llvm::DenseMapInfo<mlir::Operation*, void>>*) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x42183b4)
#15 0x00005561362bda32 (anonymous namespace)::ConvertPolygeistToNPUPass::runOnOperation()::'lambda1'(mlir::gpu::GPUFuncOp)::operator()(mlir::gpu::GPUFuncOp) const /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/ConvertPolygeistToNPU.cpp:1396:17
#16 0x00005561362c0a71 _ZZN4mlir6detail4walkILNS_9WalkOrderE1ENS_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS_3gpu9GPUFuncOpEE1_S7_vEENSt9enable_ifIXaantsrSt11disjunctionIJSt7is_sameIT2_PNS_9OperationEESB_ISC_PNS_6RegionEESB_ISC_PNS_5BlockEEEE5valuesrSB_IT3_vE5valueESN_E4typeESE_OT1_ENKUlSE_E_clESE_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:337:20
#17 0x00005561362c459a _ZN4llvm12function_refIFvPN4mlir9OperationEEE11callback_fnIZNS1_6detail4walkILNS1_9WalkOrderE1ENS1_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS1_3gpu9GPUFuncOpEE1_SE_vEENSt9enable_ifIXaantsrSt11disjunctionIJSt7is_sameIT2_S3_ESI_ISJ_PNS1_6RegionEESI_ISJ_PNS1_5BlockEEEE5valuesrSI_IT3_vE5valueESS_E4typeES3_OT1_EUlS3_E_EEvlS3_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:46:40
#18 0x0000556132d838bf llvm::function_ref<void (mlir::Operation*)>::operator()(mlir::Operation*) const /CUDA2BANG/cuda2bang/polygeist/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:68:62
#19 0x0000556132d6927a void mlir::detail::walk<mlir::ForwardIterator>(mlir::Operation*, llvm::function_ref<void (mlir::Operation*)>, mlir::WalkOrder) /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:188:1
#20 0x0000556132d6922c void mlir::detail::walk<mlir::ForwardIterator>(mlir::Operation*, llvm::function_ref<void (mlir::Operation*)>, mlir::WalkOrder) /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:180:7
#21 0x0000556132d6922c void mlir::detail::walk<mlir::ForwardIterator>(mlir::Operation*, llvm::function_ref<void (mlir::Operation*)>, mlir::WalkOrder) /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:180:7
#22 0x00005561362c0ae6 _ZN4mlir6detail4walkILNS_9WalkOrderE1ENS_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS_3gpu9GPUFuncOpEE1_S7_vEENSt9enable_ifIXaantsrSt11disjunctionIJSt7is_sameIT2_PNS_9OperationEESB_ISC_PNS_6RegionEESB_ISC_PNS_5BlockEEEE5valuesrSB_IT3_vE5valueESN_E4typeESE_OT1_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:342:38
#23 0x00005561362bf380 _ZN4mlir9Operation4walkILNS_9WalkOrderE1ENS_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS_3gpu9GPUFuncOpEE1_vEENSt9enable_ifIXeqsrN4llvm15function_traitsINSt5decayIT1_E4typeEXsrSt8is_classISF_E5valueEEE8num_argsLi1EET2_E4typeEOSD_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Operation.h:777:75
#24 0x00005561362bde6b (anonymous namespace)::ConvertPolygeistToNPUPass::runOnOperation() /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/ConvertPolygeistToNPU.cpp:1407:16
#25 0x0000556136443d21 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x41e8d21)
#26 0x00005561364442a1 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x41e92a1)
#27 0x0000556136444e1e mlir::PassManager::run(mlir::Operation*) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x41e9e1e)
#28 0x0000556132cbac5a main /CUDA2BANG/cuda2bang/polygeist/tools/cgeist/driver.cc:1039:0
#29 0x00007f1b58e6d083 __libc_start_main /build/glibc-SzIz7B/glibc-2.31/csu/../csu/libc-start.c:342:3
#30 0x0000556132c8984e _start (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0xa2e84e)
