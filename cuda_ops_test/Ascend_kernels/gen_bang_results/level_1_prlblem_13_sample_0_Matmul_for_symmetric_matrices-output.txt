warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z38__device_stub__symmetric_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z23symmetric_matmul_kernelPKfS0_Pfi(%arg0, %arg1, %arg2, %arg3) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, i32) -> ()
    return
  }
  func.func private @_Z23symmetric_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32_i32 = arith.constant 32 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = gpu.thread_id  x
    %6 = arith.index_cast %5 : index to i32
    %7 = arith.cmpi slt, %6, %c32_i32 : i32
    %8 = gpu.thread_id  y
    %9 = arith.index_cast %8 : index to i32
    %10 = arith.cmpi slt, %9, %c32_i32 : i32
    %11 = arith.muli %arg3, %c32_i32 : i32
    %12 = arith.muli %11, %4 : i32
    %13 = arith.addi %12, %arg3 : i32
    %14 = arith.index_cast %13 : i32 to index
    %15 = arith.index_cast %12 : i32 to index
    %16 = arith.index_cast %12 : i32 to index
    %17 = arith.muli %arg3, %9 : i32
    %18 = arith.index_cast %17 : i32 to index
    %19 = arith.index_cast %17 : i32 to index
    %20 = arith.index_cast %17 : i32 to index
    %21 = arith.muli %arg3, %arg3 : i32
    %22 = arith.index_cast %21 : i32 to index
    %23 = arith.andi %10, %7 : i1
    %24 = affine.for %arg4 = %15 to %14 step 32 iter_args(%arg5 = %cst) -> (f32) {
      %34 = affine.if affine_set<(d0)[s0, s1, s2, s3, s4] : (-d0 - s0 + s1 - s2 - s3 + s4 - 1 >= 0)>(%arg4)[%16, %15, %18, %5, %22] -> i1 {
        affine.yield %23 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %34 {
        %36 = affine.load %arg0[%arg4 + symbol(%16) - symbol(%15) + symbol(%19) + symbol(%5)] : memref<?xf32>
        affine.store %36, %alloca_0[symbol(%8), symbol(%5)] : memref<32x32xf32, 5>
        %37 = affine.load %arg1[((%arg4 - symbol(%15)) floordiv 32) * (symbol(%0) * 32) + symbol(%1) * 32 + symbol(%20) + symbol(%5)] : memref<?xf32>
        affine.store %37, %alloca[symbol(%8), symbol(%5)] : memref<32x32xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%8), symbol(%5)] : memref<32x32xf32, 5>
        affine.store %cst, %alloca[symbol(%8), symbol(%5)] : memref<32x32xf32, 5>
      }
      nvvm.barrier0
      %35 = affine.for %arg6 = 0 to 32 iter_args(%arg7 = %arg5) -> (f32) {
        %36 = affine.load %alloca_0[symbol(%8), %arg6] : memref<32x32xf32, 5>
        %37 = affine.load %alloca[%arg6, symbol(%5)] : memref<32x32xf32, 5>
        %38 = arith.mulf %36, %37 : f32
        %39 = arith.addf %arg7, %38 : f32
        affine.yield %39 : f32
      }
      nvvm.barrier0
      affine.yield %35 : f32
    }
    %25 = arith.muli %4, %c32_i32 : i32
    %26 = arith.addi %25, %9 : i32
    %27 = arith.muli %26, %arg3 : i32
    %28 = arith.index_cast %27 : i32 to index
    %29 = arith.cmpi slt, %26, %arg3 : i32
    %30 = arith.muli %2, %c32_i32 : i32
    %31 = arith.addi %30, %6 : i32
    %32 = arith.cmpi slt, %31, %arg3 : i32
    %33 = arith.andi %29, %32 : i1
    scf.if %33 {
      affine.store %24, %arg2[symbol(%28) + symbol(%1) * 32 + symbol(%5)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z23symmetric_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c32_i32 = arith.constant 32 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = gpu.thread_id  x
    %6 = arith.index_cast %5 : index to i32
    %7 = gpu.thread_id  y
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.muli %arg3, %c32_i32 : i32
    %10 = arith.muli %9, %4 : i32
    %11 = arith.addi %10, %arg3 : i32
    %12 = arith.index_cast %11 : i32 to index
    %13 = arith.index_cast %10 : i32 to index
    %14 = arith.muli %arg3, %8 : i32
    %15 = arith.index_cast %14 : i32 to index
    %16 = arith.muli %arg3, %arg3 : i32
    %17 = arith.index_cast %16 : i32 to index
    %18 = arith.muli %0, %c32 : index
    %19 = arith.muli %1, %c32 : index
    %20 = arith.addi %19, %15 : index
    %21 = arith.addi %20, %5 : index
    %22 = affine.for %arg4 = %13 to %12 step 32 iter_args(%arg5 = %cst) -> (f32) {
      affine.if affine_set<(d0)[s0, s1, s2, s3] : (-d0 - s0 - s1 + s2 - 1 >= 0, -s3 + 31 >= 0, -s1 + 31 >= 0)>(%arg4)[%15, %5, %17, %7] {
        %33 = affine.load %arg0[%arg4 + symbol(%15) + symbol(%5)] : memref<?xf32>
        affine.store %33, %alloca_0[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
        %34 = arith.subi %arg4, %13 : index
        %35 = arith.cmpi slt, %34, %c0 : index
        %36 = arith.subi %c-1, %34 : index
        %37 = arith.select %35, %36, %34 : index
        %38 = arith.divsi %37, %c32 : index
        %39 = arith.subi %c-1, %38 : index
        %40 = arith.select %35, %39, %38 : index
        %41 = arith.muli %40, %18 : index
        %42 = arith.addi %41, %21 : index
        %43 = memref.load %arg1[%42] : memref<?xf32>
        affine.store %43, %alloca[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
        affine.store %cst, %alloca[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      }
      nvvm.barrier0
      %32 = affine.for %arg6 = 0 to 32 iter_args(%arg7 = %arg5) -> (f32) {
        %33 = affine.load %alloca_0[symbol(%7), %arg6] : memref<32x32xf32, 5>
        %34 = affine.load %alloca[%arg6, symbol(%5)] : memref<32x32xf32, 5>
        %35 = arith.mulf %33, %34 : f32
        %36 = arith.addf %arg7, %35 : f32
        affine.yield %36 : f32
      }
      nvvm.barrier0
      affine.yield %32 : f32
    }
    %23 = arith.muli %4, %c32_i32 : i32
    %24 = arith.addi %23, %8 : i32
    %25 = arith.muli %24, %arg3 : i32
    %26 = arith.index_cast %25 : i32 to index
    %27 = arith.cmpi slt, %24, %arg3 : i32
    %28 = arith.muli %2, %c32_i32 : i32
    %29 = arith.addi %28, %6 : i32
    %30 = arith.cmpi slt, %29, %arg3 : i32
    %31 = arith.andi %27, %30 : i1
    scf.if %31 {
      affine.store %22, %arg2[symbol(%26) + symbol(%1) * 32 + symbol(%5)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z23symmetric_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1 = arith.constant 1 : index
    %c31 = arith.constant 31 : index
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c32 = arith.constant 32 : index
    %c32_i32 = arith.constant 32 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = gpu.thread_id  x
    %6 = arith.index_cast %5 : index to i32
    %7 = gpu.thread_id  y
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.muli %arg3, %c32_i32 : i32
    %10 = arith.muli %9, %4 : i32
    %11 = arith.addi %10, %arg3 : i32
    %12 = arith.index_cast %11 : i32 to index
    %13 = arith.index_cast %10 : i32 to index
    %14 = arith.muli %arg3, %8 : i32
    %15 = arith.index_cast %14 : i32 to index
    %16 = arith.muli %arg3, %arg3 : i32
    %17 = arith.index_cast %16 : i32 to index
    %18 = arith.muli %0, %c32 : index
    %19 = arith.muli %1, %c32 : index
    %20 = arith.addi %19, %15 : index
    %21 = arith.addi %20, %5 : index
    %22 = scf.for %arg4 = %13 to %12 step %c32 iter_args(%arg5 = %cst) -> (f32) {
      %32 = arith.muli %arg4, %c-1 : index
      %33 = arith.subi %32, %15 : index
      %34 = arith.subi %33, %5 : index
      %35 = arith.addi %34, %17 : index
      %36 = arith.addi %35, %c-1 : index
      %37 = arith.cmpi sge, %36, %c0 : index
      %38 = arith.subi %c31, %7 : index
      %39 = arith.cmpi sge, %38, %c0 : index
      %40 = arith.andi %37, %39 : i1
      %41 = arith.subi %c31, %5 : index
      %42 = arith.cmpi sge, %41, %c0 : index
      %43 = arith.andi %40, %42 : i1
      scf.if %43 {
        %45 = arith.addi %arg4, %15 : index
        %46 = arith.addi %45, %5 : index
        %47 = memref.load %arg0[%46] : memref<?xf32>
        memref.store %47, %alloca_0[%7, %5] : memref<32x32xf32, 5>
        %48 = arith.subi %arg4, %13 : index
        %49 = arith.cmpi slt, %48, %c0 : index
        %50 = arith.subi %c-1, %48 : index
        %51 = arith.select %49, %50, %48 : index
        %52 = arith.divsi %51, %c32 : index
        %53 = arith.subi %c-1, %52 : index
        %54 = arith.select %49, %53, %52 : index
        %55 = arith.muli %54, %18 : index
        %56 = arith.addi %55, %21 : index
        %57 = memref.load %arg1[%56] : memref<?xf32>
        memref.store %57, %alloca[%7, %5] : memref<32x32xf32, 5>
      } else {
        memref.store %cst, %alloca_0[%7, %5] : memref<32x32xf32, 5>
        memref.store %cst, %alloca[%7, %5] : memref<32x32xf32, 5>
      }
      nvvm.barrier0
      %44 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %arg5) -> (f32) {
        %45 = memref.load %alloca_0[%7, %arg6] : memref<32x32xf32, 5>
        %46 = memref.load %alloca[%arg6, %5] : memref<32x32xf32, 5>
        %47 = arith.mulf %45, %46 : f32
        %48 = arith.addf %arg7, %47 : f32
        scf.yield %48 : f32
      }
      nvvm.barrier0
      scf.yield %44 : f32
    }
    %23 = arith.muli %4, %c32_i32 : i32
    %24 = arith.addi %23, %8 : i32
    %25 = arith.muli %24, %arg3 : i32
    %26 = arith.index_cast %25 : i32 to index
    %27 = arith.cmpi slt, %24, %arg3 : i32
    %28 = arith.muli %2, %c32_i32 : i32
    %29 = arith.addi %28, %6 : i32
    %30 = arith.cmpi slt, %29, %arg3 : i32
    %31 = arith.andi %27, %30 : i1
    scf.if %31 {
      %32 = arith.addi %26, %19 : index
      %33 = arith.addi %32, %5 : index
      memref.store %22, %arg2[%33] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-error] WrapAndReplaceBarrierPass::runOnOperation(): gpuThreadIdOp.getDimension() != gpu::Dimension::x

