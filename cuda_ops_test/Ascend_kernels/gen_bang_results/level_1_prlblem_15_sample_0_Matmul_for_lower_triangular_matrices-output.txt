warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z45__device_stub__lower_triangular_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z30lower_triangular_matmul_kernelPKfS0_Pfi(%arg0, %arg1, %arg2, %arg3) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, i32) -> ()
    return
  }
  func.func private @_Z30lower_triangular_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = gpu.block_id  y
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  y
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  y
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.muli %8, %arg3 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %8 : i32 to index
    %12 = arith.muli %8, %arg3 : i32
    %13 = arith.index_cast %12 : i32 to index
    %14 = gpu.block_id  x
    %15 = arith.index_cast %14 : index to i32
    %16 = gpu.block_dim  x
    %17 = arith.index_cast %16 : index to i32
    %18 = arith.muli %15, %17 : i32
    %19 = gpu.thread_id  x
    %20 = arith.index_cast %19 : index to i32
    %21 = arith.addi %18, %20 : i32
    %22 = arith.index_cast %21 : i32 to index
    %23 = arith.index_cast %21 : i32 to index
    %24 = arith.index_cast %21 : i32 to index
    %25 = arith.index_cast %21 : i32 to index
    %26 = arith.cmpi slt, %8, %arg3 : i32
    %27 = arith.cmpi slt, %21, %arg3 : i32
    %28 = arith.cmpi sge, %8, %21 : i32
    %29 = arith.andi %27, %28 : i1
    %30 = arith.andi %26, %29 : i1
    scf.if %30 {
      %31 = affine.for %arg4 = %25 to affine_map<()[s0] -> (s0 + 1)>()[%11] iter_args(%arg5 = %cst) -> (f32) {
        %32 = affine.load %arg0[%arg4 + symbol(%10) + symbol(%24) - symbol(%22)] : memref<?xf32>
        %33 = affine.load %arg1[(%arg4 + symbol(%24) - symbol(%23)) * symbol(%0) + symbol(%23)] : memref<?xf32>
        %34 = arith.mulf %32, %33 : f32
        %35 = arith.addf %arg5, %34 : f32
        affine.yield %35 : f32
      }
      affine.store %31, %arg2[symbol(%13) + symbol(%25)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z30lower_triangular_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = gpu.block_id  y
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  y
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  y
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.muli %8, %arg3 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %8 : i32 to index
    %12 = gpu.block_id  x
    %13 = arith.index_cast %12 : index to i32
    %14 = gpu.block_dim  x
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %13, %15 : i32
    %17 = gpu.thread_id  x
    %18 = arith.index_cast %17 : index to i32
    %19 = arith.addi %16, %18 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = arith.cmpi slt, %8, %arg3 : i32
    %22 = arith.cmpi slt, %19, %arg3 : i32
    %23 = arith.cmpi sge, %8, %19 : i32
    %24 = arith.andi %22, %23 : i1
    %25 = arith.andi %21, %24 : i1
    scf.if %25 {
      %26 = affine.for %arg4 = %20 to affine_map<()[s0] -> (s0 + 1)>()[%11] iter_args(%arg5 = %cst) -> (f32) {
        %27 = affine.load %arg0[%arg4 + symbol(%10)] : memref<?xf32>
        %28 = affine.load %arg1[%arg4 * symbol(%0) + symbol(%20)] : memref<?xf32>
        %29 = arith.mulf %27, %28 : f32
        %30 = arith.addf %arg5, %29 : f32
        affine.yield %30 : f32
      }
      affine.store %26, %arg2[symbol(%10) + symbol(%20)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z30lower_triangular_matmul_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = gpu.block_id  y
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  y
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  y
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.muli %8, %arg3 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %8 : i32 to index
    %12 = gpu.block_id  x
    %13 = arith.index_cast %12 : index to i32
    %14 = gpu.block_dim  x
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %13, %15 : i32
    %17 = gpu.thread_id  x
    %18 = arith.index_cast %17 : index to i32
    %19 = arith.addi %16, %18 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = arith.cmpi slt, %8, %arg3 : i32
    %22 = arith.cmpi slt, %19, %arg3 : i32
    %23 = arith.cmpi sge, %8, %19 : i32
    %24 = arith.andi %22, %23 : i1
    %25 = arith.andi %21, %24 : i1
    scf.if %25 {
      %26 = arith.addi %11, %c1 : index
      %27 = scf.for %arg4 = %20 to %26 step %c1 iter_args(%arg5 = %cst) -> (f32) {
        %29 = arith.addi %arg4, %10 : index
        %30 = memref.load %arg0[%29] : memref<?xf32>
        %31 = arith.muli %arg4, %0 : index
        %32 = arith.addi %31, %20 : index
        %33 = memref.load %arg1[%32] : memref<?xf32>
        %34 = arith.mulf %30, %33 : f32
        %35 = arith.addf %arg5, %34 : f32
        scf.yield %35 : f32
      }
      %28 = arith.addi %10, %20 : index
      memref.store %27, %arg2[%28] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-error] WrapAndReplaceBarrierPass::runOnOperation(): gpuThreadIdOp.getDimension() != gpu::Dimension::x

