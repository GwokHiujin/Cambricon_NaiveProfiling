warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z28__device_stub__matmul_kernelPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z13matmul_kernelPKfS0_Pfiii(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, i32, i32, i32) -> ()
    return
  }
  func.func private @_Z13matmul_kernelPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c16_i32 = arith.constant 16 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %c15_i32 = arith.constant 15 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %2 = gpu.block_id  y
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %3, %c16_i32 : i32
    %5 = gpu.thread_id  y
    %6 = arith.index_cast %5 : index to i32
    %7 = arith.addi %4, %6 : i32
    %8 = arith.index_cast %7 : i32 to index
    %9 = arith.muli %7, %arg4 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = gpu.block_id  x
    %12 = arith.index_cast %11 : index to i32
    %13 = arith.muli %12, %c16_i32 : i32
    %14 = gpu.thread_id  x
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.addi %13, %15 : i32
    %17 = arith.index_cast %16 : i32 to index
    %18 = arith.index_cast %16 : i32 to index
    %19 = arith.addi %arg5, %c15_i32 : i32
    %20 = arith.divsi %19, %c16_i32 : i32
    %21 = arith.index_cast %20 : i32 to index
    %22 = gpu.thread_id  y
    %23 = gpu.thread_id  x
    %24 = gpu.thread_id  x
    %25 = arith.index_cast %24 : index to i32
    %26 = gpu.thread_id  y
    %27 = gpu.thread_id  x
    %28 = arith.muli %7, %arg5 : i32
    %29 = arith.index_cast %28 : i32 to index
    %30 = gpu.thread_id  y
    %31 = gpu.thread_id  x
    %32 = gpu.thread_id  y
    %33 = arith.index_cast %32 : index to i32
    %34 = gpu.thread_id  y
    %35 = gpu.thread_id  x
    %36 = gpu.thread_id  y
    %37 = gpu.thread_id  x
    %38 = affine.for %arg6 = 0 to %21 iter_args(%arg7 = %cst) -> (f32) {
      %42 = arith.index_cast %arg6 : index to i32
      %43 = affine.if affine_set<()[s0, s1] : (-s0 + s1 - 1 >= 0)>()[%8, %0] -> i1 {
        %46 = arith.muli %42, %c16_i32 : i32
        %47 = arith.addi %46, %25 : i32
        %48 = arith.cmpi ult, %47, %arg5 : i32
        affine.yield %48 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %43 {
        %46 = affine.load %arg0[%arg6 * 16 + symbol(%29) + symbol(%27)] : memref<?xf32>
        affine.store %46, %alloca_0[symbol(%26), symbol(%27)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%30), symbol(%31)] : memref<16x16xf32, 5>
      }
      %44 = affine.if affine_set<()[s0, s1] : (-s0 + s1 - 1 >= 0)>()[%17, %1] -> i1 {
        %46 = arith.muli %42, %c16_i32 : i32
        %47 = arith.addi %46, %33 : i32
        %48 = arith.cmpi ult, %47, %arg5 : i32
        affine.yield %48 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %44 {
        %46 = affine.load %arg1[(%arg6 * 16 + symbol(%34)) * symbol(%1) + symbol(%17)] : memref<?xf32>
        affine.store %46, %alloca[symbol(%34), symbol(%35)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca[symbol(%36), symbol(%37)] : memref<16x16xf32, 5>
      }
      nvvm.barrier0
      %45 = affine.for %arg8 = 0 to 16 iter_args(%arg9 = %arg7) -> (f32) {
        %46 = affine.load %alloca_0[symbol(%22), %arg8] : memref<16x16xf32, 5>
        %47 = affine.load %alloca[%arg8, symbol(%23)] : memref<16x16xf32, 5>
        %48 = arith.mulf %46, %47 : f32
        %49 = arith.addf %arg9, %48 : f32
        affine.yield %49 : f32
      }
      nvvm.barrier0
      affine.yield %45 : f32
    }
    %39 = arith.cmpi slt, %7, %arg3 : i32
    %40 = arith.cmpi slt, %16, %arg4 : i32
    %41 = arith.andi %39, %40 : i1
    scf.if %41 {
      affine.store %38, %arg2[symbol(%10) + symbol(%18)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z13matmul_kernelPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c16_i32 = arith.constant 16 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %c15_i32 = arith.constant 15 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %2 = gpu.block_id  y
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %3, %c16_i32 : i32
    %5 = gpu.thread_id  y
    %6 = arith.index_cast %5 : index to i32
    %7 = arith.addi %4, %6 : i32
    %8 = arith.index_cast %7 : i32 to index
    %9 = arith.muli %7, %arg4 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = gpu.block_id  x
    %12 = arith.index_cast %11 : index to i32
    %13 = arith.muli %12, %c16_i32 : i32
    %14 = gpu.thread_id  x
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.addi %13, %15 : i32
    %17 = arith.index_cast %16 : i32 to index
    %18 = arith.addi %arg5, %c15_i32 : i32
    %19 = arith.divsi %18, %c16_i32 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = arith.muli %7, %arg5 : i32
    %22 = arith.index_cast %21 : i32 to index
    %23 = affine.for %arg6 = 0 to %20 iter_args(%arg7 = %cst) -> (f32) {
      %27 = arith.index_cast %arg6 : index to i32
      %28 = affine.if affine_set<()[s0, s1] : (s0 - s1 - 1 >= 0)>()[%0, %8] -> i1 {
        %31 = arith.muli %27, %c16_i32 : i32
        %32 = arith.addi %31, %15 : i32
        %33 = arith.cmpi ult, %32, %arg5 : i32
        affine.yield %33 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %28 {
        %31 = affine.load %arg0[%arg6 * 16 + symbol(%22) + symbol(%14)] : memref<?xf32>
        affine.store %31, %alloca_0[symbol(%5), symbol(%14)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%5), symbol(%14)] : memref<16x16xf32, 5>
      }
      %29 = affine.if affine_set<()[s0, s1] : (s0 - s1 - 1 >= 0)>()[%1, %17] -> i1 {
        %31 = arith.muli %27, %c16_i32 : i32
        %32 = arith.addi %31, %6 : i32
        %33 = arith.cmpi ult, %32, %arg5 : i32
        affine.yield %33 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %29 {
        %31 = affine.load %arg1[(%arg6 * 16 + symbol(%5)) * symbol(%1) + symbol(%17)] : memref<?xf32>
        affine.store %31, %alloca[symbol(%5), symbol(%14)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca[symbol(%5), symbol(%14)] : memref<16x16xf32, 5>
      }
      nvvm.barrier0
      %30 = affine.for %arg8 = 0 to 16 iter_args(%arg9 = %arg7) -> (f32) {
        %31 = affine.load %alloca_0[symbol(%5), %arg8] : memref<16x16xf32, 5>
        %32 = affine.load %alloca[%arg8, symbol(%14)] : memref<16x16xf32, 5>
        %33 = arith.mulf %31, %32 : f32
        %34 = arith.addf %arg9, %33 : f32
        affine.yield %34 : f32
      }
      nvvm.barrier0
      affine.yield %30 : f32
    }
    %24 = arith.cmpi slt, %7, %arg3 : i32
    %25 = arith.cmpi slt, %16, %arg4 : i32
    %26 = arith.andi %24, %25 : i1
    scf.if %26 {
      affine.store %23, %arg2[symbol(%10) + symbol(%17)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z13matmul_kernelPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c16 = arith.constant 16 : index
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c16_i32 = arith.constant 16 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %c15_i32 = arith.constant 15 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %alloca = memref.alloca() : memref<16x16xf32, 5>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %2 = gpu.block_id  y
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %3, %c16_i32 : i32
    %5 = gpu.thread_id  y
    %6 = arith.index_cast %5 : index to i32
    %7 = arith.addi %4, %6 : i32
    %8 = arith.index_cast %7 : i32 to index
    %9 = arith.muli %7, %arg4 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = gpu.block_id  x
    %12 = arith.index_cast %11 : index to i32
    %13 = arith.muli %12, %c16_i32 : i32
    %14 = gpu.thread_id  x
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.addi %13, %15 : i32
    %17 = arith.index_cast %16 : i32 to index
    %18 = arith.addi %arg5, %c15_i32 : i32
    %19 = arith.divsi %18, %c16_i32 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = arith.muli %7, %arg5 : i32
    %22 = arith.index_cast %21 : i32 to index
    %23 = scf.for %arg6 = %c0 to %20 step %c1 iter_args(%arg7 = %cst) -> (f32) {
      %27 = arith.index_cast %arg6 : index to i32
      %28 = arith.subi %0, %8 : index
      %29 = arith.addi %28, %c-1 : index
      %30 = arith.cmpi sge, %29, %c0 : index
      %31 = scf.if %30 -> (i1) {
        %37 = arith.muli %27, %c16_i32 : i32
        %38 = arith.addi %37, %15 : i32
        %39 = arith.cmpi ult, %38, %arg5 : i32
        scf.yield %39 : i1
      } else {
        scf.yield %false : i1
      }
      scf.if %31 {
        %37 = arith.muli %arg6, %c16 : index
        %38 = arith.addi %37, %22 : index
        %39 = arith.addi %38, %14 : index
        %40 = memref.load %arg0[%39] : memref<?xf32>
        memref.store %40, %alloca_0[%5, %14] : memref<16x16xf32, 5>
      } else {
        memref.store %cst, %alloca_0[%5, %14] : memref<16x16xf32, 5>
      }
      %32 = arith.subi %1, %17 : index
      %33 = arith.addi %32, %c-1 : index
      %34 = arith.cmpi sge, %33, %c0 : index
      %35 = scf.if %34 -> (i1) {
        %37 = arith.muli %27, %c16_i32 : i32
        %38 = arith.addi %37, %6 : i32
        %39 = arith.cmpi ult, %38, %arg5 : i32
        scf.yield %39 : i1
      } else {
        scf.yield %false : i1
      }
      scf.if %35 {
        %37 = arith.muli %arg6, %c16 : index
        %38 = arith.addi %37, %5 : index
        %39 = arith.muli %38, %1 : index
        %40 = arith.addi %39, %17 : index
        %41 = memref.load %arg1[%40] : memref<?xf32>
        memref.store %41, %alloca[%5, %14] : memref<16x16xf32, 5>
      } else {
        memref.store %cst, %alloca[%5, %14] : memref<16x16xf32, 5>
      }
      nvvm.barrier0
      %36 = scf.for %arg8 = %c0 to %c16 step %c1 iter_args(%arg9 = %arg7) -> (f32) {
        %37 = memref.load %alloca_0[%5, %arg8] : memref<16x16xf32, 5>
        %38 = memref.load %alloca[%arg8, %14] : memref<16x16xf32, 5>
        %39 = arith.mulf %37, %38 : f32
        %40 = arith.addf %arg9, %39 : f32
        scf.yield %40 : f32
      }
      nvvm.barrier0
      scf.yield %36 : f32
    }
    %24 = arith.cmpi slt, %7, %arg3 : i32
    %25 = arith.cmpi slt, %16, %arg4 : i32
    %26 = arith.andi %24, %25 : i1
    scf.if %26 {
      %27 = arith.addi %10, %17 : index
      memref.store %23, %arg2[%27] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-error] WrapAndReplaceBarrierPass::runOnOperation(): gpuThreadIdOp.getDimension() != gpu::Dimension::x

