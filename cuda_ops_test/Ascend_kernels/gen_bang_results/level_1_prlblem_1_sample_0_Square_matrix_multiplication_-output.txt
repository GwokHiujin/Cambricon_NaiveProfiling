warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z37__device_stub__matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0, %arg1, %arg2, %arg3) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, i32) -> ()
    return
  }
  func.func private @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32_i32 = arith.constant 32 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %c31_i32 = arith.constant 31 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = gpu.thread_id  x
    %6 = arith.index_cast %5 : index to i32
    %7 = gpu.thread_id  y
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.muli %4, %c32_i32 : i32
    %10 = arith.addi %9, %8 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = arith.muli %10, %arg3 : i32
    %13 = arith.index_cast %12 : i32 to index
    %14 = arith.muli %2, %c32_i32 : i32
    %15 = arith.addi %14, %6 : i32
    %16 = arith.index_cast %15 : i32 to index
    %17 = arith.index_cast %15 : i32 to index
    %18 = arith.addi %arg3, %c31_i32 : i32
    %19 = arith.divsi %18, %c32_i32 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = arith.muli %10, %arg3 : i32
    %22 = arith.index_cast %21 : i32 to index
    %23 = affine.for %arg4 = 0 to %20 iter_args(%arg5 = %cst) -> (f32) {
      %27 = arith.index_cast %arg4 : index to i32
      %28 = affine.if affine_set<()[s0, s1] : (-s0 + s1 - 1 >= 0)>()[%11, %0] -> i1 {
        %31 = arith.muli %27, %c32_i32 : i32
        %32 = arith.addi %31, %6 : i32
        %33 = arith.cmpi slt, %32, %arg3 : i32
        affine.yield %33 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %28 {
        %31 = affine.load %arg0[%arg4 * 32 + symbol(%22) + symbol(%5)] : memref<?xf32>
        affine.store %31, %alloca_0[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      }
      %29 = affine.if affine_set<()[s0, s1] : (-s0 + s1 - 1 >= 0)>()[%16, %0] -> i1 {
        %31 = arith.muli %27, %c32_i32 : i32
        %32 = arith.addi %31, %8 : i32
        %33 = arith.cmpi slt, %32, %arg3 : i32
        affine.yield %33 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %29 {
        %31 = affine.load %arg1[(%arg4 * 32 + symbol(%7)) * symbol(%0) + symbol(%16)] : memref<?xf32>
        affine.store %31, %alloca[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      } else {
        affine.store %cst, %alloca[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      }
      nvvm.barrier0
      %30 = affine.for %arg6 = 0 to 32 iter_args(%arg7 = %arg5) -> (f32) {
        %31 = affine.load %alloca_0[symbol(%7), %arg6] : memref<32x32xf32, 5>
        %32 = affine.load %alloca[%arg6, symbol(%5)] : memref<32x32xf32, 5>
        %33 = arith.mulf %31, %32 : f32
        %34 = arith.addf %arg7, %33 : f32
        affine.yield %34 : f32
      }
      nvvm.barrier0
      affine.yield %30 : f32
    }
    %24 = arith.cmpi slt, %10, %arg3 : i32
    %25 = arith.cmpi slt, %15, %arg3 : i32
    %26 = arith.andi %24, %25 : i1
    scf.if %26 {
      affine.store %23, %arg2[symbol(%13) + symbol(%17)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32_i32 = arith.constant 32 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %c31_i32 = arith.constant 31 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = gpu.thread_id  x
    %6 = arith.index_cast %5 : index to i32
    %7 = gpu.thread_id  y
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.muli %4, %c32_i32 : i32
    %10 = arith.addi %9, %8 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = arith.muli %10, %arg3 : i32
    %13 = arith.index_cast %12 : i32 to index
    %14 = arith.muli %2, %c32_i32 : i32
    %15 = arith.addi %14, %6 : i32
    %16 = arith.index_cast %15 : i32 to index
    %17 = arith.addi %arg3, %c31_i32 : i32
    %18 = arith.divsi %17, %c32_i32 : i32
    %19 = arith.index_cast %18 : i32 to index
    %20 = affine.for %arg4 = 0 to %19 iter_args(%arg5 = %cst) -> (f32) {
      %24 = arith.index_cast %arg4 : index to i32
      %25 = affine.if affine_set<()[s0, s1] : (s0 - s1 - 1 >= 0)>()[%0, %11] -> i1 {
        %28 = arith.muli %24, %c32_i32 : i32
        %29 = arith.addi %28, %6 : i32
        %30 = arith.cmpi slt, %29, %arg3 : i32
        affine.yield %30 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %25 {
        %28 = affine.load %arg0[%arg4 * 32 + symbol(%13) + symbol(%5)] : memref<?xf32>
        affine.store %28, %alloca_0[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      }
      %26 = affine.if affine_set<()[s0, s1] : (s0 - s1 - 1 >= 0)>()[%0, %16] -> i1 {
        %28 = arith.muli %24, %c32_i32 : i32
        %29 = arith.addi %28, %8 : i32
        %30 = arith.cmpi slt, %29, %arg3 : i32
        affine.yield %30 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %26 {
        %28 = affine.load %arg1[(%arg4 * 32 + symbol(%7)) * symbol(%0) + symbol(%16)] : memref<?xf32>
        affine.store %28, %alloca[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      } else {
        affine.store %cst, %alloca[symbol(%7), symbol(%5)] : memref<32x32xf32, 5>
      }
      nvvm.barrier0
      %27 = affine.for %arg6 = 0 to 32 iter_args(%arg7 = %arg5) -> (f32) {
        %28 = affine.load %alloca_0[symbol(%7), %arg6] : memref<32x32xf32, 5>
        %29 = affine.load %alloca[%arg6, symbol(%5)] : memref<32x32xf32, 5>
        %30 = arith.mulf %28, %29 : f32
        %31 = arith.addf %arg7, %30 : f32
        affine.yield %31 : f32
      }
      nvvm.barrier0
      affine.yield %27 : f32
    }
    %21 = arith.cmpi slt, %10, %arg3 : i32
    %22 = arith.cmpi slt, %15, %arg3 : i32
    %23 = arith.andi %21, %22 : i1
    scf.if %23 {
      affine.store %20, %arg2[symbol(%13) + symbol(%16)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32 = arith.constant 32 : index
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c32_i32 = arith.constant 32 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %false = arith.constant false
    %c31_i32 = arith.constant 31 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = gpu.thread_id  x
    %6 = arith.index_cast %5 : index to i32
    %7 = gpu.thread_id  y
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.muli %4, %c32_i32 : i32
    %10 = arith.addi %9, %8 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = arith.muli %10, %arg3 : i32
    %13 = arith.index_cast %12 : i32 to index
    %14 = arith.muli %2, %c32_i32 : i32
    %15 = arith.addi %14, %6 : i32
    %16 = arith.index_cast %15 : i32 to index
    %17 = arith.addi %arg3, %c31_i32 : i32
    %18 = arith.divsi %17, %c32_i32 : i32
    %19 = arith.index_cast %18 : i32 to index
    %20 = scf.for %arg4 = %c0 to %19 step %c1 iter_args(%arg5 = %cst) -> (f32) {
      %24 = arith.index_cast %arg4 : index to i32
      %25 = arith.subi %0, %11 : index
      %26 = arith.addi %25, %c-1 : index
      %27 = arith.cmpi sge, %26, %c0 : index
      %28 = scf.if %27 -> (i1) {
        %34 = arith.muli %24, %c32_i32 : i32
        %35 = arith.addi %34, %6 : i32
        %36 = arith.cmpi slt, %35, %arg3 : i32
        scf.yield %36 : i1
      } else {
        scf.yield %false : i1
      }
      scf.if %28 {
        %34 = arith.muli %arg4, %c32 : index
        %35 = arith.addi %34, %13 : index
        %36 = arith.addi %35, %5 : index
        %37 = memref.load %arg0[%36] : memref<?xf32>
        memref.store %37, %alloca_0[%7, %5] : memref<32x32xf32, 5>
      } else {
        memref.store %cst, %alloca_0[%7, %5] : memref<32x32xf32, 5>
      }
      %29 = arith.subi %0, %16 : index
      %30 = arith.addi %29, %c-1 : index
      %31 = arith.cmpi sge, %30, %c0 : index
      %32 = scf.if %31 -> (i1) {
        %34 = arith.muli %24, %c32_i32 : i32
        %35 = arith.addi %34, %8 : i32
        %36 = arith.cmpi slt, %35, %arg3 : i32
        scf.yield %36 : i1
      } else {
        scf.yield %false : i1
      }
      scf.if %32 {
        %34 = arith.muli %arg4, %c32 : index
        %35 = arith.addi %34, %7 : index
        %36 = arith.muli %35, %0 : index
        %37 = arith.addi %36, %16 : index
        %38 = memref.load %arg1[%37] : memref<?xf32>
        memref.store %38, %alloca[%7, %5] : memref<32x32xf32, 5>
      } else {
        memref.store %cst, %alloca[%7, %5] : memref<32x32xf32, 5>
      }
      nvvm.barrier0
      %33 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %arg5) -> (f32) {
        %34 = memref.load %alloca_0[%7, %arg6] : memref<32x32xf32, 5>
        %35 = memref.load %alloca[%arg6, %5] : memref<32x32xf32, 5>
        %36 = arith.mulf %34, %35 : f32
        %37 = arith.addf %arg7, %36 : f32
        scf.yield %37 : f32
      }
      nvvm.barrier0
      scf.yield %33 : f32
    }
    %21 = arith.cmpi slt, %10, %arg3 : i32
    %22 = arith.cmpi slt, %15, %arg3 : i32
    %23 = arith.andi %21, %22 : i1
    scf.if %23 {
      %24 = arith.addi %13, %16 : index
      memref.store %20, %arg2[%24] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %c1_1 = arith.constant 1 : index
      %0 = arith.remui %arg4, %c1_1 : index
      %c1_2 = arith.constant 1 : index
      %1 = arith.divui %arg4, %c1_2 : index
      %c32_3 = arith.constant 32 : index
      %c-1 = arith.constant -1 : index
      %c1_4 = arith.constant 1 : index
      %c0_5 = arith.constant 0 : index
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %false = arith.constant false
      %c31_i32 = arith.constant 31 : i32
      %2 = arith.index_cast %arg3 : i32 to index
      %3 = gpu.block_id  x
      %4 = arith.index_cast %3 : index to i32
      %5 = gpu.block_id  y
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.index_cast %1 : index to i32
      %8 = arith.index_cast %0 : index to i32
      %9 = arith.muli %6, %c32_i32 : i32
      %10 = arith.addi %9, %8 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.muli %10, %arg3 : i32
      %13 = arith.index_cast %12 : i32 to index
      %14 = arith.muli %4, %c32_i32 : i32
      %15 = arith.addi %14, %7 : i32
      %16 = arith.index_cast %15 : i32 to index
      %17 = arith.addi %arg3, %c31_i32 : i32
      %18 = arith.divsi %17, %c32_i32 : i32
      %19 = arith.index_cast %18 : i32 to index
      %20 = scf.for %arg5 = %c0_5 to %19 step %c1_4 iter_args(%arg6 = %cst) -> (f32) {
        %24 = arith.index_cast %arg5 : index to i32
        %25 = arith.subi %2, %11 : index
        %26 = arith.addi %25, %c-1 : index
        %27 = arith.cmpi sge, %26, %c0_5 : index
        %28 = scf.if %27 -> (i1) {
          %34 = arith.muli %24, %c32_i32 : i32
          %35 = arith.addi %34, %7 : i32
          %36 = arith.cmpi slt, %35, %arg3 : i32
          scf.yield %36 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %28 {
          %34 = arith.muli %arg5, %c32_3 : index
          %35 = arith.addi %34, %13 : index
          %36 = arith.addi %35, %1 : index
          %37 = memref.load %arg0[%36] : memref<?xf32>
          memref.store %37, %alloca_0[%0, %1] : memref<32x32xf32, 5>
        } else {
          memref.store %cst, %alloca_0[%0, %1] : memref<32x32xf32, 5>
        }
        %29 = arith.subi %2, %16 : index
        %30 = arith.addi %29, %c-1 : index
        %31 = arith.cmpi sge, %30, %c0_5 : index
        %32 = scf.if %31 -> (i1) {
          %34 = arith.muli %24, %c32_i32 : i32
          %35 = arith.addi %34, %8 : i32
          %36 = arith.cmpi slt, %35, %arg3 : i32
          scf.yield %36 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %32 {
          %34 = arith.muli %arg5, %c32_3 : index
          %35 = arith.addi %34, %0 : index
          %36 = arith.muli %35, %2 : index
          %37 = arith.addi %36, %16 : index
          %38 = memref.load %arg1[%37] : memref<?xf32>
          memref.store %38, %alloca[%0, %1] : memref<32x32xf32, 5>
        } else {
          memref.store %cst, %alloca[%0, %1] : memref<32x32xf32, 5>
        }
        "polygeist.barrier"(%arg4) : (index) -> ()
        %33 = scf.for %arg7 = %c0_5 to %c32_3 step %c1_4 iter_args(%arg8 = %arg6) -> (f32) {
          %34 = memref.load %alloca_0[%0, %arg7] : memref<32x32xf32, 5>
          %35 = memref.load %alloca[%arg7, %1] : memref<32x32xf32, 5>
          %36 = arith.mulf %34, %35 : f32
          %37 = arith.addf %arg8, %36 : f32
          scf.yield %37 : f32
        }
        "polygeist.barrier"(%arg4) : (index) -> ()
        scf.yield %33 : f32
      }
      %21 = arith.cmpi slt, %10, %arg3 : i32
      %22 = arith.cmpi slt, %15, %arg3 : i32
      %23 = arith.andi %21, %22 : i1
      scf.if %23 {
        %24 = arith.addi %13, %16 : index
        memref.store %20, %arg2[%24] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %c1_1 = arith.constant 1 : index
      %0 = arith.remui %arg4, %c1_1 : index
      %c1_2 = arith.constant 1 : index
      %1 = arith.divui %arg4, %c1_2 : index
      %c32_3 = arith.constant 32 : index
      %c-1 = arith.constant -1 : index
      %c1_4 = arith.constant 1 : index
      %c0_5 = arith.constant 0 : index
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %false = arith.constant false
      %c31_i32 = arith.constant 31 : i32
      %2 = arith.index_cast %arg3 : i32 to index
      %3 = gpu.block_id  x
      %4 = arith.index_cast %3 : index to i32
      %5 = gpu.block_id  y
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.index_cast %1 : index to i32
      %8 = arith.index_cast %0 : index to i32
      %9 = arith.muli %6, %c32_i32 : i32
      %10 = arith.addi %9, %8 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.muli %10, %arg3 : i32
      %13 = arith.index_cast %12 : i32 to index
      %14 = arith.muli %4, %c32_i32 : i32
      %15 = arith.addi %14, %7 : i32
      %16 = arith.index_cast %15 : i32 to index
      %17 = arith.addi %arg3, %c31_i32 : i32
      %18 = arith.divsi %17, %c32_i32 : i32
      %19 = arith.index_cast %18 : i32 to index
      %20 = scf.for %arg5 = %c0_5 to %19 step %c1_4 iter_args(%arg6 = %cst) -> (f32) {
        %24 = arith.index_cast %arg5 : index to i32
        %25 = arith.subi %2, %11 : index
        %26 = arith.addi %25, %c-1 : index
        %27 = arith.cmpi sge, %26, %c0_5 : index
        %28 = scf.if %27 -> (i1) {
          %34 = arith.muli %24, %c32_i32 : i32
          %35 = arith.addi %34, %7 : i32
          %36 = arith.cmpi slt, %35, %arg3 : i32
          scf.yield %36 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %28 {
          %34 = arith.muli %arg5, %c32_3 : index
          %35 = arith.addi %34, %13 : index
          %36 = arith.addi %35, %1 : index
          %37 = memref.load %arg0[%36] : memref<?xf32>
          memref.store %37, %alloca_0[%0, %1] : memref<32x32xf32, 5>
        } else {
          memref.store %cst, %alloca_0[%0, %1] : memref<32x32xf32, 5>
        }
        %29 = arith.subi %2, %16 : index
        %30 = arith.addi %29, %c-1 : index
        %31 = arith.cmpi sge, %30, %c0_5 : index
        %32 = scf.if %31 -> (i1) {
          %34 = arith.muli %24, %c32_i32 : i32
          %35 = arith.addi %34, %8 : i32
          %36 = arith.cmpi slt, %35, %arg3 : i32
          scf.yield %36 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %32 {
          %34 = arith.muli %arg5, %c32_3 : index
          %35 = arith.addi %34, %0 : index
          %36 = arith.muli %35, %2 : index
          %37 = arith.addi %36, %16 : index
          %38 = memref.load %arg1[%37] : memref<?xf32>
          memref.store %38, %alloca[%0, %1] : memref<32x32xf32, 5>
        } else {
          memref.store %cst, %alloca[%0, %1] : memref<32x32xf32, 5>
        }
        "polygeist.barrier"(%arg4) : (index) -> ()
        %33 = scf.for %arg7 = %c0_5 to %c32_3 step %c1_4 iter_args(%arg8 = %arg6) -> (f32) {
          %34 = memref.load %alloca_0[%0, %arg7] : memref<32x32xf32, 5>
          %35 = memref.load %alloca[%arg7, %1] : memref<32x32xf32, 5>
          %36 = arith.mulf %34, %35 : f32
          %37 = arith.addf %arg8, %36 : f32
          scf.yield %37 : f32
        }
        "polygeist.barrier"(%arg4) : (index) -> ()
        scf.yield %33 : f32
      }
      %21 = arith.cmpi slt, %10, %arg3 : i32
      %22 = arith.cmpi slt, %15, %arg3 : i32
      %23 = arith.andi %21, %22 : i1
      scf.if %23 {
        %24 = arith.addi %13, %16 : index
        memref.store %20, %arg2[%24] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c31_i32 = arith.constant 31 : i32
    %false = arith.constant false
    %cst = arith.constant 0.000000e+00 : f32
    %c32_i32 = arith.constant 32 : i32
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<32x32xf32, 5>
    %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
    %alloca_1 = memref.alloca() : memref<32xf32>
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      memref.store %cst, %alloca_1[%arg4] : memref<32xf32>
      scf.yield
    }
    %0 = arith.addi %arg3, %c31_i32 : i32
    %1 = arith.divsi %0, %c32_i32 : i32
    %2 = arith.index_cast %1 : i32 to index
    %3 = gpu.block_id  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %4, %c32_i32 : i32
    %6 = gpu.block_id  y
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.muli %7, %c32_i32 : i32
    %9 = arith.muli %8, %arg3 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %8 : i32 to index
    %12 = arith.index_cast %arg3 : i32 to index
    %13 = arith.subi %12, %11 : index
    %14 = arith.addi %13, %c-1 : index
    %15 = arith.cmpi sge, %14, %c0 : index
    scf.for %arg4 = %c0 to %2 step %c1 {
      %25 = arith.index_cast %arg4 : index to i32
      %26 = arith.muli %25, %c32_i32 : i32
      %27 = arith.muli %arg4, %c32 : index
      %28 = arith.addi %27, %10 : index
      %29 = arith.muli %25, %c32_i32 : i32
      %30 = arith.cmpi slt, %29, %arg3 : i32
      %31 = arith.muli %arg4, %c32 : index
      %32 = arith.muli %31, %12 : index
      scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
        %33 = arith.index_cast %arg5 : index to i32
        %34 = arith.addi %5, %33 : i32
        %35 = arith.index_cast %34 : i32 to index
        %36 = scf.if %15 -> (i1) {
          %41 = arith.addi %26, %33 : i32
          %42 = arith.cmpi slt, %41, %arg3 : i32
          scf.yield %42 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %36 {
          %41 = arith.addi %28, %arg5 : index
          %42 = memref.load %arg0[%41] : memref<?xf32>
          memref.store %42, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
        } else {
          memref.store %cst, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
        }
        %37 = arith.subi %12, %35 : index
        %38 = arith.addi %37, %c-1 : index
        %39 = arith.cmpi sge, %38, %c0 : index
        %40 = scf.if %39 -> (i1) {
          scf.yield %30 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %40 {
          %41 = arith.addi %32, %35 : index
          %42 = memref.load %arg1[%41] : memref<?xf32>
          memref.store %42, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
        } else {
          memref.store %cst, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
        }
        scf.yield
      }
      scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
        %33 = memref.load %alloca_1[%arg5] : memref<32xf32>
        %34 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %33) -> (f32) {
          %35 = memref.load %alloca_0[%c0, %arg6] : memref<32x32xf32, 5>
          %36 = memref.load %alloca[%arg6, %arg5] : memref<32x32xf32, 5>
          %37 = arith.mulf %35, %36 : f32
          %38 = arith.addf %arg7, %37 : f32
          scf.yield %38 : f32
        }
        memref.store %34, %alloca_1[%arg5] : memref<32xf32>
        scf.yield
      }
    }
    %16 = gpu.block_id  y
    %17 = arith.index_cast %16 : index to i32
    %18 = arith.muli %17, %c32_i32 : i32
    %19 = arith.muli %18, %arg3 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = gpu.block_id  x
    %22 = arith.index_cast %21 : index to i32
    %23 = arith.muli %22, %c32_i32 : i32
    %24 = arith.cmpi slt, %18, %arg3 : i32
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %25 = arith.index_cast %arg4 : index to i32
      %26 = arith.addi %23, %25 : i32
      %27 = arith.index_cast %26 : i32 to index
      %28 = memref.load %alloca_1[%arg4] : memref<32xf32>
      %29 = arith.cmpi slt, %26, %arg3 : i32
      %30 = arith.andi %24, %29 : i1
      scf.if %30 {
        %31 = arith.addi %20, %27 : index
        memref.store %28, %arg2[%31] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<32x32xf32, 5>
      %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32>
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        memref.store %cst, %alloca_1[%arg4] : memref<32xf32>
        scf.yield
      }
      %0 = arith.addi %arg3, %c31_i32 : i32
      %1 = arith.divsi %0, %c32_i32 : i32
      %2 = arith.index_cast %1 : i32 to index
      %3 = gpu.block_id  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %4, %c32_i32 : i32
      %6 = gpu.block_id  y
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.muli %7, %c32_i32 : i32
      %9 = arith.muli %8, %arg3 : i32
      %10 = arith.index_cast %9 : i32 to index
      %11 = arith.index_cast %8 : i32 to index
      %12 = arith.index_cast %arg3 : i32 to index
      %13 = arith.subi %12, %11 : index
      %14 = arith.addi %13, %c-1 : index
      %15 = arith.cmpi sge, %14, %c0 : index
      scf.for %arg4 = %c0 to %2 step %c1 {
        %17 = arith.index_cast %arg4 : index to i32
        %18 = arith.muli %17, %c32_i32 : i32
        %19 = arith.muli %arg4, %c32 : index
        %20 = arith.addi %19, %10 : index
        %21 = arith.cmpi slt, %18, %arg3 : i32
        %22 = arith.muli %19, %12 : index
        scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
          %23 = arith.index_cast %arg5 : index to i32
          %24 = arith.addi %5, %23 : i32
          %25 = arith.index_cast %24 : i32 to index
          %26 = scf.if %15 -> (i1) {
            %31 = arith.addi %18, %23 : i32
            %32 = arith.cmpi slt, %31, %arg3 : i32
            scf.yield %32 : i1
          } else {
            scf.yield %false : i1
          }
          scf.if %26 {
            %31 = arith.addi %20, %arg5 : index
            %32 = memref.load %arg0[%31] : memref<?xf32>
            memref.store %32, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %27 = arith.subi %12, %25 : index
          %28 = arith.addi %27, %c-1 : index
          %29 = arith.cmpi sge, %28, %c0 : index
          %30 = arith.andi %29, %21 : i1
          scf.if %30 {
            %31 = arith.addi %22, %25 : index
            %32 = memref.load %arg1[%31] : memref<?xf32>
            memref.store %32, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          }
          scf.yield
        }
        scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
          %23 = memref.load %alloca_1[%arg5] : memref<32xf32>
          %24 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %23) -> (f32) {
            %25 = memref.load %alloca_0[%c0, %arg6] : memref<32x32xf32, 5>
            %26 = memref.load %alloca[%arg6, %arg5] : memref<32x32xf32, 5>
            %27 = arith.mulf %25, %26 : f32
            %28 = arith.addf %arg7, %27 : f32
            scf.yield %28 : f32
          }
          memref.store %24, %alloca_1[%arg5] : memref<32xf32>
          scf.yield
        }
      }
      %16 = arith.cmpi slt, %8, %arg3 : i32
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %17 = arith.index_cast %arg4 : index to i32
        %18 = arith.addi %5, %17 : i32
        %19 = arith.index_cast %18 : i32 to index
        %20 = memref.load %alloca_1[%arg4] : memref<32xf32>
        %21 = arith.cmpi slt, %18, %arg3 : i32
        %22 = arith.andi %16, %21 : i1
        scf.if %22 {
          %23 = arith.addi %10, %19 : index
          memref.store %20, %arg2[%23] : memref<?xf32>
        }
        scf.yield
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<32x32xf32, 5>
      %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32>
      %c1_2 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg4] : memref<32xf32>
      }
      %0 = arith.addi %arg3, %c31_i32 : i32
      %1 = arith.divsi %0, %c32_i32 : i32
      %2 = arith.index_cast %1 : i32 to index
      %3 = gpu.block_id  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %4, %c32_i32 : i32
      %6 = gpu.block_id  y
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.muli %7, %c32_i32 : i32
      %9 = arith.muli %8, %arg3 : i32
      %10 = arith.index_cast %9 : i32 to index
      %11 = arith.index_cast %8 : i32 to index
      %12 = arith.index_cast %arg3 : i32 to index
      %13 = arith.subi %12, %11 : index
      %14 = arith.addi %13, %c-1 : index
      %15 = arith.cmpi sge, %14, %c0 : index
      scf.for %arg4 = %c0 to %2 step %c1 {
        %17 = arith.index_cast %arg4 : index to i32
        %18 = arith.muli %17, %c32_i32 : i32
        %19 = arith.muli %arg4, %c32 : index
        %20 = arith.addi %19, %10 : index
        %21 = arith.cmpi slt, %18, %arg3 : i32
        %22 = arith.muli %19, %12 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_4 {
          %23 = arith.index_cast %arg5 : index to i32
          %24 = arith.addi %5, %23 : i32
          %25 = arith.index_cast %24 : i32 to index
          %26 = scf.if %15 -> (i1) {
            %31 = arith.addi %18, %23 : i32
            %32 = arith.cmpi slt, %31, %arg3 : i32
            scf.yield %32 : i1
          } else {
            scf.yield %false : i1
          }
          scf.if %26 {
            %31 = arith.addi %20, %arg5 : index
            %32 = memref.load %arg0[%31] : memref<?xf32>
            memref.store %32, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %27 = arith.subi %12, %25 : index
          %28 = arith.addi %27, %c-1 : index
          %29 = arith.cmpi sge, %28, %c0 : index
          %30 = arith.andi %29, %21 : i1
          scf.if %30 {
            %31 = arith.addi %22, %25 : index
            %32 = memref.load %arg1[%31] : memref<?xf32>
            memref.store %32, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_5 {
          %23 = memref.load %alloca_1[%arg5] : memref<32xf32>
          %24 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %23) -> (f32) {
            %25 = memref.load %alloca_0[%c0, %arg6] : memref<32x32xf32, 5>
            %26 = memref.load %alloca[%arg6, %arg5] : memref<32x32xf32, 5>
            %27 = arith.mulf %25, %26 : f32
            %28 = arith.addf %arg7, %27 : f32
            scf.yield %28 : f32
          }
          memref.store %24, %alloca_1[%arg5] : memref<32xf32>
        }
      }
      %16 = arith.cmpi slt, %8, %arg3 : i32
      %c1_3 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_3 {
        %17 = arith.index_cast %arg4 : index to i32
        %18 = arith.addi %5, %17 : i32
        %19 = arith.index_cast %18 : i32 to index
        %20 = memref.load %alloca_1[%arg4] : memref<32xf32>
        %21 = arith.cmpi slt, %18, %arg3 : i32
        %22 = arith.andi %16, %21 : i1
        scf.if %22 {
          %23 = arith.addi %10, %19 : index
          memref.store %20, %arg2[%23] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca = memref.alloca() : memref<32x32xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca = memref.alloca() : memref<32x32xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<32x32xf32, 5>
      %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32, 5>
      %c1_2 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg4] : memref<32xf32, 5>
      }
      %1 = arith.addi %arg3, %c31_i32 : i32
      %2 = arith.divsi %1, %c32_i32 : i32
      %3 = arith.index_cast %2 : i32 to index
      %4 = gpu.block_id  x
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.muli %5, %c32_i32 : i32
      %7 = gpu.block_id  y
      %8 = arith.index_cast %7 : index to i32
      %9 = arith.muli %8, %c32_i32 : i32
      %10 = arith.muli %9, %arg3 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.index_cast %9 : i32 to index
      %13 = arith.index_cast %arg3 : i32 to index
      %14 = arith.subi %13, %12 : index
      %15 = arith.addi %14, %c-1 : index
      %16 = arith.cmpi sge, %15, %c0 : index
      scf.for %arg4 = %c0 to %3 step %c1 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.muli %18, %c32_i32 : i32
        %20 = arith.muli %arg4, %c32 : index
        %21 = arith.addi %20, %11 : index
        %22 = arith.cmpi slt, %19, %arg3 : i32
        %23 = arith.muli %20, %13 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_4 {
          %24 = arith.index_cast %arg5 : index to i32
          %25 = arith.addi %6, %24 : i32
          %26 = arith.index_cast %25 : i32 to index
          %27 = scf.if %16 -> (i1) {
            %32 = arith.addi %19, %24 : i32
            %33 = arith.cmpi slt, %32, %arg3 : i32
            scf.yield %33 : i1
          } else {
            scf.yield %false : i1
          }
          scf.if %27 {
            %32 = arith.addi %21, %arg5 : index
            %33 = memref.load %arg0[%32] : memref<?xf32>
            memref.store %33, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %28 = arith.subi %13, %26 : index
          %29 = arith.addi %28, %c-1 : index
          %30 = arith.cmpi sge, %29, %c0 : index
          %31 = arith.andi %30, %22 : i1
          scf.if %31 {
            %32 = arith.addi %23, %26 : index
            %33 = memref.load %arg1[%32] : memref<?xf32>
            memref.store %33, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_5 {
          %24 = memref.load %alloca_1[%arg5] : memref<32xf32, 5>
          %25 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %24) -> (f32) {
            %26 = memref.load %alloca_0[%c0, %arg6] : memref<32x32xf32, 5>
            %27 = memref.load %alloca[%arg6, %arg5] : memref<32x32xf32, 5>
            %28 = arith.mulf %26, %27 : f32
            %29 = arith.addf %arg7, %28 : f32
            scf.yield %29 : f32
          }
          memref.store %25, %alloca_1[%arg5] : memref<32xf32, 5>
        }
      }
      %17 = arith.cmpi slt, %9, %arg3 : i32
      %c1_3 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_3 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.addi %6, %18 : i32
        %20 = arith.index_cast %19 : i32 to index
        %21 = memref.load %alloca_1[%arg4] : memref<32xf32, 5>
        %22 = arith.cmpi slt, %19, %arg3 : i32
        %23 = arith.andi %17, %22 : i1
        scf.if %23 {
          %24 = arith.addi %11, %20 : index
          memref.store %21, %arg2[%24] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_0 = memref.alloca() : memref<32x32xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%1 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_0 = memref.alloca() : memref<32x32xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<32x32xf32, 5>
      %1 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
      %alloca_1 = memref.alloca() : memref<32xf32, 5>
      %c1_2 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg4] : memref<32xf32, 5>
      }
      %2 = arith.addi %arg3, %c31_i32 : i32
      %3 = arith.divsi %2, %c32_i32 : i32
      %4 = arith.index_cast %3 : i32 to index
      %5 = gpu.block_id  x
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.muli %6, %c32_i32 : i32
      %8 = gpu.block_id  y
      %9 = arith.index_cast %8 : index to i32
      %10 = arith.muli %9, %c32_i32 : i32
      %11 = arith.muli %10, %arg3 : i32
      %12 = arith.index_cast %11 : i32 to index
      %13 = arith.index_cast %10 : i32 to index
      %14 = arith.index_cast %arg3 : i32 to index
      %15 = arith.subi %14, %13 : index
      %16 = arith.addi %15, %c-1 : index
      %17 = arith.cmpi sge, %16, %c0 : index
      scf.for %arg4 = %c0 to %4 step %c1 {
        %19 = arith.index_cast %arg4 : index to i32
        %20 = arith.muli %19, %c32_i32 : i32
        %21 = arith.muli %arg4, %c32 : index
        %22 = arith.addi %21, %12 : index
        %23 = arith.cmpi slt, %20, %arg3 : i32
        %24 = arith.muli %21, %14 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_4 {
          %25 = arith.index_cast %arg5 : index to i32
          %26 = arith.addi %7, %25 : i32
          %27 = arith.index_cast %26 : i32 to index
          %28 = scf.if %17 -> (i1) {
            %33 = arith.addi %20, %25 : i32
            %34 = arith.cmpi slt, %33, %arg3 : i32
            scf.yield %34 : i1
          } else {
            scf.yield %false : i1
          }
          scf.if %28 {
            %33 = arith.addi %22, %arg5 : index
            %34 = memref.load %arg0[%33] : memref<?xf32>
            memref.store %34, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %29 = arith.subi %14, %27 : index
          %30 = arith.addi %29, %c-1 : index
          %31 = arith.cmpi sge, %30, %c0 : index
          %32 = arith.andi %31, %23 : i1
          scf.if %32 {
            %33 = arith.addi %24, %27 : index
            %34 = memref.load %arg1[%33] : memref<?xf32>
            memref.store %34, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_5 {
          %25 = memref.load %alloca_1[%arg5] : memref<32xf32, 5>
          %26 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %25) -> (f32) {
            %27 = memref.load %alloca_0[%c0, %arg6] : memref<32x32xf32, 5>
            %28 = memref.load %alloca[%arg6, %arg5] : memref<32x32xf32, 5>
            %29 = arith.mulf %27, %28 : f32
            %30 = arith.addf %arg7, %29 : f32
            scf.yield %30 : f32
          }
          memref.store %26, %alloca_1[%arg5] : memref<32xf32, 5>
        }
      }
      %18 = arith.cmpi slt, %10, %arg3 : i32
      %c1_3 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_3 {
        %19 = arith.index_cast %arg4 : index to i32
        %20 = arith.addi %7, %19 : i32
        %21 = arith.index_cast %20 : i32 to index
        %22 = memref.load %alloca_1[%arg4] : memref<32xf32, 5>
        %23 = arith.cmpi slt, %20, %arg3 : i32
        %24 = arith.andi %18, %23 : i1
        scf.if %24 {
          %25 = arith.addi %12, %21 : index
          memref.store %22, %arg2[%25] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_1 = memref.alloca() : memref<32xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_1 = memref.alloca() : memref<32xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<32x32xf32, 5>
      %1 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<32x32xf32, 5>
      %2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_1 = memref.alloca() : memref<32xf32, 5>
      %c1_2 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_2 {
        memref.store %cst, %alloca_1[%arg4] : memref<32xf32, 5>
      }
      %3 = arith.addi %arg3, %c31_i32 : i32
      %4 = arith.divsi %3, %c32_i32 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = gpu.block_id  x
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.muli %7, %c32_i32 : i32
      %9 = gpu.block_id  y
      %10 = arith.index_cast %9 : index to i32
      %11 = arith.muli %10, %c32_i32 : i32
      %12 = arith.muli %11, %arg3 : i32
      %13 = arith.index_cast %12 : i32 to index
      %14 = arith.index_cast %11 : i32 to index
      %15 = arith.index_cast %arg3 : i32 to index
      %16 = arith.subi %15, %14 : index
      %17 = arith.addi %16, %c-1 : index
      %18 = arith.cmpi sge, %17, %c0 : index
      scf.for %arg4 = %c0 to %5 step %c1 {
        %20 = arith.index_cast %arg4 : index to i32
        %21 = arith.muli %20, %c32_i32 : i32
        %22 = arith.muli %arg4, %c32 : index
        %23 = arith.addi %22, %13 : index
        %24 = arith.cmpi slt, %21, %arg3 : i32
        %25 = arith.muli %22, %15 : index
        %c1_4 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_4 {
          %26 = arith.index_cast %arg5 : index to i32
          %27 = arith.addi %8, %26 : i32
          %28 = arith.index_cast %27 : i32 to index
          %29 = scf.if %18 -> (i1) {
            %34 = arith.addi %21, %26 : i32
            %35 = arith.cmpi slt, %34, %arg3 : i32
            scf.yield %35 : i1
          } else {
            scf.yield %false : i1
          }
          scf.if %29 {
            %34 = arith.addi %23, %arg5 : index
            %35 = memref.load %arg0[%34] : memref<?xf32>
            memref.store %35, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca_0[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %30 = arith.subi %15, %28 : index
          %31 = arith.addi %30, %c-1 : index
          %32 = arith.cmpi sge, %31, %c0 : index
          %33 = arith.andi %32, %24 : i1
          scf.if %33 {
            %34 = arith.addi %25, %28 : index
            %35 = memref.load %arg1[%34] : memref<?xf32>
            memref.store %35, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %alloca[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_5 {
          %26 = memref.load %alloca_1[%arg5] : memref<32xf32, 5>
          %27 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %26) -> (f32) {
            %28 = memref.load %alloca_0[%c0, %arg6] : memref<32x32xf32, 5>
            %29 = memref.load %alloca[%arg6, %arg5] : memref<32x32xf32, 5>
            %30 = arith.mulf %28, %29 : f32
            %31 = arith.addf %arg7, %30 : f32
            scf.yield %31 : f32
          }
          memref.store %27, %alloca_1[%arg5] : memref<32xf32, 5>
        }
      }
      %19 = arith.cmpi slt, %11, %arg3 : i32
      %c1_3 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_3 {
        %20 = arith.index_cast %arg4 : index to i32
        %21 = arith.addi %8, %20 : i32
        %22 = arith.index_cast %21 : i32 to index
        %23 = memref.load %alloca_1[%arg4] : memref<32xf32, 5>
        %24 = arith.cmpi slt, %21, %arg3 : i32
        %25 = arith.andi %19, %24 : i1
        scf.if %25 {
          %26 = arith.addi %13, %22 : index
          memref.store %23, %arg2[%26] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] GPUBlockIdToNPULowering: process op: 

%6 = gpu.block_id  x
[ict-debug] GPUBlockIdToNPULowering: process op: 

%10 = gpu.block_id  y
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %1 = builtin.unrealized_conversion_cast %0 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %2 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %3 = builtin.unrealized_conversion_cast %2 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %5 = builtin.unrealized_conversion_cast %4 : !llvm.ptr<6> to memref<32xf32, 5>
      %c1_0 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_0 {
        memref.store %cst, %5[%arg4] : memref<32xf32, 5>
      }
      %6 = arith.addi %arg3, %c31_i32 : i32
      %7 = arith.divsi %6, %c32_i32 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %10 = arith.index_cast %9 : i64 to index
      %11 = builtin.unrealized_conversion_cast %9 : i64 to index
      %12 = arith.index_cast %10 : index to i32
      %13 = arith.muli %12, %c32_i32 : i32
      %14 = "npu.block_id"() <{dimension = "Y"}> : () -> i64
      %15 = arith.index_cast %14 : i64 to index
      %16 = builtin.unrealized_conversion_cast %14 : i64 to index
      %17 = arith.index_cast %15 : index to i32
      %18 = arith.muli %17, %c32_i32 : i32
      %19 = arith.muli %18, %arg3 : i32
      %20 = arith.index_cast %19 : i32 to index
      %21 = arith.index_cast %18 : i32 to index
      %22 = arith.index_cast %arg3 : i32 to index
      %23 = arith.subi %22, %21 : index
      %24 = arith.addi %23, %c-1 : index
      %25 = arith.cmpi sge, %24, %c0 : index
      scf.for %arg4 = %c0 to %8 step %c1 {
        %27 = arith.index_cast %arg4 : index to i32
        %28 = arith.muli %27, %c32_i32 : i32
        %29 = arith.muli %arg4, %c32 : index
        %30 = arith.addi %29, %20 : index
        %31 = arith.cmpi slt, %28, %arg3 : i32
        %32 = arith.muli %29, %22 : index
        %c1_2 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_2 {
          %33 = arith.index_cast %arg5 : index to i32
          %34 = arith.addi %13, %33 : i32
          %35 = arith.index_cast %34 : i32 to index
          %36 = scf.if %25 -> (i1) {
            %41 = arith.addi %28, %33 : i32
            %42 = arith.cmpi slt, %41, %arg3 : i32
            scf.yield %42 : i1
          } else {
            scf.yield %false : i1
          }
          scf.if %36 {
            %41 = arith.addi %30, %arg5 : index
            %42 = memref.load %arg0[%41] : memref<?xf32>
            memref.store %42, %3[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %3[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %37 = arith.subi %22, %35 : index
          %38 = arith.addi %37, %c-1 : index
          %39 = arith.cmpi sge, %38, %c0 : index
          %40 = arith.andi %39, %31 : i1
          scf.if %40 {
            %41 = arith.addi %32, %35 : index
            %42 = memref.load %arg1[%41] : memref<?xf32>
            memref.store %42, %1[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %1[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        %c1_3 = arith.constant 1 : index
        scf.for %arg5 = %c0 to %c32 step %c1_3 {
          %33 = memref.load %5[%arg5] : memref<32xf32, 5>
          %34 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %33) -> (f32) {
            %35 = memref.load %3[%c0, %arg6] : memref<32x32xf32, 5>
            %36 = memref.load %1[%arg6, %arg5] : memref<32x32xf32, 5>
            %37 = emitc.mul %35, %36 : (f32, f32) -> f32
            %38 = emitc.add %arg7, %37 : (f32, f32) -> f32
            scf.yield %38 : f32
          }
          memref.store %34, %5[%arg5] : memref<32xf32, 5>
        }
      }
      %26 = arith.cmpi slt, %18, %arg3 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_1 {
        %27 = arith.index_cast %arg4 : index to i32
        %28 = arith.addi %13, %27 : i32
        %29 = arith.index_cast %28 : i32 to index
        %30 = memref.load %5[%arg4] : memref<32xf32, 5>
        %31 = arith.cmpi slt, %28, %arg3 : i32
        %32 = arith.andi %26, %31 : i1
        scf.if %32 {
          %33 = arith.addi %20, %29 : index
          memref.store %30, %arg2[%33] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU: end

[ict-debug] driver.cc: Before convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %1 = builtin.unrealized_conversion_cast %0 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %2 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %3 = builtin.unrealized_conversion_cast %2 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %5 = builtin.unrealized_conversion_cast %4 : !llvm.ptr<6> to memref<32xf32, 5>
      scf.for %arg4 = %c0 to %c32 step %c1 {
        memref.store %cst, %5[%arg4] : memref<32xf32, 5>
      }
      %6 = arith.addi %arg3, %c31_i32 : i32
      %7 = arith.divsi %6, %c32_i32 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %10 = arith.index_cast %9 : i64 to index
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.muli %11, %c32_i32 : i32
      %13 = "npu.block_id"() <{dimension = "Y"}> : () -> i64
      %14 = arith.index_cast %13 : i64 to index
      %15 = arith.index_cast %14 : index to i32
      %16 = arith.muli %15, %c32_i32 : i32
      %17 = arith.muli %16, %arg3 : i32
      %18 = arith.index_cast %17 : i32 to index
      %19 = arith.index_cast %16 : i32 to index
      %20 = arith.index_cast %arg3 : i32 to index
      %21 = arith.subi %20, %19 : index
      %22 = arith.addi %21, %c-1 : index
      %23 = arith.cmpi sge, %22, %c0 : index
      scf.for %arg4 = %c0 to %8 step %c1 {
        %25 = arith.index_cast %arg4 : index to i32
        %26 = arith.muli %25, %c32_i32 : i32
        %27 = arith.muli %arg4, %c32 : index
        %28 = arith.addi %27, %18 : index
        %29 = arith.cmpi slt, %26, %arg3 : i32
        %30 = arith.muli %27, %20 : index
        scf.for %arg5 = %c0 to %c32 step %c1 {
          %31 = arith.index_cast %arg5 : index to i32
          %32 = arith.addi %12, %31 : i32
          %33 = arith.index_cast %32 : i32 to index
          %34 = scf.if %23 -> (i1) {
            %39 = arith.addi %26, %31 : i32
            %40 = arith.cmpi slt, %39, %arg3 : i32
            scf.yield %40 : i1
          } else {
            scf.yield %false : i1
          }
          scf.if %34 {
            %39 = arith.addi %28, %arg5 : index
            %40 = memref.load %arg0[%39] : memref<?xf32>
            memref.store %40, %3[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %3[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %35 = arith.subi %20, %33 : index
          %36 = arith.addi %35, %c-1 : index
          %37 = arith.cmpi sge, %36, %c0 : index
          %38 = arith.andi %37, %29 : i1
          scf.if %38 {
            %39 = arith.addi %30, %33 : index
            %40 = memref.load %arg1[%39] : memref<?xf32>
            memref.store %40, %1[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %1[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        scf.for %arg5 = %c0 to %c32 step %c1 {
          %31 = memref.load %5[%arg5] : memref<32xf32, 5>
          %32 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %31) -> (f32) {
            %33 = memref.load %3[%c0, %arg6] : memref<32x32xf32, 5>
            %34 = memref.load %1[%arg6, %arg5] : memref<32x32xf32, 5>
            %35 = emitc.mul %33, %34 : (f32, f32) -> f32
            %36 = emitc.add %arg7, %35 : (f32, f32) -> f32
            scf.yield %36 : f32
          }
          memref.store %32, %5[%arg5] : memref<32xf32, 5>
        }
      }
      %24 = arith.cmpi slt, %16, %arg3 : i32
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %25 = arith.index_cast %arg4 : index to i32
        %26 = arith.addi %12, %25 : i32
        %27 = arith.index_cast %26 : i32 to index
        %28 = memref.load %5[%arg4] : memref<32xf32, 5>
        %29 = arith.cmpi slt, %26, %arg3 : i32
        %30 = arith.andi %24, %29 : i1
        scf.if %30 {
          %31 = arith.addi %18, %27 : index
          memref.store %28, %arg2[%31] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] driver.cc: Before convert to EmitC dialect: end

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %1 = builtin.unrealized_conversion_cast %0 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %2 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %3 = builtin.unrealized_conversion_cast %2 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %5 = builtin.unrealized_conversion_cast %4 : !llvm.ptr<6> to memref<32xf32, 5>
      scf.for %arg4 = %c0 to %c32 step %c1 {
        memref.store %cst, %5[%arg4] : memref<32xf32, 5>
      }
      %6 = arith.addi %arg3, %c31_i32 : i32
      %7 = arith.divsi %6, %c32_i32 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %10 = arith.index_cast %9 : i64 to index
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.muli %11, %c32_i32 : i32
      %13 = "npu.block_id"() <{dimension = "Y"}> : () -> i64
      %14 = arith.index_cast %13 : i64 to index
      %15 = arith.index_cast %14 : index to i32
      %16 = arith.muli %15, %c32_i32 : i32
      %17 = arith.muli %16, %arg3 : i32
      %18 = arith.index_cast %17 : i32 to index
      %19 = arith.index_cast %16 : i32 to index
      %20 = arith.index_cast %arg3 : i32 to index
      %21 = arith.subi %20, %19 : index
      %22 = arith.addi %21, %c-1 : index
      %23 = arith.cmpi sge, %22, %c0 : index
      scf.for %arg4 = %c0 to %8 step %c1 {
        %25 = arith.index_cast %arg4 : index to i32
        %26 = arith.muli %25, %c32_i32 : i32
        %27 = arith.muli %arg4, %c32 : index
        %28 = arith.addi %27, %18 : index
        %29 = arith.cmpi slt, %26, %arg3 : i32
        %30 = arith.muli %27, %20 : index
        scf.for %arg5 = %c0 to %c32 step %c1 {
          %31 = arith.index_cast %arg5 : index to i32
          %32 = arith.addi %12, %31 : i32
          %33 = arith.index_cast %32 : i32 to index
          %34 = "emitc.variable"() <{value = #emitc.opaque<"">}> : () -> i1
          emitc.if %23 {
            %39 = arith.addi %26, %31 : i32
            %40 = arith.cmpi slt, %39, %arg3 : i32
            emitc.assign %40 : i1 to %34 : i1
          } else {
            emitc.assign %false : i1 to %34 : i1
          }
          emitc.if %34 {
            %39 = arith.addi %28, %arg5 : index
            %40 = memref.load %arg0[%39] : memref<?xf32>
            memref.store %40, %3[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %3[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %35 = arith.subi %20, %33 : index
          %36 = arith.addi %35, %c-1 : index
          %37 = arith.cmpi sge, %36, %c0 : index
          %38 = arith.andi %37, %29 : i1
          emitc.if %38 {
            %39 = arith.addi %30, %33 : index
            %40 = memref.load %arg1[%39] : memref<?xf32>
            memref.store %40, %1[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %1[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        scf.for %arg5 = %c0 to %c32 step %c1 {
          %31 = memref.load %5[%arg5] : memref<32xf32, 5>
          %32 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %31) -> (f32) {
            %33 = memref.load %3[%c0, %arg6] : memref<32x32xf32, 5>
            %34 = memref.load %1[%arg6, %arg5] : memref<32x32xf32, 5>
            %35 = emitc.mul %33, %34 : (f32, f32) -> f32
            %36 = emitc.add %arg7, %35 : (f32, f32) -> f32
            scf.yield %36 : f32
          }
          memref.store %32, %5[%arg5] : memref<32xf32, 5>
        }
      }
      %24 = arith.cmpi slt, %16, %arg3 : i32
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %25 = arith.index_cast %arg4 : index to i32
        %26 = arith.addi %12, %25 : i32
        %27 = arith.index_cast %26 : i32 to index
        %28 = memref.load %5[%arg4] : memref<32xf32, 5>
        %29 = arith.cmpi slt, %26, %arg3 : i32
        %30 = arith.andi %24, %29 : i1
        emitc.if %30 {
          %31 = arith.addi %18, %27 : index
          memref.store %28, %arg2[%31] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] driver.cc: After convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22matrix_multiply_kernelPKfS0_Pfi_0 {
    gpu.func @_Z22matrix_multiply_kernelPKfS0_Pfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %false = arith.constant false
      %cst = arith.constant 0.000000e+00 : f32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %1 = builtin.unrealized_conversion_cast %0 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %2 = "npu.alloca"() <{numElems = 1024 : i32}> : () -> !llvm.ptr<6>
      %3 = builtin.unrealized_conversion_cast %2 : !llvm.ptr<6> to memref<32x32xf32, 5>
      %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %5 = builtin.unrealized_conversion_cast %4 : !llvm.ptr<6> to memref<32xf32, 5>
      scf.for %arg4 = %c0 to %c32 step %c1 {
        memref.store %cst, %5[%arg4] : memref<32xf32, 5>
      }
      %6 = arith.addi %arg3, %c31_i32 : i32
      %7 = arith.divsi %6, %c32_i32 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %10 = arith.index_cast %9 : i64 to index
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.muli %11, %c32_i32 : i32
      %13 = "npu.block_id"() <{dimension = "Y"}> : () -> i64
      %14 = arith.index_cast %13 : i64 to index
      %15 = arith.index_cast %14 : index to i32
      %16 = arith.muli %15, %c32_i32 : i32
      %17 = arith.muli %16, %arg3 : i32
      %18 = arith.index_cast %17 : i32 to index
      %19 = arith.index_cast %16 : i32 to index
      %20 = arith.index_cast %arg3 : i32 to index
      %21 = arith.subi %20, %19 : index
      %22 = arith.addi %21, %c-1 : index
      %23 = arith.cmpi sge, %22, %c0 : index
      scf.for %arg4 = %c0 to %8 step %c1 {
        %25 = arith.index_cast %arg4 : index to i32
        %26 = arith.muli %25, %c32_i32 : i32
        %27 = arith.muli %arg4, %c32 : index
        %28 = arith.addi %27, %18 : index
        %29 = arith.cmpi slt, %26, %arg3 : i32
        %30 = arith.muli %27, %20 : index
        scf.for %arg5 = %c0 to %c32 step %c1 {
          %31 = arith.index_cast %arg5 : index to i32
          %32 = arith.addi %12, %31 : i32
          %33 = arith.index_cast %32 : i32 to index
          %34 = "emitc.variable"() <{value = #emitc.opaque<"">}> : () -> i1
          emitc.if %23 {
            %39 = arith.addi %26, %31 : i32
            %40 = arith.cmpi slt, %39, %arg3 : i32
            emitc.assign %40 : i1 to %34 : i1
          } else {
            emitc.assign %false : i1 to %34 : i1
          }
          emitc.if %34 {
            %39 = arith.addi %28, %arg5 : index
            %40 = memref.load %arg0[%39] : memref<?xf32>
            memref.store %40, %3[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %3[%c0, %arg5] : memref<32x32xf32, 5>
          }
          %35 = arith.subi %20, %33 : index
          %36 = arith.addi %35, %c-1 : index
          %37 = arith.cmpi sge, %36, %c0 : index
          %38 = arith.andi %37, %29 : i1
          emitc.if %38 {
            %39 = arith.addi %30, %33 : index
            %40 = memref.load %arg1[%39] : memref<?xf32>
            memref.store %40, %1[%c0, %arg5] : memref<32x32xf32, 5>
          } else {
            memref.store %cst, %1[%c0, %arg5] : memref<32x32xf32, 5>
          }
        }
        scf.for %arg5 = %c0 to %c32 step %c1 {
          %31 = memref.load %5[%arg5] : memref<32xf32, 5>
          %32 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %31) -> (f32) {
            %33 = memref.load %3[%c0, %arg6] : memref<32x32xf32, 5>
            %34 = memref.load %1[%arg6, %arg5] : memref<32x32xf32, 5>
            %35 = emitc.mul %33, %34 : (f32, f32) -> f32
            %36 = emitc.add %arg7, %35 : (f32, f32) -> f32
            scf.yield %36 : f32
          }
          memref.store %32, %5[%arg5] : memref<32xf32, 5>
        }
      }
      %24 = arith.cmpi slt, %16, %arg3 : i32
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %25 = arith.index_cast %arg4 : index to i32
        %26 = arith.addi %12, %25 : i32
        %27 = arith.index_cast %26 : i32 to index
        %28 = memref.load %5[%arg4] : memref<32xf32, 5>
        %29 = arith.cmpi slt, %26, %arg3 : i32
        %30 = arith.andi %24, %29 : i1
        emitc.if %30 {
          %31 = arith.addi %18, %27 : index
          memref.store %28, %arg2[%31] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] driver.cc: After convert to EmitC dialect: end

[ict-debug] driver.cc: After emitc::translateToCpp:

