warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z30__device_stub__hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z15hardtanh_kernelPKfPfiff(%arg0, %arg1, %arg2, %arg3, %arg4) : (memref<?xf32>, memref<?xf32>, i32, f32, f32) -> ()
    return
  }
  func.func private @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %alloca = memref.alloca() : memref<1xf32>
    %0 = llvm.mlir.undef : f32
    affine.store %0, %alloca[0] : memref<1xf32>
    %alloca_0 = memref.alloca() : memref<1xf32>
    affine.store %0, %alloca_0[0] : memref<1xf32>
    %alloca_1 = memref.alloca() : memref<1xf32>
    %cast = memref.cast %alloca_1 : memref<1xf32> to memref<?xf32>
    affine.store %0, %alloca_1[0] : memref<1xf32>
    affine.store %arg3, %alloca_1[0] : memref<1xf32>
    affine.store %arg4, %alloca_0[0] : memref<1xf32>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.cmpi slt, %8, %arg2 : i32
    scf.if %10 {
      %11 = affine.load %arg0[symbol(%9)] : memref<?xf32>
      affine.store %11, %alloca[0] : memref<1xf32>
      %12 = affine.load %alloca[0] : memref<1xf32>
      %13 = affine.load %alloca_1[0] : memref<1xf32>
      %14 = arith.cmpf olt, %12, %13 : f32
      %15 = scf.if %14 -> (memref<?xf32>) {
        scf.yield %cast : memref<?xf32>
      } else {
        %17 = affine.load %alloca[0] : memref<1xf32>
        %18 = affine.load %alloca_0[0] : memref<1xf32>
        %19 = arith.cmpf ogt, %17, %18 : f32
        %20 = arith.select %19, %alloca_0, %alloca : memref<1xf32>
        %cast_2 = memref.cast %20 : memref<1xf32> to memref<?xf32>
        scf.yield %cast_2 : memref<?xf32>
      }
      %16 = affine.load %15[0] : memref<?xf32>
      affine.store %16, %arg1[symbol(%9)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %alloca = memref.alloca() : memref<1xf32>
    %0 = llvm.mlir.undef : f32
    affine.store %0, %alloca[0] : memref<1xf32>
    %alloca_0 = memref.alloca() : memref<1xf32>
    affine.store %0, %alloca_0[0] : memref<1xf32>
    %alloca_1 = memref.alloca() : memref<1xf32>
    %cast = memref.cast %alloca_1 : memref<1xf32> to memref<?xf32>
    affine.store %0, %alloca_1[0] : memref<1xf32>
    affine.store %arg3, %alloca_1[0] : memref<1xf32>
    affine.store %arg4, %alloca_0[0] : memref<1xf32>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.cmpi slt, %8, %arg2 : i32
    scf.if %10 {
      %11 = affine.load %arg0[symbol(%9)] : memref<?xf32>
      affine.store %11, %alloca[0] : memref<1xf32>
      %12 = affine.load %alloca[0] : memref<1xf32>
      %13 = affine.load %alloca_1[0] : memref<1xf32>
      %14 = arith.cmpf olt, %12, %13 : f32
      %15 = scf.if %14 -> (memref<?xf32>) {
        scf.yield %cast : memref<?xf32>
      } else {
        %17 = affine.load %alloca[0] : memref<1xf32>
        %18 = affine.load %alloca_0[0] : memref<1xf32>
        %19 = arith.cmpf ogt, %17, %18 : f32
        %20 = arith.select %19, %alloca_0, %alloca : memref<1xf32>
        %cast_2 = memref.cast %20 : memref<1xf32> to memref<?xf32>
        scf.yield %cast_2 : memref<?xf32>
      }
      %16 = affine.load %15[0] : memref<?xf32>
      affine.store %16, %arg1[symbol(%9)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %alloca = memref.alloca() : memref<1xf32>
    %0 = llvm.mlir.undef : f32
    memref.store %0, %alloca[%c0] : memref<1xf32>
    %alloca_0 = memref.alloca() : memref<1xf32>
    memref.store %0, %alloca_0[%c0] : memref<1xf32>
    %alloca_1 = memref.alloca() : memref<1xf32>
    %cast = memref.cast %alloca_1 : memref<1xf32> to memref<?xf32>
    memref.store %0, %alloca_1[%c0] : memref<1xf32>
    memref.store %arg3, %alloca_1[%c0] : memref<1xf32>
    memref.store %arg4, %alloca_0[%c0] : memref<1xf32>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.cmpi slt, %8, %arg2 : i32
    scf.if %10 {
      %11 = memref.load %arg0[%9] : memref<?xf32>
      memref.store %11, %alloca[%c0] : memref<1xf32>
      %12 = memref.load %alloca[%c0] : memref<1xf32>
      %13 = memref.load %alloca_1[%c0] : memref<1xf32>
      %14 = arith.cmpf olt, %12, %13 : f32
      %15 = scf.if %14 -> (memref<?xf32>) {
        scf.yield %cast : memref<?xf32>
      } else {
        %17 = memref.load %alloca[%c0] : memref<1xf32>
        %18 = memref.load %alloca_0[%c0] : memref<1xf32>
        %19 = arith.cmpf ogt, %17, %18 : f32
        %20 = arith.select %19, %alloca_0, %alloca : memref<1xf32>
        %cast_2 = memref.cast %20 : memref<1xf32> to memref<?xf32>
        scf.yield %cast_2 : memref<?xf32>
      }
      %16 = memref.load %15[%c0] : memref<?xf32>
      memref.store %16, %arg1[%9] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
      %c0_0 = arith.constant 0 : index
      %alloca = memref.alloca() : memref<1xf32>
      %0 = llvm.mlir.undef : f32
      memref.store %0, %alloca[%c0_0] : memref<1xf32>
      %alloca_1 = memref.alloca() : memref<1xf32>
      memref.store %0, %alloca_1[%c0_0] : memref<1xf32>
      %alloca_2 = memref.alloca() : memref<1xf32>
      %cast = memref.cast %alloca_2 : memref<1xf32> to memref<?xf32>
      memref.store %0, %alloca_2[%c0_0] : memref<1xf32>
      memref.store %arg3, %alloca_2[%c0_0] : memref<1xf32>
      memref.store %arg4, %alloca_1[%c0_0] : memref<1xf32>
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      %6 = arith.index_cast %arg5 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.cmpi slt, %7, %arg2 : i32
      scf.if %9 {
        %10 = memref.load %arg0[%8] : memref<?xf32>
        memref.store %10, %alloca[%c0_0] : memref<1xf32>
        %11 = memref.load %alloca[%c0_0] : memref<1xf32>
        %12 = memref.load %alloca_2[%c0_0] : memref<1xf32>
        %13 = arith.cmpf olt, %11, %12 : f32
        %14 = scf.if %13 -> (memref<?xf32>) {
          scf.yield %cast : memref<?xf32>
        } else {
          %16 = memref.load %alloca[%c0_0] : memref<1xf32>
          %17 = memref.load %alloca_1[%c0_0] : memref<1xf32>
          %18 = arith.cmpf ogt, %16, %17 : f32
          %19 = arith.select %18, %alloca_1, %alloca : memref<1xf32>
          %cast_3 = memref.cast %19 : memref<1xf32> to memref<?xf32>
          scf.yield %cast_3 : memref<?xf32>
        }
        %15 = memref.load %14[%c0_0] : memref<?xf32>
        memref.store %15, %arg1[%8] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
      %c0_0 = arith.constant 0 : index
      %alloca = memref.alloca() : memref<1xf32>
      %0 = llvm.mlir.undef : f32
      memref.store %0, %alloca[%c0_0] : memref<1xf32>
      %alloca_1 = memref.alloca() : memref<1xf32>
      memref.store %0, %alloca_1[%c0_0] : memref<1xf32>
      %alloca_2 = memref.alloca() : memref<1xf32>
      %cast = memref.cast %alloca_2 : memref<1xf32> to memref<?xf32>
      memref.store %0, %alloca_2[%c0_0] : memref<1xf32>
      memref.store %arg3, %alloca_2[%c0_0] : memref<1xf32>
      memref.store %arg4, %alloca_1[%c0_0] : memref<1xf32>
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      %6 = arith.index_cast %arg5 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.cmpi slt, %7, %arg2 : i32
      scf.if %9 {
        %10 = memref.load %arg0[%8] : memref<?xf32>
        memref.store %10, %alloca[%c0_0] : memref<1xf32>
        %11 = memref.load %alloca[%c0_0] : memref<1xf32>
        %12 = memref.load %alloca_2[%c0_0] : memref<1xf32>
        %13 = arith.cmpf olt, %11, %12 : f32
        %14 = scf.if %13 -> (memref<?xf32>) {
          scf.yield %cast : memref<?xf32>
        } else {
          %16 = memref.load %alloca[%c0_0] : memref<1xf32>
          %17 = memref.load %alloca_1[%c0_0] : memref<1xf32>
          %18 = arith.cmpf ogt, %16, %17 : f32
          %19 = arith.select %18, %alloca_1, %alloca : memref<1xf32>
          %cast_3 = memref.cast %19 : memref<1xf32> to memref<?xf32>
          scf.yield %cast_3 : memref<?xf32>
        }
        %15 = memref.load %14[%c0_0] : memref<?xf32>
        memref.store %15, %arg1[%8] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %0 = llvm.mlir.undef : f32
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
      %alloca = memref.alloca() : memref<1xf32>
      memref.store %0, %alloca[%c0] : memref<1xf32>
      %alloca_0 = memref.alloca() : memref<1xf32>
      memref.store %0, %alloca_0[%c0] : memref<1xf32>
      %alloca_1 = memref.alloca() : memref<1xf32>
      %cast = memref.cast %alloca_1 : memref<1xf32> to memref<?xf32>
      memref.store %0, %alloca_1[%c0] : memref<1xf32>
      memref.store %arg3, %alloca_1[%c0] : memref<1xf32>
      memref.store %arg4, %alloca_0[%c0] : memref<1xf32>
      %6 = arith.index_cast %arg5 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.cmpi slt, %7, %arg2 : i32
      scf.if %9 {
        %10 = memref.load %arg0[%8] : memref<?xf32>
        memref.store %10, %alloca[%c0] : memref<1xf32>
        %11 = memref.load %alloca[%c0] : memref<1xf32>
        %12 = memref.load %alloca_1[%c0] : memref<1xf32>
        %13 = arith.cmpf olt, %11, %12 : f32
        %14 = scf.if %13 -> (memref<?xf32>) {
          scf.yield %cast : memref<?xf32>
        } else {
          %16 = memref.load %alloca[%c0] : memref<1xf32>
          %17 = memref.load %alloca_0[%c0] : memref<1xf32>
          %18 = arith.cmpf ogt, %16, %17 : f32
          %19 = arith.select %18, %alloca_0, %alloca : memref<1xf32>
          %cast_2 = memref.cast %19 : memref<1xf32> to memref<?xf32>
          scf.yield %cast_2 : memref<?xf32>
        }
        %15 = memref.load %14[%c0] : memref<?xf32>
        memref.store %15, %arg1[%8] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z15hardtanh_kernelPKfPfiff_0 {
    gpu.func @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) {
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = llvm.mlir.undef : f32
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
        %alloca = memref.alloca() : memref<1xf32>
        memref.store %0, %alloca[%c0] : memref<1xf32>
        %alloca_0 = memref.alloca() : memref<1xf32>
        memref.store %0, %alloca_0[%c0] : memref<1xf32>
        %alloca_1 = memref.alloca() : memref<1xf32>
        %cast = memref.cast %alloca_1 : memref<1xf32> to memref<?xf32>
        memref.store %0, %alloca_1[%c0] : memref<1xf32>
        memref.store %arg3, %alloca_1[%c0] : memref<1xf32>
        memref.store %arg4, %alloca_0[%c0] : memref<1xf32>
        %6 = arith.index_cast %arg5 : index to i32
        %7 = arith.addi %5, %6 : i32
        %8 = arith.index_cast %7 : i32 to index
        %9 = arith.cmpi slt, %7, %arg2 : i32
        scf.if %9 {
          %10 = memref.load %arg0[%8] : memref<?xf32>
          memref.store %10, %alloca[%c0] : memref<1xf32>
          %11 = memref.load %alloca[%c0] : memref<1xf32>
          %12 = memref.load %alloca_1[%c0] : memref<1xf32>
          %13 = arith.cmpf olt, %11, %12 : f32
          %14 = scf.if %13 -> (memref<?xf32>) {
            scf.yield %cast : memref<?xf32>
          } else {
            %16 = memref.load %alloca[%c0] : memref<1xf32>
            %17 = memref.load %alloca_0[%c0] : memref<1xf32>
            %18 = arith.cmpf ogt, %16, %17 : f32
            %19 = arith.select %18, %alloca_0, %alloca : memref<1xf32>
            %cast_2 = memref.cast %19 : memref<1xf32> to memref<?xf32>
            scf.yield %cast_2 : memref<?xf32>
          }
          %15 = memref.load %14[%c0] : memref<?xf32>
          memref.store %15, %arg1[%8] : memref<?xf32>
        }
        scf.yield
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z15hardtanh_kernelPKfPfiff_0 {
    gpu.func @_Z15hardtanh_kernelPKfPfiff(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32) {
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = llvm.mlir.undef : f32
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %c32_0 = arith.constant 32 : index
      %3 = arith.index_cast %c32_0 : index to i32
      %4 = arith.muli %2, %3 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg5 = %c0 to %c32 step %c1_1 {
        %alloca = memref.alloca() : memref<1xf32>
        memref.store %0, %alloca[%c0] : memref<1xf32>
        %alloca_2 = memref.alloca() : memref<1xf32>
        memref.store %0, %alloca_2[%c0] : memref<1xf32>
        %alloca_3 = memref.alloca() : memref<1xf32>
        %cast = memref.cast %alloca_3 : memref<1xf32> to memref<?xf32>
        memref.store %0, %alloca_3[%c0] : memref<1xf32>
        memref.store %arg3, %alloca_3[%c0] : memref<1xf32>
        memref.store %arg4, %alloca_2[%c0] : memref<1xf32>
        %5 = arith.index_cast %arg5 : index to i32
        %6 = arith.addi %4, %5 : i32
        %7 = arith.index_cast %6 : i32 to index
        %8 = arith.cmpi slt, %6, %arg2 : i32
        scf.if %8 {
          %9 = memref.load %arg0[%7] : memref<?xf32>
          memref.store %9, %alloca[%c0] : memref<1xf32>
          %10 = memref.load %alloca[%c0] : memref<1xf32>
          %11 = memref.load %alloca_3[%c0] : memref<1xf32>
          %12 = arith.cmpf olt, %10, %11 : f32
          %13 = scf.if %12 -> (memref<?xf32>) {
            scf.yield %cast : memref<?xf32>
          } else {
            %15 = memref.load %alloca[%c0] : memref<1xf32>
            %16 = memref.load %alloca_2[%c0] : memref<1xf32>
            %17 = arith.cmpf ogt, %15, %16 : f32
            %18 = arith.select %17, %alloca_2, %alloca : memref<1xf32>
            %cast_4 = memref.cast %18 : memref<1xf32> to memref<?xf32>
            scf.yield %cast_4 : memref<?xf32>
          }
          %14 = memref.load %13[%c0] : memref<?xf32>
          memref.store %14, %arg1[%7] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] GPUBlockIdToNPULowering: process op: 

%4 = "gpu.block_id"() <{dimension = #gpu<dim x>}> : () -> index
[ict-debug] MemRefAllocaToNPULowering: process op: 

%11 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%11 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%12 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
MemRefAllocaToNPULowering: module: 
"builtin.module"() ({
  "gpu.module"() ({
    "gpu.func"() <{function_type = (memref<?xf32>, memref<?xf32>, i32, f32, f32) -> ()}> ({
    ^bb0(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32):
      %0 = "arith.constant"() <{value = 0 : index}> : () -> index
      %1 = "arith.constant"() <{value = 1 : index}> : () -> index
      %2 = "arith.constant"() <{value = 32 : index}> : () -> index
      %3 = "llvm.mlir.undef"() : () -> f32
      %4 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %5 = "gpu.block_id"() <{dimension = #gpu<dim x>}> : () -> index
      %6 = "arith.index_cast"(%5) : (index) -> i32
      %7 = "arith.constant"() <{value = 32 : index}> : () -> index
      %8 = "arith.index_cast"(%7) : (index) -> i32
      %9 = "arith.muli"(%6, %8) : (i32, i32) -> i32
      %10 = "arith.constant"() <{value = 1 : index}> : () -> index
      "scf.for"(%0, %2, %10) ({
      ^bb0(%arg5: index):
        %11 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %12 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        "memref.store"(%3, %12, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %13 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        "memref.store"(%3, %13, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %14 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        %15 = "memref.cast"(%14) : (memref<1xf32, 5>) -> memref<?xf32>
        "memref.store"(%3, %14, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg3, %14, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg4, %13, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %16 = "arith.index_cast"(%arg5) : (index) -> i32
        %17 = "arith.addi"(%9, %16) : (i32, i32) -> i32
        %18 = "arith.index_cast"(%17) : (i32) -> index
        %19 = "arith.cmpi"(%17, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
        "scf.if"(%19) ({
          %20 = "memref.load"(%arg0, %18) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%20, %12, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
          %21 = "memref.load"(%12, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %22 = "memref.load"(%14, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %23 = "arith.cmpf"(%21, %22) <{predicate = 4 : i64}> : (f32, f32) -> i1
          %24 = "scf.if"(%23) ({
            "scf.yield"(%15) : (memref<?xf32>) -> ()
          }, {
            %26 = "memref.load"(%12, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %27 = "memref.load"(%13, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %28 = "arith.cmpf"(%26, %27) <{predicate = 2 : i64}> : (f32, f32) -> i1
            %29 = "arith.select"(%28, %13, %12) : (i1, memref<1xf32, 5>, memref<1xf32, 5>) -> memref<1xf32>
            %30 = "memref.cast"(%29) : (memref<1xf32>) -> memref<?xf32>
            "scf.yield"(%30) : (memref<?xf32>) -> ()
          }) : (i1) -> memref<?xf32>
          %25 = "memref.load"(%24, %0) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%25, %arg1, %18) <{nontemporal = false}> : (f32, memref<?xf32>, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "gpu.return"() : () -> ()
    }) {sym_name = "_Z15hardtanh_kernelPKfPfiff", workgroup_attributions = 0 : i64} : () -> ()
    "gpu.module_end"() : () -> ()
  }) {sym_name = "_Z15hardtanh_kernelPKfPfiff_0"} : () -> ()
}) {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} : () -> ()
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%13 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%13 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%14 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
MemRefAllocaToNPULowering: module: 
"builtin.module"() ({
  "gpu.module"() ({
    "gpu.func"() <{function_type = (memref<?xf32>, memref<?xf32>, i32, f32, f32) -> ()}> ({
    ^bb0(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32):
      %0 = "arith.constant"() <{value = 0 : index}> : () -> index
      %1 = "arith.constant"() <{value = 1 : index}> : () -> index
      %2 = "arith.constant"() <{value = 32 : index}> : () -> index
      %3 = "llvm.mlir.undef"() : () -> f32
      %4 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %5 = "gpu.block_id"() <{dimension = #gpu<dim x>}> : () -> index
      %6 = "arith.index_cast"(%5) : (index) -> i32
      %7 = "arith.constant"() <{value = 32 : index}> : () -> index
      %8 = "arith.index_cast"(%7) : (index) -> i32
      %9 = "arith.muli"(%6, %8) : (i32, i32) -> i32
      %10 = "arith.constant"() <{value = 1 : index}> : () -> index
      "scf.for"(%0, %2, %10) ({
      ^bb0(%arg5: index):
        %11 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %12 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        "memref.store"(%3, %12, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %13 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %14 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        "memref.store"(%3, %14, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %15 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        %16 = "memref.cast"(%15) : (memref<1xf32, 5>) -> memref<?xf32>
        "memref.store"(%3, %15, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg3, %15, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg4, %14, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %17 = "arith.index_cast"(%arg5) : (index) -> i32
        %18 = "arith.addi"(%9, %17) : (i32, i32) -> i32
        %19 = "arith.index_cast"(%18) : (i32) -> index
        %20 = "arith.cmpi"(%18, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
        "scf.if"(%20) ({
          %21 = "memref.load"(%arg0, %19) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%21, %12, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
          %22 = "memref.load"(%12, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %23 = "memref.load"(%15, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %24 = "arith.cmpf"(%22, %23) <{predicate = 4 : i64}> : (f32, f32) -> i1
          %25 = "scf.if"(%24) ({
            "scf.yield"(%16) : (memref<?xf32>) -> ()
          }, {
            %27 = "memref.load"(%12, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %28 = "memref.load"(%14, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %29 = "arith.cmpf"(%27, %28) <{predicate = 2 : i64}> : (f32, f32) -> i1
            %30 = "arith.select"(%29, %14, %12) : (i1, memref<1xf32, 5>, memref<1xf32, 5>) -> memref<1xf32>
            %31 = "memref.cast"(%30) : (memref<1xf32>) -> memref<?xf32>
            "scf.yield"(%31) : (memref<?xf32>) -> ()
          }) : (i1) -> memref<?xf32>
          %26 = "memref.load"(%25, %0) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%26, %arg1, %19) <{nontemporal = false}> : (f32, memref<?xf32>, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "gpu.return"() : () -> ()
    }) {sym_name = "_Z15hardtanh_kernelPKfPfiff", workgroup_attributions = 0 : i64} : () -> ()
    "gpu.module_end"() : () -> ()
  }) {sym_name = "_Z15hardtanh_kernelPKfPfiff_0"} : () -> ()
}) {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} : () -> ()
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%15 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%15 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%16 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
MemRefAllocaToNPULowering: module: 
"builtin.module"() ({
  "gpu.module"() ({
    "gpu.func"() <{function_type = (memref<?xf32>, memref<?xf32>, i32, f32, f32) -> ()}> ({
    ^bb0(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32):
      %0 = "arith.constant"() <{value = 0 : index}> : () -> index
      %1 = "arith.constant"() <{value = 1 : index}> : () -> index
      %2 = "arith.constant"() <{value = 32 : index}> : () -> index
      %3 = "llvm.mlir.undef"() : () -> f32
      %4 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %5 = "gpu.block_id"() <{dimension = #gpu<dim x>}> : () -> index
      %6 = "arith.index_cast"(%5) : (index) -> i32
      %7 = "arith.constant"() <{value = 32 : index}> : () -> index
      %8 = "arith.index_cast"(%7) : (index) -> i32
      %9 = "arith.muli"(%6, %8) : (i32, i32) -> i32
      %10 = "arith.constant"() <{value = 1 : index}> : () -> index
      "scf.for"(%0, %2, %10) ({
      ^bb0(%arg5: index):
        %11 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %12 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        "memref.store"(%3, %12, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %13 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %14 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        "memref.store"(%3, %14, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %15 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %16 = "memref.alloca"() <{operandSegmentSizes = array<i32: 0, 0>}> : () -> memref<1xf32, 5>
        %17 = "memref.cast"(%16) : (memref<1xf32, 5>) -> memref<?xf32>
        "memref.store"(%3, %16, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg3, %16, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg4, %14, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %18 = "arith.index_cast"(%arg5) : (index) -> i32
        %19 = "arith.addi"(%9, %18) : (i32, i32) -> i32
        %20 = "arith.index_cast"(%19) : (i32) -> index
        %21 = "arith.cmpi"(%19, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
        "scf.if"(%21) ({
          %22 = "memref.load"(%arg0, %20) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%22, %12, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
          %23 = "memref.load"(%12, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %24 = "memref.load"(%16, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %25 = "arith.cmpf"(%23, %24) <{predicate = 4 : i64}> : (f32, f32) -> i1
          %26 = "scf.if"(%25) ({
            "scf.yield"(%17) : (memref<?xf32>) -> ()
          }, {
            %28 = "memref.load"(%12, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %29 = "memref.load"(%14, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %30 = "arith.cmpf"(%28, %29) <{predicate = 2 : i64}> : (f32, f32) -> i1
            %31 = "arith.select"(%30, %14, %12) : (i1, memref<1xf32, 5>, memref<1xf32, 5>) -> memref<1xf32>
            %32 = "memref.cast"(%31) : (memref<1xf32>) -> memref<?xf32>
            "scf.yield"(%32) : (memref<?xf32>) -> ()
          }) : (i1) -> memref<?xf32>
          %27 = "memref.load"(%26, %0) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%27, %arg1, %20) <{nontemporal = false}> : (f32, memref<?xf32>, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "gpu.return"() : () -> ()
    }) {sym_name = "_Z15hardtanh_kernelPKfPfiff", workgroup_attributions = 0 : i64} : () -> ()
    "gpu.module_end"() : () -> ()
  }) {sym_name = "_Z15hardtanh_kernelPKfPfiff_0"} : () -> ()
}) {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} : () -> ()
MemRefAllocaToNPULowering: module: end
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU:

"builtin.module"() ({
  "gpu.module"() ({
    "gpu.func"() <{function_type = (memref<?xf32>, memref<?xf32>, i32, f32, f32) -> ()}> ({
    ^bb0(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32):
      %0 = "arith.constant"() <{value = 0 : index}> : () -> index
      %1 = "arith.constant"() <{value = 1 : index}> : () -> index
      %2 = "arith.constant"() <{value = 32 : index}> : () -> index
      %3 = "llvm.mlir.undef"() : () -> f32
      %4 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %5 = "arith.index_cast"(%4) : (i64) -> index
      %6 = "builtin.unrealized_conversion_cast"(%4) : (i64) -> index
      %7 = "arith.index_cast"(%5) : (index) -> i32
      %8 = "arith.constant"() <{value = 32 : index}> : () -> index
      %9 = "arith.index_cast"(%8) : (index) -> i32
      %10 = "arith.muli"(%7, %9) : (i32, i32) -> i32
      %11 = "arith.constant"() <{value = 1 : index}> : () -> index
      "scf.for"(%0, %2, %11) ({
      ^bb0(%arg5: index):
        %12 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %13 = "builtin.unrealized_conversion_cast"(%12) : (!llvm.ptr<6>) -> memref<1xf32, 5>
        "memref.store"(%3, %13, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %14 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %15 = "builtin.unrealized_conversion_cast"(%14) : (!llvm.ptr<6>) -> memref<1xf32, 5>
        "memref.store"(%3, %15, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %16 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %17 = "builtin.unrealized_conversion_cast"(%16) : (!llvm.ptr<6>) -> memref<1xf32, 5>
        %18 = "memref.cast"(%17) : (memref<1xf32, 5>) -> memref<?xf32>
        "memref.store"(%3, %17, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg3, %17, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg4, %15, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %19 = "arith.index_cast"(%arg5) : (index) -> i32
        %20 = "arith.addi"(%10, %19) : (i32, i32) -> i32
        %21 = "arith.index_cast"(%20) : (i32) -> index
        %22 = "arith.cmpi"(%20, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
        "scf.if"(%22) ({
          %23 = "memref.load"(%arg0, %21) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%23, %13, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
          %24 = "memref.load"(%13, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %25 = "memref.load"(%17, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %26 = "arith.cmpf"(%24, %25) <{predicate = 4 : i64}> : (f32, f32) -> i1
          %27 = "scf.if"(%26) ({
            "scf.yield"(%18) : (memref<?xf32>) -> ()
          }, {
            %29 = "memref.load"(%13, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %30 = "memref.load"(%15, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %31 = "arith.cmpf"(%29, %30) <{predicate = 2 : i64}> : (f32, f32) -> i1
            %32 = "arith.select"(%31, %15, %13) : (i1, memref<1xf32, 5>, memref<1xf32, 5>) -> memref<1xf32>
            %33 = "memref.cast"(%32) : (memref<1xf32>) -> memref<?xf32>
            "scf.yield"(%33) : (memref<?xf32>) -> ()
          }) : (i1) -> memref<?xf32>
          %28 = "memref.load"(%27, %0) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%28, %arg1, %21) <{nontemporal = false}> : (f32, memref<?xf32>, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "gpu.return"() : () -> ()
    }) {sym_name = "_Z15hardtanh_kernelPKfPfiff", workgroup_attributions = 0 : i64} : () -> ()
    "gpu.module_end"() : () -> ()
  }) {sym_name = "_Z15hardtanh_kernelPKfPfiff_0"} : () -> ()
}) {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} : () -> ()
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU: end

loc("/CUDA2BANG/Cambricon_NaiveProfiling/cuda_ops_test/Ascend_kernels/gen_cuda_kernels/level_1_prlblem_32_sample_0_HardTanh.cu":3:78): error: 'memref.cast' op operand type 'memref<1xf32, 5>' and result type 'memref<?xf32>' are cast incompatible
"builtin.module"() ({
  "gpu.module"() ({
    "gpu.func"() <{function_type = (memref<?xf32>, memref<?xf32>, i32, f32, f32) -> ()}> ({
    ^bb0(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: f32, %arg4: f32):
      %0 = "arith.constant"() <{value = 0 : index}> : () -> index
      %1 = "arith.constant"() <{value = 1 : index}> : () -> index
      %2 = "arith.constant"() <{value = 32 : index}> : () -> index
      %3 = "llvm.mlir.undef"() : () -> f32
      %4 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %5 = "arith.index_cast"(%4) : (i64) -> index
      %6 = "builtin.unrealized_conversion_cast"(%4) : (i64) -> index
      %7 = "arith.index_cast"(%5) : (index) -> i32
      %8 = "arith.constant"() <{value = 32 : index}> : () -> index
      %9 = "arith.index_cast"(%8) : (index) -> i32
      %10 = "arith.muli"(%7, %9) : (i32, i32) -> i32
      %11 = "arith.constant"() <{value = 1 : index}> : () -> index
      "scf.for"(%0, %2, %11) ({
      ^bb0(%arg5: index):
        %12 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %13 = "builtin.unrealized_conversion_cast"(%12) : (!llvm.ptr<6>) -> memref<1xf32, 5>
        "memref.store"(%3, %13, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %14 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %15 = "builtin.unrealized_conversion_cast"(%14) : (!llvm.ptr<6>) -> memref<1xf32, 5>
        "memref.store"(%3, %15, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %16 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %17 = "builtin.unrealized_conversion_cast"(%16) : (!llvm.ptr<6>) -> memref<1xf32, 5>
        %18 = "memref.cast"(%17) : (memref<1xf32, 5>) -> memref<?xf32>
        "memref.store"(%3, %17, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg3, %17, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        "memref.store"(%arg4, %15, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
        %19 = "arith.index_cast"(%arg5) : (index) -> i32
        %20 = "arith.addi"(%10, %19) : (i32, i32) -> i32
        %21 = "arith.index_cast"(%20) : (i32) -> index
        %22 = "arith.cmpi"(%20, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
        "scf.if"(%22) ({
          %23 = "memref.load"(%arg0, %21) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%23, %13, %0) <{nontemporal = false}> : (f32, memref<1xf32, 5>, index) -> ()
          %24 = "memref.load"(%13, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %25 = "memref.load"(%17, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
          %26 = "arith.cmpf"(%24, %25) <{predicate = 4 : i64}> : (f32, f32) -> i1
          %27 = "scf.if"(%26) ({
            "scf.yield"(%18) : (memref<?xf32>) -> ()
          }, {
            %29 = "memref.load"(%13, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %30 = "memref.load"(%15, %0) <{nontemporal = false}> : (memref<1xf32, 5>, index) -> f32
            %31 = "arith.cmpf"(%29, %30) <{predicate = 2 : i64}> : (f32, f32) -> i1
            %32 = "arith.select"(%31, %15, %13) : (i1, memref<1xf32, 5>, memref<1xf32, 5>) -> memref<1xf32>
            %33 = "memref.cast"(%32) : (memref<1xf32>) -> memref<?xf32>
            "scf.yield"(%33) : (memref<?xf32>) -> ()
          }) : (i1) -> memref<?xf32>
          %28 = "memref.load"(%27, %0) <{nontemporal = false}> : (memref<?xf32>, index) -> f32
          "memref.store"(%28, %arg1, %21) <{nontemporal = false}> : (f32, memref<?xf32>, index) -> ()
          "scf.yield"() : () -> ()
        }, {
        }) : (i1) -> ()
        "scf.yield"() : () -> ()
      }) : (index, index, index) -> ()
      "gpu.return"() : () -> ()
    }) {sym_name = "_Z15hardtanh_kernelPKfPfiff", workgroup_attributions = 0 : i64} : () -> ()
    "gpu.module_end"() : () -> ()
  }) {sym_name = "_Z15hardtanh_kernelPKfPfiff_0"} : () -> ()
}) {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} : () -> ()
