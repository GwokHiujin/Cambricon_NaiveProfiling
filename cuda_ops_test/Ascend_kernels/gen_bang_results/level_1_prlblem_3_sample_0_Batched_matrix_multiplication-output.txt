warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z45__device_stub__batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, i32, i32, i32, i32) -> ()
    return
  }
  func.func private @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg6 : i32 to index
    %1 = arith.index_cast %arg5 : i32 to index
    %2 = gpu.block_id  z
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %3, %arg4 : i32
    %5 = arith.muli %4, %arg5 : i32
    %6 = arith.index_cast %5 : i32 to index
    %7 = arith.muli %3, %arg5 : i32
    %8 = arith.muli %7, %arg6 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %3, %arg4 : i32
    %11 = arith.muli %10, %arg6 : i32
    %12 = arith.index_cast %11 : i32 to index
    %13 = gpu.block_id  y
    %14 = arith.index_cast %13 : index to i32
    %15 = gpu.block_dim  y
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.muli %14, %16 : i32
    %18 = gpu.thread_id  y
    %19 = arith.index_cast %18 : index to i32
    %20 = arith.addi %17, %19 : i32
    %21 = arith.muli %20, %arg5 : i32
    %22 = arith.index_cast %21 : i32 to index
    %23 = arith.muli %20, %arg6 : i32
    %24 = arith.index_cast %23 : i32 to index
    %25 = gpu.block_id  x
    %26 = arith.index_cast %25 : index to i32
    %27 = gpu.block_dim  x
    %28 = arith.index_cast %27 : index to i32
    %29 = arith.muli %26, %28 : i32
    %30 = gpu.thread_id  x
    %31 = arith.index_cast %30 : index to i32
    %32 = arith.addi %29, %31 : i32
    %33 = arith.index_cast %32 : i32 to index
    %34 = arith.index_cast %32 : i32 to index
    %35 = arith.cmpi slt, %3, %arg3 : i32
    %36 = arith.cmpi slt, %20, %arg4 : i32
    %37 = arith.cmpi slt, %32, %arg6 : i32
    %38 = arith.andi %36, %37 : i1
    %39 = arith.andi %35, %38 : i1
    scf.if %39 {
      %40 = affine.for %arg7 = 0 to %1 iter_args(%arg8 = %cst) -> (f32) {
        %41 = affine.load %arg0[%arg7 + symbol(%6) + symbol(%22)] : memref<?xf32>
        %42 = affine.load %arg1[%arg7 * symbol(%0) + symbol(%9) + symbol(%33)] : memref<?xf32>
        %43 = arith.mulf %41, %42 : f32
        %44 = arith.addf %arg8, %43 : f32
        affine.yield %44 : f32
      }
      affine.store %40, %arg2[symbol(%12) + symbol(%24) + symbol(%34)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg6 : i32 to index
    %1 = arith.index_cast %arg5 : i32 to index
    %2 = gpu.block_id  z
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %3, %arg4 : i32
    %5 = arith.muli %4, %arg5 : i32
    %6 = arith.index_cast %5 : i32 to index
    %7 = arith.muli %3, %arg5 : i32
    %8 = arith.muli %7, %arg6 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %4, %arg6 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = gpu.block_id  y
    %13 = arith.index_cast %12 : index to i32
    %14 = gpu.block_dim  y
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %13, %15 : i32
    %17 = gpu.thread_id  y
    %18 = arith.index_cast %17 : index to i32
    %19 = arith.addi %16, %18 : i32
    %20 = arith.muli %19, %arg5 : i32
    %21 = arith.index_cast %20 : i32 to index
    %22 = arith.muli %19, %arg6 : i32
    %23 = arith.index_cast %22 : i32 to index
    %24 = gpu.block_id  x
    %25 = arith.index_cast %24 : index to i32
    %26 = gpu.block_dim  x
    %27 = arith.index_cast %26 : index to i32
    %28 = arith.muli %25, %27 : i32
    %29 = gpu.thread_id  x
    %30 = arith.index_cast %29 : index to i32
    %31 = arith.addi %28, %30 : i32
    %32 = arith.index_cast %31 : i32 to index
    %33 = arith.cmpi slt, %3, %arg3 : i32
    %34 = arith.cmpi slt, %19, %arg4 : i32
    %35 = arith.cmpi slt, %31, %arg6 : i32
    %36 = arith.andi %34, %35 : i1
    %37 = arith.andi %33, %36 : i1
    scf.if %37 {
      %38 = affine.for %arg7 = 0 to %1 iter_args(%arg8 = %cst) -> (f32) {
        %39 = affine.load %arg0[%arg7 + symbol(%6) + symbol(%21)] : memref<?xf32>
        %40 = affine.load %arg1[%arg7 * symbol(%0) + symbol(%9) + symbol(%32)] : memref<?xf32>
        %41 = arith.mulf %39, %40 : f32
        %42 = arith.addf %arg8, %41 : f32
        affine.yield %42 : f32
      }
      affine.store %38, %arg2[symbol(%11) + symbol(%23) + symbol(%32)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg6 : i32 to index
    %1 = arith.index_cast %arg5 : i32 to index
    %2 = gpu.block_id  z
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %3, %arg4 : i32
    %5 = arith.muli %4, %arg5 : i32
    %6 = arith.index_cast %5 : i32 to index
    %7 = arith.muli %3, %arg5 : i32
    %8 = arith.muli %7, %arg6 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %4, %arg6 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = gpu.block_id  y
    %13 = arith.index_cast %12 : index to i32
    %14 = gpu.block_dim  y
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %13, %15 : i32
    %17 = gpu.thread_id  y
    %18 = arith.index_cast %17 : index to i32
    %19 = arith.addi %16, %18 : i32
    %20 = arith.muli %19, %arg5 : i32
    %21 = arith.index_cast %20 : i32 to index
    %22 = arith.muli %19, %arg6 : i32
    %23 = arith.index_cast %22 : i32 to index
    %24 = gpu.block_id  x
    %25 = arith.index_cast %24 : index to i32
    %26 = gpu.block_dim  x
    %27 = arith.index_cast %26 : index to i32
    %28 = arith.muli %25, %27 : i32
    %29 = gpu.thread_id  x
    %30 = arith.index_cast %29 : index to i32
    %31 = arith.addi %28, %30 : i32
    %32 = arith.index_cast %31 : i32 to index
    %33 = arith.cmpi slt, %3, %arg3 : i32
    %34 = arith.cmpi slt, %19, %arg4 : i32
    %35 = arith.cmpi slt, %31, %arg6 : i32
    %36 = arith.andi %34, %35 : i1
    %37 = arith.andi %33, %36 : i1
    scf.if %37 {
      %38 = scf.for %arg7 = %c0 to %1 step %c1 iter_args(%arg8 = %cst) -> (f32) {
        %41 = arith.addi %arg7, %6 : index
        %42 = arith.addi %41, %21 : index
        %43 = memref.load %arg0[%42] : memref<?xf32>
        %44 = arith.muli %arg7, %0 : index
        %45 = arith.addi %44, %9 : index
        %46 = arith.addi %45, %32 : index
        %47 = memref.load %arg1[%46] : memref<?xf32>
        %48 = arith.mulf %43, %47 : f32
        %49 = arith.addf %arg8, %48 : f32
        scf.yield %49 : f32
      }
      %39 = arith.addi %11, %23 : index
      %40 = arith.addi %39, %32 : index
      memref.store %38, %arg2[%40] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
      %c1_0 = arith.constant 1 : index
      %0 = arith.divui %arg7, %c1_0 : index
      %c1_1 = arith.constant 1 : index
      %1 = arith.remui %arg7, %c1_1 : index
      %c1_2 = arith.constant 1 : index
      %c0_3 = arith.constant 0 : index
      %cst = arith.constant 0.000000e+00 : f32
      %2 = arith.index_cast %arg6 : i32 to index
      %3 = arith.index_cast %arg5 : i32 to index
      %4 = gpu.block_id  z
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.muli %5, %arg4 : i32
      %7 = arith.muli %6, %arg5 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.muli %5, %arg5 : i32
      %10 = arith.muli %9, %arg6 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.muli %6, %arg6 : i32
      %13 = arith.index_cast %12 : i32 to index
      %14 = gpu.block_id  y
      %15 = arith.index_cast %14 : index to i32
      %16 = gpu.block_dim  y
      %17 = arith.index_cast %16 : index to i32
      %18 = arith.muli %15, %17 : i32
      %19 = arith.index_cast %1 : index to i32
      %20 = arith.addi %18, %19 : i32
      %21 = arith.muli %20, %arg5 : i32
      %22 = arith.index_cast %21 : i32 to index
      %23 = arith.muli %20, %arg6 : i32
      %24 = arith.index_cast %23 : i32 to index
      %25 = gpu.block_id  x
      %26 = arith.index_cast %25 : index to i32
      %27 = gpu.block_dim  x
      %28 = arith.index_cast %27 : index to i32
      %29 = arith.muli %26, %28 : i32
      %30 = arith.index_cast %0 : index to i32
      %31 = arith.addi %29, %30 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.cmpi slt, %5, %arg3 : i32
      %34 = arith.cmpi slt, %20, %arg4 : i32
      %35 = arith.cmpi slt, %31, %arg6 : i32
      %36 = arith.andi %34, %35 : i1
      %37 = arith.andi %33, %36 : i1
      scf.if %37 {
        %38 = scf.for %arg8 = %c0_3 to %3 step %c1_2 iter_args(%arg9 = %cst) -> (f32) {
          %41 = arith.addi %arg8, %8 : index
          %42 = arith.addi %41, %22 : index
          %43 = memref.load %arg0[%42] : memref<?xf32>
          %44 = arith.muli %arg8, %2 : index
          %45 = arith.addi %44, %11 : index
          %46 = arith.addi %45, %32 : index
          %47 = memref.load %arg1[%46] : memref<?xf32>
          %48 = arith.mulf %43, %47 : f32
          %49 = arith.addf %arg9, %48 : f32
          scf.yield %49 : f32
        }
        %39 = arith.addi %13, %24 : index
        %40 = arith.addi %39, %32 : index
        memref.store %38, %arg2[%40] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
      %c1_0 = arith.constant 1 : index
      %0 = arith.divui %arg7, %c1_0 : index
      %c1_1 = arith.constant 1 : index
      %1 = arith.remui %arg7, %c1_1 : index
      %c1_2 = arith.constant 1 : index
      %c0_3 = arith.constant 0 : index
      %cst = arith.constant 0.000000e+00 : f32
      %2 = arith.index_cast %arg6 : i32 to index
      %3 = arith.index_cast %arg5 : i32 to index
      %4 = gpu.block_id  z
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.muli %5, %arg4 : i32
      %7 = arith.muli %6, %arg5 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.muli %5, %arg5 : i32
      %10 = arith.muli %9, %arg6 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.muli %6, %arg6 : i32
      %13 = arith.index_cast %12 : i32 to index
      %14 = gpu.block_id  y
      %15 = arith.index_cast %14 : index to i32
      %16 = gpu.block_dim  y
      %17 = arith.index_cast %16 : index to i32
      %18 = arith.muli %15, %17 : i32
      %19 = arith.index_cast %1 : index to i32
      %20 = arith.addi %18, %19 : i32
      %21 = arith.muli %20, %arg5 : i32
      %22 = arith.index_cast %21 : i32 to index
      %23 = arith.muli %20, %arg6 : i32
      %24 = arith.index_cast %23 : i32 to index
      %25 = gpu.block_id  x
      %26 = arith.index_cast %25 : index to i32
      %27 = gpu.block_dim  x
      %28 = arith.index_cast %27 : index to i32
      %29 = arith.muli %26, %28 : i32
      %30 = arith.index_cast %0 : index to i32
      %31 = arith.addi %29, %30 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.cmpi slt, %5, %arg3 : i32
      %34 = arith.cmpi slt, %20, %arg4 : i32
      %35 = arith.cmpi slt, %31, %arg6 : i32
      %36 = arith.andi %34, %35 : i1
      %37 = arith.andi %33, %36 : i1
      scf.if %37 {
        %38 = scf.for %arg8 = %c0_3 to %3 step %c1_2 iter_args(%arg9 = %cst) -> (f32) {
          %41 = arith.addi %arg8, %8 : index
          %42 = arith.addi %41, %22 : index
          %43 = memref.load %arg0[%42] : memref<?xf32>
          %44 = arith.muli %arg8, %2 : index
          %45 = arith.addi %44, %11 : index
          %46 = arith.addi %45, %32 : index
          %47 = memref.load %arg1[%46] : memref<?xf32>
          %48 = arith.mulf %43, %47 : f32
          %49 = arith.addf %arg9, %48 : f32
          scf.yield %49 : f32
        }
        %39 = arith.addi %13, %24 : index
        %40 = arith.addi %39, %32 : index
        memref.store %38, %arg2[%40] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %0 = arith.index_cast %arg6 : i32 to index
    %1 = arith.index_cast %arg5 : i32 to index
    %2 = gpu.block_id  z
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %3, %arg4 : i32
    %5 = arith.muli %4, %arg5 : i32
    %6 = arith.index_cast %5 : i32 to index
    %7 = arith.muli %3, %arg5 : i32
    %8 = arith.muli %7, %arg6 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %4, %arg6 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = gpu.block_id  y
    %13 = arith.index_cast %12 : index to i32
    %14 = gpu.block_dim  y
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %13, %15 : i32
    %17 = arith.muli %16, %arg5 : i32
    %18 = arith.index_cast %17 : i32 to index
    %19 = arith.muli %16, %arg6 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = gpu.block_id  x
    %22 = arith.index_cast %21 : index to i32
    %23 = gpu.block_dim  x
    %24 = arith.index_cast %23 : index to i32
    %25 = arith.muli %22, %24 : i32
    %26 = arith.cmpi slt, %3, %arg3 : i32
    %27 = arith.cmpi slt, %16, %arg4 : i32
    %28 = arith.addi %11, %20 : index
    scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
      %29 = arith.index_cast %arg7 : index to i32
      %30 = arith.addi %25, %29 : i32
      %31 = arith.index_cast %30 : i32 to index
      %32 = arith.cmpi slt, %30, %arg6 : i32
      %33 = arith.andi %27, %32 : i1
      %34 = arith.andi %26, %33 : i1
      scf.if %34 {
        %35 = scf.for %arg8 = %c0 to %1 step %c1 iter_args(%arg9 = %cst) -> (f32) {
          %37 = arith.addi %arg8, %6 : index
          %38 = arith.addi %37, %18 : index
          %39 = memref.load %arg0[%38] : memref<?xf32>
          %40 = arith.muli %arg8, %0 : index
          %41 = arith.addi %40, %9 : index
          %42 = arith.addi %41, %31 : index
          %43 = memref.load %arg1[%42] : memref<?xf32>
          %44 = arith.mulf %39, %43 : f32
          %45 = arith.addf %arg9, %44 : f32
          scf.yield %45 : f32
        }
        %36 = arith.addi %28, %31 : index
        memref.store %35, %arg2[%36] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii_0 {
    gpu.func @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = arith.index_cast %arg6 : i32 to index
      %1 = arith.index_cast %arg5 : i32 to index
      %2 = gpu.block_id  z
      %3 = arith.index_cast %2 : index to i32
      %4 = arith.muli %3, %arg4 : i32
      %5 = arith.muli %4, %arg5 : i32
      %6 = arith.index_cast %5 : i32 to index
      %7 = arith.muli %3, %arg5 : i32
      %8 = arith.muli %7, %arg6 : i32
      %9 = arith.index_cast %8 : i32 to index
      %10 = arith.muli %4, %arg6 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = gpu.block_id  y
      %13 = arith.index_cast %12 : index to i32
      %14 = gpu.block_dim  y
      %15 = arith.index_cast %14 : index to i32
      %16 = arith.muli %13, %15 : i32
      %17 = arith.muli %16, %arg5 : i32
      %18 = arith.index_cast %17 : i32 to index
      %19 = arith.muli %16, %arg6 : i32
      %20 = arith.index_cast %19 : i32 to index
      %21 = gpu.block_id  x
      %22 = arith.index_cast %21 : index to i32
      %23 = gpu.block_dim  x
      %24 = arith.index_cast %23 : index to i32
      %25 = arith.muli %22, %24 : i32
      %26 = arith.cmpi slt, %3, %arg3 : i32
      %27 = arith.cmpi slt, %16, %arg4 : i32
      %28 = arith.addi %11, %20 : index
      scf.parallel (%arg7) = (%c0) to (%c32) step (%c1) {
        %29 = arith.index_cast %arg7 : index to i32
        %30 = arith.addi %25, %29 : i32
        %31 = arith.index_cast %30 : i32 to index
        %32 = arith.cmpi slt, %30, %arg6 : i32
        %33 = arith.andi %27, %32 : i1
        %34 = arith.andi %26, %33 : i1
        scf.if %34 {
          %35 = scf.for %arg8 = %c0 to %1 step %c1 iter_args(%arg9 = %cst) -> (f32) {
            %37 = arith.addi %arg8, %6 : index
            %38 = arith.addi %37, %18 : index
            %39 = memref.load %arg0[%38] : memref<?xf32>
            %40 = arith.muli %arg8, %0 : index
            %41 = arith.addi %40, %9 : index
            %42 = arith.addi %41, %31 : index
            %43 = memref.load %arg1[%42] : memref<?xf32>
            %44 = arith.mulf %39, %43 : f32
            %45 = arith.addf %arg9, %44 : f32
            scf.yield %45 : f32
          }
          %36 = arith.addi %28, %31 : index
          memref.store %35, %arg2[%36] : memref<?xf32>
        }
        scf.yield
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii_0 {
    gpu.func @_Z30batched_matrix_multiply_kernelPKfS0_Pfiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = arith.index_cast %arg6 : i32 to index
      %1 = arith.index_cast %arg5 : i32 to index
      %2 = gpu.block_id  z
      %3 = arith.index_cast %2 : index to i32
      %4 = arith.muli %3, %arg4 : i32
      %5 = arith.muli %4, %arg5 : i32
      %6 = arith.index_cast %5 : i32 to index
      %7 = arith.muli %3, %arg5 : i32
      %8 = arith.muli %7, %arg6 : i32
      %9 = arith.index_cast %8 : i32 to index
      %10 = arith.muli %4, %arg6 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = gpu.block_id  y
      %13 = arith.index_cast %12 : index to i32
      %14 = gpu.block_dim  y
      %15 = arith.index_cast %14 : index to i32
      %16 = arith.muli %13, %15 : i32
      %17 = arith.muli %16, %arg5 : i32
      %18 = arith.index_cast %17 : i32 to index
      %19 = arith.muli %16, %arg6 : i32
      %20 = arith.index_cast %19 : i32 to index
      %21 = gpu.block_id  x
      %22 = arith.index_cast %21 : index to i32
      %c32_0 = arith.constant 32 : index
      %23 = arith.index_cast %c32_0 : index to i32
      %24 = arith.muli %22, %23 : i32
      %25 = arith.cmpi slt, %3, %arg3 : i32
      %26 = arith.cmpi slt, %16, %arg4 : i32
      %27 = arith.addi %11, %20 : index
      %c1_1 = arith.constant 1 : index
      scf.for %arg7 = %c0 to %c32 step %c1_1 {
        %28 = arith.index_cast %arg7 : index to i32
        %29 = arith.addi %24, %28 : i32
        %30 = arith.index_cast %29 : i32 to index
        %31 = arith.cmpi slt, %29, %arg6 : i32
        %32 = arith.andi %26, %31 : i1
        %33 = arith.andi %25, %32 : i1
        scf.if %33 {
          %34 = scf.for %arg8 = %c0 to %1 step %c1 iter_args(%arg9 = %cst) -> (f32) {
            %36 = arith.addi %arg8, %6 : index
            %37 = arith.addi %36, %18 : index
            %38 = memref.load %arg0[%37] : memref<?xf32>
            %39 = arith.muli %arg8, %0 : index
            %40 = arith.addi %39, %9 : index
            %41 = arith.addi %40, %30 : index
            %42 = memref.load %arg1[%41] : memref<?xf32>
            %43 = arith.mulf %38, %42 : f32
            %44 = arith.addf %arg9, %43 : f32
            scf.yield %44 : f32
          }
          %35 = arith.addi %27, %30 : index
          memref.store %34, %arg2[%35] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] GPUBlockIdToNPULowering: process op: 

%2 = gpu.block_id  z
cgeist: /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/VectorToNPU.cpp:772: virtual mlir::LogicalResult GPUBlockIdToNPULowering::matchAndRewrite(mlir::gpu::BlockIdOp, mlir::OpConversionPattern<mlir::gpu::BlockIdOp>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `blockIdOp.getDimension() == gpu::Dimension::y' failed.
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist --function=* -cuda-lower -output-intermediate-gpu -scal-rep=0 -raise-scf-to-affine --cuda-gpu-arch=sm_70 -parallel-licm=1 -gpu-kernel-structure-mode=block_thread_noops --enable-buffer-elim=0 -O2 -I /CUDA2BANG/cuda2bang/polygeist/mlir-build/projects/openmp/runtime/src/ -resource-dir=/CUDA2BANG/cuda2bang/polygeist/mlir-build/lib/clang/18/ -I /CUDA2BANG/cuda2bang/polygeist/mlir-build/projects/openmp/runtime/src/ -I /usr/local/cuda/include/ -use-original-gpu-block-size --emit-npu=distribute.mincut -use-my-pass -bang-dump-file=/CUDA2BANG/Cambricon_NaiveProfiling/cuda_ops_test/Ascend_kernels/gen_bang_results/level_1_prlblem_3_sample_0_Batched_matrix_multiplication.mlu /CUDA2BANG/Cambricon_NaiveProfiling/cuda_ops_test/Ascend_kernels/gen_cuda_kernels/level_1_prlblem_3_sample_0_Batched_matrix_multiplication.cu -o level_1_prlblem_3_sample_0_Batched_matrix_multiplication.o
 #0 0x0000564cd7279bcf llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x3391bcf)
 #1 0x0000564cd72773b4 SignalHandler(int) Signals.cpp:0:0
 #2 0x00007f36a408a420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #3 0x00007f36a3a0f00b raise /build/glibc-SzIz7B/glibc-2.31/signal/../sysdeps/unix/sysv/linux/raise.c:51:1
 #4 0x00007f36a39ee859 abort /build/glibc-SzIz7B/glibc-2.31/stdlib/abort.c:81:7
 #5 0x00007f36a39ee729 get_sysdep_segment_value /build/glibc-SzIz7B/glibc-2.31/intl/loadmsgcat.c:509:8
 #6 0x00007f36a39ee729 _nl_load_domain /build/glibc-SzIz7B/glibc-2.31/intl/loadmsgcat.c:970:34
 #7 0x00007f36a39fffd6 (/lib/x86_64-linux-gnu/libc.so.6+0x33fd6)
 #8 0x0000564cd7f5e40c GPUBlockIdToNPULowering::matchAndRewrite(mlir::gpu::BlockIdOp, mlir::gpu::BlockIdOpAdaptor, mlir::ConversionPatternRewriter&) const /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/VectorToNPU.cpp:773:88
 #9 0x0000564cd7f7d50b mlir::OpConversionPattern<mlir::gpu::BlockIdOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/Transforms/DialectConversion.h:536:77
#10 0x0000564cd80f10a9 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x42090a9)
#11 0x0000564cdb2f2572 mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<mlir::LogicalResult (mlir::Pattern const&)>) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x740a572)
#12 0x0000564cd80ff6bb (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#13 0x0000564cd80ffb9f (anonymous namespace)::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>, llvm::function_ref<void (mlir::Diagnostic&)>) DialectConversion.cpp:0:0
#14 0x0000564cd81003b4 mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, llvm::DenseSet<mlir::Operation*, llvm::DenseMapInfo<mlir::Operation*, void>>*) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x42183b4)
#15 0x0000564cd7f4aa32 (anonymous namespace)::ConvertPolygeistToNPUPass::runOnOperation()::'lambda1'(mlir::gpu::GPUFuncOp)::operator()(mlir::gpu::GPUFuncOp) const /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/ConvertPolygeistToNPU.cpp:1396:17
#16 0x0000564cd7f4da71 _ZZN4mlir6detail4walkILNS_9WalkOrderE1ENS_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS_3gpu9GPUFuncOpEE1_S7_vEENSt9enable_ifIXaantsrSt11disjunctionIJSt7is_sameIT2_PNS_9OperationEESB_ISC_PNS_6RegionEESB_ISC_PNS_5BlockEEEE5valuesrSB_IT3_vE5valueESN_E4typeESE_OT1_ENKUlSE_E_clESE_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:337:20
#17 0x0000564cd7f5159a _ZN4llvm12function_refIFvPN4mlir9OperationEEE11callback_fnIZNS1_6detail4walkILNS1_9WalkOrderE1ENS1_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS1_3gpu9GPUFuncOpEE1_SE_vEENSt9enable_ifIXaantsrSt11disjunctionIJSt7is_sameIT2_S3_ESI_ISJ_PNS1_6RegionEESI_ISJ_PNS1_5BlockEEEE5valuesrSI_IT3_vE5valueESS_E4typeES3_OT1_EUlS3_E_EEvlS3_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:46:40
#18 0x0000564cd4a108bf llvm::function_ref<void (mlir::Operation*)>::operator()(mlir::Operation*) const /CUDA2BANG/cuda2bang/polygeist/llvm-project/llvm/include/llvm/ADT/STLFunctionalExtras.h:68:62
#19 0x0000564cd49f627a void mlir::detail::walk<mlir::ForwardIterator>(mlir::Operation*, llvm::function_ref<void (mlir::Operation*)>, mlir::WalkOrder) /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:188:1
#20 0x0000564cd49f622c void mlir::detail::walk<mlir::ForwardIterator>(mlir::Operation*, llvm::function_ref<void (mlir::Operation*)>, mlir::WalkOrder) /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:180:7
#21 0x0000564cd49f622c void mlir::detail::walk<mlir::ForwardIterator>(mlir::Operation*, llvm::function_ref<void (mlir::Operation*)>, mlir::WalkOrder) /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:180:7
#22 0x0000564cd7f4dae6 _ZN4mlir6detail4walkILNS_9WalkOrderE1ENS_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS_3gpu9GPUFuncOpEE1_S7_vEENSt9enable_ifIXaantsrSt11disjunctionIJSt7is_sameIT2_PNS_9OperationEESB_ISC_PNS_6RegionEESB_ISC_PNS_5BlockEEEE5valuesrSB_IT3_vE5valueESN_E4typeESE_OT1_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Visitors.h:342:38
#23 0x0000564cd7f4c380 _ZN4mlir9Operation4walkILNS_9WalkOrderE1ENS_15ForwardIteratorEZN12_GLOBAL__N_125ConvertPolygeistToNPUPass14runOnOperationEvEUlNS_3gpu9GPUFuncOpEE1_vEENSt9enable_ifIXeqsrN4llvm15function_traitsINSt5decayIT1_E4typeEXsrSt8is_classISF_E5valueEEE8num_argsLi1EET2_E4typeEOSD_ /CUDA2BANG/cuda2bang/polygeist/llvm-project/mlir/include/mlir/IR/Operation.h:777:75
#24 0x0000564cd7f4ae6b (anonymous namespace)::ConvertPolygeistToNPUPass::runOnOperation() /CUDA2BANG/cuda2bang/polygeist/lib/polygeist/Passes/ConvertPolygeistToNPU.cpp:1407:16
#25 0x0000564cd80d0d21 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x41e8d21)
#26 0x0000564cd80d12a1 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x41e92a1)
#27 0x0000564cd80d1e1e mlir::PassManager::run(mlir::Operation*) (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0x41e9e1e)
#28 0x0000564cd4947c5a main /CUDA2BANG/cuda2bang/polygeist/tools/cgeist/driver.cc:1039:0
#29 0x00007f36a39f0083 __libc_start_main /build/glibc-SzIz7B/glibc-2.31/csu/../csu/libc-start.c:342:3
#30 0x0000564cd491684e _start (/CUDA2BANG/cuda2bang/polygeist/build/bin/cgeist+0xa2e84e)
