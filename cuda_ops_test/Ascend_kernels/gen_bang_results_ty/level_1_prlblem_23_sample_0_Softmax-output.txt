warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z35__device_stub__softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z20softmax_kernel_batchPKfPfii(%arg0, %arg1, %arg2, %arg3) : (memref<?xf32>, memref<?xf32>, i32, i32) -> ()
    return
  }
  func.func private @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c2_i32 = arith.constant 2 : i32
    %cst_0 = arith.constant -3.40282347E+38 : f32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.block_id  x
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.cmpi slt, %1, %arg2 : i32
    scf.if %2 {
      %3 = gpu.block_dim  x
      %4 = gpu.thread_id  x
      %5 = arith.muli %1, %arg3 : i32
      %6 = gpu.block_dim  x
      %7 = arith.index_cast %arg3 : i32 to index
      %8 = scf.for %arg4 = %4 to %7 step %6 iter_args(%arg5 = %cst_0) -> (f32) {
        %42 = arith.subi %arg4, %4 : index
        %43 = arith.divui %42, %6 : index
        %44 = arith.muli %43, %6 : index
        %45 = arith.addi %4, %44 : index
        %46 = arith.index_cast %45 : index to i32
        %47 = arith.addi %5, %46 : i32
        %48 = arith.index_cast %47 : i32 to index
        %49 = memref.load %arg0[%48] : memref<?xf32>
        %50 = arith.cmpf ogt, %49, %arg5 : f32
        %51 = arith.select %50, %49, %arg5 : f32
        scf.yield %51 : f32
      }
      %9 = gpu.thread_id  x
      memref.store %8, %alloca[%9] : memref<1xf32, 5>
      nvvm.barrier0
      %10 = gpu.block_dim  x
      %11 = arith.index_cast %10 : index to i32
      %12 = arith.divui %11, %c2_i32 : i32
      %13 = math.ctlz %12 : i32
      %14 = arith.index_cast %13 : i32 to index
      %15 = arith.subi %c32, %14 : index
      %16 = arith.divui %11, %c2_i32 : i32
      %17 = gpu.thread_id  x
      %18 = arith.index_cast %17 : index to i32
      scf.for %arg4 = %c0 to %15 step %c1 {
        %42 = arith.index_cast %arg4 : index to i32
        %43 = arith.shrui %16, %42 : i32
        %44 = arith.cmpi ult, %18, %43 : i32
        scf.if %44 {
          %45 = memref.load %alloca[%17] : memref<1xf32, 5>
          %46 = arith.addi %18, %43 : i32
          %47 = arith.index_cast %46 : i32 to index
          %48 = memref.load %alloca[%47] : memref<1xf32, 5>
          %49 = arith.cmpf olt, %45, %48 : f32
          scf.if %49 {
            memref.store %48, %alloca[%17] : memref<1xf32, 5>
          }
        }
        nvvm.barrier0
      }
      %19 = affine.load %alloca[0] : memref<1xf32, 5>
      nvvm.barrier0
      %20 = arith.muli %1, %arg3 : i32
      %21 = arith.muli %1, %arg3 : i32
      %22 = gpu.block_dim  x
      %23 = arith.index_cast %arg3 : i32 to index
      %24 = scf.for %arg4 = %4 to %23 step %22 iter_args(%arg5 = %cst) -> (f32) {
        %42 = arith.subi %arg4, %4 : index
        %43 = arith.divui %42, %22 : index
        %44 = arith.muli %43, %22 : index
        %45 = arith.addi %4, %44 : index
        %46 = arith.index_cast %45 : index to i32
        %47 = arith.addi %20, %46 : i32
        %48 = arith.index_cast %47 : i32 to index
        %49 = memref.load %arg0[%48] : memref<?xf32>
        %50 = arith.subf %49, %19 : f32
        %51 = math.exp %50 : f32
        %52 = arith.addi %21, %46 : i32
        %53 = arith.index_cast %52 : i32 to index
        memref.store %51, %arg1[%53] : memref<?xf32>
        %54 = arith.addf %arg5, %51 : f32
        scf.yield %54 : f32
      }
      %25 = gpu.thread_id  x
      %26 = arith.addi %25, %3 : index
      memref.store %24, %alloca[%26] : memref<1xf32, 5>
      nvvm.barrier0
      %27 = gpu.block_dim  x
      %28 = arith.index_cast %27 : index to i32
      %29 = arith.divui %28, %c2_i32 : i32
      %30 = math.ctlz %29 : i32
      %31 = arith.index_cast %30 : i32 to index
      %32 = arith.subi %c32, %31 : index
      %33 = arith.divui %28, %c2_i32 : i32
      %34 = gpu.thread_id  x
      %35 = arith.index_cast %34 : index to i32
      %36 = arith.addi %34, %3 : index
      %37 = arith.addi %34, %3 : index
      scf.for %arg4 = %c0 to %32 step %c1 {
        %42 = arith.index_cast %arg4 : index to i32
        %43 = arith.shrui %33, %42 : i32
        %44 = arith.cmpi ult, %35, %43 : i32
        scf.if %44 {
          %45 = arith.addi %35, %43 : i32
          %46 = arith.index_cast %45 : i32 to index
          %47 = arith.addi %46, %3 : index
          %48 = memref.load %alloca[%47] : memref<1xf32, 5>
          %49 = memref.load %alloca[%36] : memref<1xf32, 5>
          %50 = arith.addf %49, %48 : f32
          memref.store %50, %alloca[%37] : memref<1xf32, 5>
        }
        nvvm.barrier0
      }
      %38 = memref.load %alloca[%3] : memref<1xf32, 5>
      nvvm.barrier0
      %39 = arith.muli %1, %arg3 : i32
      %40 = gpu.block_dim  x
      %41 = arith.index_cast %arg3 : i32 to index
      scf.for %arg4 = %4 to %41 step %40 {
        %42 = arith.subi %arg4, %4 : index
        %43 = arith.divui %42, %40 : index
        %44 = arith.muli %43, %40 : index
        %45 = arith.addi %4, %44 : index
        %46 = arith.index_cast %45 : index to i32
        %47 = arith.addi %39, %46 : i32
        %48 = arith.index_cast %47 : i32 to index
        %49 = memref.load %arg1[%48] : memref<?xf32>
        %50 = arith.divf %49, %38 : f32
        memref.store %50, %arg1[%48] : memref<?xf32>
      }
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c2_i32 = arith.constant 2 : i32
    %cst_0 = arith.constant -3.40282347E+38 : f32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.block_id  x
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.cmpi slt, %1, %arg2 : i32
    scf.if %2 {
      %3 = gpu.block_dim  x
      %4 = gpu.thread_id  x
      %5 = arith.muli %1, %arg3 : i32
      %6 = arith.index_cast %arg3 : i32 to index
      %7 = scf.for %arg4 = %4 to %6 step %3 iter_args(%arg5 = %cst_0) -> (f32) {
        %18 = arith.subi %arg4, %4 : index
        %19 = arith.divui %18, %3 : index
        %20 = arith.muli %19, %3 : index
        %21 = arith.addi %4, %20 : index
        %22 = arith.index_cast %21 : index to i32
        %23 = arith.addi %5, %22 : i32
        %24 = arith.index_cast %23 : i32 to index
        %25 = memref.load %arg0[%24] : memref<?xf32>
        %26 = arith.cmpf ogt, %25, %arg5 : f32
        %27 = arith.select %26, %25, %arg5 : f32
        scf.yield %27 : f32
      }
      memref.store %7, %alloca[%4] : memref<1xf32, 5>
      nvvm.barrier0
      %8 = arith.index_cast %3 : index to i32
      %9 = arith.divui %8, %c2_i32 : i32
      %10 = math.ctlz %9 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.subi %c32, %11 : index
      %13 = arith.index_cast %4 : index to i32
      scf.for %arg4 = %c0 to %12 step %c1 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.shrui %9, %18 : i32
        %20 = arith.cmpi ult, %13, %19 : i32
        scf.if %20 {
          %21 = memref.load %alloca[%4] : memref<1xf32, 5>
          %22 = arith.addi %13, %19 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %alloca[%23] : memref<1xf32, 5>
          %25 = arith.cmpf olt, %21, %24 : f32
          scf.if %25 {
            memref.store %24, %alloca[%4] : memref<1xf32, 5>
          }
        }
        nvvm.barrier0
      }
      %14 = affine.load %alloca[0] : memref<1xf32, 5>
      nvvm.barrier0
      %15 = scf.for %arg4 = %4 to %6 step %3 iter_args(%arg5 = %cst) -> (f32) {
        %18 = arith.subi %arg4, %4 : index
        %19 = arith.divui %18, %3 : index
        %20 = arith.muli %19, %3 : index
        %21 = arith.addi %4, %20 : index
        %22 = arith.index_cast %21 : index to i32
        %23 = arith.addi %5, %22 : i32
        %24 = arith.index_cast %23 : i32 to index
        %25 = memref.load %arg0[%24] : memref<?xf32>
        %26 = arith.subf %25, %14 : f32
        %27 = math.exp %26 : f32
        memref.store %27, %arg1[%24] : memref<?xf32>
        %28 = arith.addf %arg5, %27 : f32
        scf.yield %28 : f32
      }
      %16 = arith.addi %4, %3 : index
      memref.store %15, %alloca[%16] : memref<1xf32, 5>
      nvvm.barrier0
      scf.for %arg4 = %c0 to %12 step %c1 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.shrui %9, %18 : i32
        %20 = arith.cmpi ult, %13, %19 : i32
        scf.if %20 {
          %21 = arith.addi %13, %19 : i32
          %22 = arith.index_cast %21 : i32 to index
          %23 = arith.addi %22, %3 : index
          %24 = memref.load %alloca[%23] : memref<1xf32, 5>
          %25 = memref.load %alloca[%16] : memref<1xf32, 5>
          %26 = arith.addf %25, %24 : f32
          memref.store %26, %alloca[%16] : memref<1xf32, 5>
        }
        nvvm.barrier0
      }
      %17 = memref.load %alloca[%3] : memref<1xf32, 5>
      nvvm.barrier0
      scf.for %arg4 = %4 to %6 step %3 {
        %18 = arith.subi %arg4, %4 : index
        %19 = arith.divui %18, %3 : index
        %20 = arith.muli %19, %3 : index
        %21 = arith.addi %4, %20 : index
        %22 = arith.index_cast %21 : index to i32
        %23 = arith.addi %5, %22 : i32
        %24 = arith.index_cast %23 : i32 to index
        %25 = memref.load %arg1[%24] : memref<?xf32>
        %26 = arith.divf %25, %17 : f32
        memref.store %26, %arg1[%24] : memref<?xf32>
      }
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c2_i32 = arith.constant 2 : i32
    %cst_0 = arith.constant -3.40282347E+38 : f32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.block_id  x
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.cmpi slt, %1, %arg2 : i32
    scf.if %2 {
      %3 = gpu.block_dim  x
      %4 = gpu.thread_id  x
      %5 = arith.muli %1, %arg3 : i32
      %6 = arith.index_cast %arg3 : i32 to index
      %7 = scf.for %arg4 = %4 to %6 step %3 iter_args(%arg5 = %cst_0) -> (f32) {
        %18 = arith.subi %arg4, %4 : index
        %19 = arith.divui %18, %3 : index
        %20 = arith.muli %19, %3 : index
        %21 = arith.addi %4, %20 : index
        %22 = arith.index_cast %21 : index to i32
        %23 = arith.addi %5, %22 : i32
        %24 = arith.index_cast %23 : i32 to index
        %25 = memref.load %arg0[%24] : memref<?xf32>
        %26 = arith.cmpf ogt, %25, %arg5 : f32
        %27 = arith.select %26, %25, %arg5 : f32
        scf.yield %27 : f32
      }
      memref.store %7, %alloca[%4] : memref<1xf32, 5>
      nvvm.barrier0
      %8 = arith.index_cast %3 : index to i32
      %9 = arith.divui %8, %c2_i32 : i32
      %10 = math.ctlz %9 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.subi %c32, %11 : index
      %13 = arith.index_cast %4 : index to i32
      scf.for %arg4 = %c0 to %12 step %c1 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.shrui %9, %18 : i32
        %20 = arith.cmpi ult, %13, %19 : i32
        scf.if %20 {
          %21 = memref.load %alloca[%4] : memref<1xf32, 5>
          %22 = arith.addi %13, %19 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %alloca[%23] : memref<1xf32, 5>
          %25 = arith.cmpf olt, %21, %24 : f32
          scf.if %25 {
            memref.store %24, %alloca[%4] : memref<1xf32, 5>
          }
        }
        nvvm.barrier0
      }
      %14 = memref.load %alloca[%c0] : memref<1xf32, 5>
      nvvm.barrier0
      %15 = scf.for %arg4 = %4 to %6 step %3 iter_args(%arg5 = %cst) -> (f32) {
        %18 = arith.subi %arg4, %4 : index
        %19 = arith.divui %18, %3 : index
        %20 = arith.muli %19, %3 : index
        %21 = arith.addi %4, %20 : index
        %22 = arith.index_cast %21 : index to i32
        %23 = arith.addi %5, %22 : i32
        %24 = arith.index_cast %23 : i32 to index
        %25 = memref.load %arg0[%24] : memref<?xf32>
        %26 = arith.subf %25, %14 : f32
        %27 = math.exp %26 : f32
        memref.store %27, %arg1[%24] : memref<?xf32>
        %28 = arith.addf %arg5, %27 : f32
        scf.yield %28 : f32
      }
      %16 = arith.addi %4, %3 : index
      memref.store %15, %alloca[%16] : memref<1xf32, 5>
      nvvm.barrier0
      scf.for %arg4 = %c0 to %12 step %c1 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.shrui %9, %18 : i32
        %20 = arith.cmpi ult, %13, %19 : i32
        scf.if %20 {
          %21 = arith.addi %13, %19 : i32
          %22 = arith.index_cast %21 : i32 to index
          %23 = arith.addi %22, %3 : index
          %24 = memref.load %alloca[%23] : memref<1xf32, 5>
          %25 = memref.load %alloca[%16] : memref<1xf32, 5>
          %26 = arith.addf %25, %24 : f32
          memref.store %26, %alloca[%16] : memref<1xf32, 5>
        }
        nvvm.barrier0
      }
      %17 = memref.load %alloca[%3] : memref<1xf32, 5>
      nvvm.barrier0
      scf.for %arg4 = %4 to %6 step %3 {
        %18 = arith.subi %arg4, %4 : index
        %19 = arith.divui %18, %3 : index
        %20 = arith.muli %19, %3 : index
        %21 = arith.addi %4, %20 : index
        %22 = arith.index_cast %21 : index to i32
        %23 = arith.addi %5, %22 : i32
        %24 = arith.index_cast %23 : i32 to index
        %25 = memref.load %arg1[%24] : memref<?xf32>
        %26 = arith.divf %25, %17 : f32
        memref.store %26, %arg1[%24] : memref<?xf32>
      }
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %c32_0 = arith.constant 32 : index
      %c0_1 = arith.constant 0 : index
      %c1_2 = arith.constant 1 : index
      %cst = arith.constant 0.000000e+00 : f32
      %c2_i32 = arith.constant 2 : i32
      %cst_3 = arith.constant -3.40282347E+38 : f32
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.cmpi slt, %1, %arg2 : i32
      scf.if %2 {
        %3 = gpu.block_dim  x
        %4 = arith.muli %1, %arg3 : i32
        %5 = arith.index_cast %arg3 : i32 to index
        %6 = scf.for %arg5 = %arg4 to %5 step %3 iter_args(%arg6 = %cst_3) -> (f32) {
          %17 = arith.subi %arg5, %arg4 : index
          %18 = arith.divui %17, %3 : index
          %19 = arith.muli %18, %3 : index
          %20 = arith.addi %arg4, %19 : index
          %21 = arith.index_cast %20 : index to i32
          %22 = arith.addi %4, %21 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.cmpf ogt, %24, %arg6 : f32
          %26 = arith.select %25, %24, %arg6 : f32
          scf.yield %26 : f32
        }
        memref.store %6, %alloca[%arg4] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        %7 = arith.index_cast %3 : index to i32
        %8 = arith.divui %7, %c2_i32 : i32
        %9 = math.ctlz %8 : i32
        %10 = arith.index_cast %9 : i32 to index
        %11 = arith.subi %c32_0, %10 : index
        %12 = arith.index_cast %arg4 : index to i32
        scf.for %arg5 = %c0_1 to %11 step %c1_2 {
          %17 = arith.index_cast %arg5 : index to i32
          %18 = arith.shrui %8, %17 : i32
          %19 = arith.cmpi ult, %12, %18 : i32
          scf.if %19 {
            %20 = memref.load %alloca[%arg4] : memref<1xf32, 5>
            %21 = arith.addi %12, %18 : i32
            %22 = arith.index_cast %21 : i32 to index
            %23 = memref.load %alloca[%22] : memref<1xf32, 5>
            %24 = arith.cmpf olt, %20, %23 : f32
            scf.if %24 {
              memref.store %23, %alloca[%arg4] : memref<1xf32, 5>
            }
          }
          "polygeist.barrier"(%arg4) : (index) -> ()
        }
        %13 = memref.load %alloca[%c0_1] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        %14 = scf.for %arg5 = %arg4 to %5 step %3 iter_args(%arg6 = %cst) -> (f32) {
          %17 = arith.subi %arg5, %arg4 : index
          %18 = arith.divui %17, %3 : index
          %19 = arith.muli %18, %3 : index
          %20 = arith.addi %arg4, %19 : index
          %21 = arith.index_cast %20 : index to i32
          %22 = arith.addi %4, %21 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.subf %24, %13 : f32
          %26 = math.exp %25 : f32
          memref.store %26, %arg1[%23] : memref<?xf32>
          %27 = arith.addf %arg6, %26 : f32
          scf.yield %27 : f32
        }
        %15 = arith.addi %arg4, %3 : index
        memref.store %14, %alloca[%15] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        scf.for %arg5 = %c0_1 to %11 step %c1_2 {
          %17 = arith.index_cast %arg5 : index to i32
          %18 = arith.shrui %8, %17 : i32
          %19 = arith.cmpi ult, %12, %18 : i32
          scf.if %19 {
            %20 = arith.addi %12, %18 : i32
            %21 = arith.index_cast %20 : i32 to index
            %22 = arith.addi %21, %3 : index
            %23 = memref.load %alloca[%22] : memref<1xf32, 5>
            %24 = memref.load %alloca[%15] : memref<1xf32, 5>
            %25 = arith.addf %24, %23 : f32
            memref.store %25, %alloca[%15] : memref<1xf32, 5>
          }
          "polygeist.barrier"(%arg4) : (index) -> ()
        }
        %16 = memref.load %alloca[%3] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        scf.for %arg5 = %arg4 to %5 step %3 {
          %17 = arith.subi %arg5, %arg4 : index
          %18 = arith.divui %17, %3 : index
          %19 = arith.muli %18, %3 : index
          %20 = arith.addi %arg4, %19 : index
          %21 = arith.index_cast %20 : index to i32
          %22 = arith.addi %4, %21 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %arg1[%23] : memref<?xf32>
          %25 = arith.divf %24, %16 : f32
          memref.store %25, %arg1[%23] : memref<?xf32>
        }
      }
      scf.yield
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %c32_0 = arith.constant 32 : index
      %c0_1 = arith.constant 0 : index
      %c1_2 = arith.constant 1 : index
      %cst = arith.constant 0.000000e+00 : f32
      %c2_i32 = arith.constant 2 : i32
      %cst_3 = arith.constant -3.40282347E+38 : f32
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.cmpi slt, %1, %arg2 : i32
      scf.if %2 {
        %3 = gpu.block_dim  x
        %4 = arith.muli %1, %arg3 : i32
        %5 = arith.index_cast %arg3 : i32 to index
        %6 = scf.for %arg5 = %arg4 to %5 step %3 iter_args(%arg6 = %cst_3) -> (f32) {
          %17 = arith.subi %arg5, %arg4 : index
          %18 = arith.divui %17, %3 : index
          %19 = arith.muli %18, %3 : index
          %20 = arith.addi %arg4, %19 : index
          %21 = arith.index_cast %20 : index to i32
          %22 = arith.addi %4, %21 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.cmpf ogt, %24, %arg6 : f32
          %26 = arith.select %25, %24, %arg6 : f32
          scf.yield %26 : f32
        }
        memref.store %6, %alloca[%arg4] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        %7 = arith.index_cast %3 : index to i32
        %8 = arith.divui %7, %c2_i32 : i32
        %9 = math.ctlz %8 : i32
        %10 = arith.index_cast %9 : i32 to index
        %11 = arith.subi %c32_0, %10 : index
        %12 = arith.index_cast %arg4 : index to i32
        scf.for %arg5 = %c0_1 to %11 step %c1_2 {
          %17 = arith.index_cast %arg5 : index to i32
          %18 = arith.shrui %8, %17 : i32
          %19 = arith.cmpi ult, %12, %18 : i32
          scf.if %19 {
            %20 = memref.load %alloca[%arg4] : memref<1xf32, 5>
            %21 = arith.addi %12, %18 : i32
            %22 = arith.index_cast %21 : i32 to index
            %23 = memref.load %alloca[%22] : memref<1xf32, 5>
            %24 = arith.cmpf olt, %20, %23 : f32
            scf.if %24 {
              memref.store %23, %alloca[%arg4] : memref<1xf32, 5>
            }
          }
          "polygeist.barrier"(%arg4) : (index) -> ()
        }
        %13 = memref.load %alloca[%c0_1] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        %14 = scf.for %arg5 = %arg4 to %5 step %3 iter_args(%arg6 = %cst) -> (f32) {
          %17 = arith.subi %arg5, %arg4 : index
          %18 = arith.divui %17, %3 : index
          %19 = arith.muli %18, %3 : index
          %20 = arith.addi %arg4, %19 : index
          %21 = arith.index_cast %20 : index to i32
          %22 = arith.addi %4, %21 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.subf %24, %13 : f32
          %26 = math.exp %25 : f32
          memref.store %26, %arg1[%23] : memref<?xf32>
          %27 = arith.addf %arg6, %26 : f32
          scf.yield %27 : f32
        }
        %15 = arith.addi %arg4, %3 : index
        memref.store %14, %alloca[%15] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        scf.for %arg5 = %c0_1 to %11 step %c1_2 {
          %17 = arith.index_cast %arg5 : index to i32
          %18 = arith.shrui %8, %17 : i32
          %19 = arith.cmpi ult, %12, %18 : i32
          scf.if %19 {
            %20 = arith.addi %12, %18 : i32
            %21 = arith.index_cast %20 : i32 to index
            %22 = arith.addi %21, %3 : index
            %23 = memref.load %alloca[%22] : memref<1xf32, 5>
            %24 = memref.load %alloca[%15] : memref<1xf32, 5>
            %25 = arith.addf %24, %23 : f32
            memref.store %25, %alloca[%15] : memref<1xf32, 5>
          }
          "polygeist.barrier"(%arg4) : (index) -> ()
        }
        %16 = memref.load %alloca[%3] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        scf.for %arg5 = %arg4 to %5 step %3 {
          %17 = arith.subi %arg5, %arg4 : index
          %18 = arith.divui %17, %3 : index
          %19 = arith.muli %18, %3 : index
          %20 = arith.addi %arg4, %19 : index
          %21 = arith.index_cast %20 : index to i32
          %22 = arith.addi %4, %21 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = memref.load %arg1[%23] : memref<?xf32>
          %25 = arith.divf %24, %16 : f32
          memref.store %25, %arg1[%23] : memref<?xf32>
        }
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant -3.40282347E+38 : f32
    %c2_i32 = arith.constant 2 : i32
    %cst_0 = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.block_id  x
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.cmpi slt, %1, %arg2 : i32
    scf.if %2 {
      %alloca_1 = memref.alloca() : memref<32xf32>
      %3 = gpu.block_dim  x
      %4 = arith.muli %1, %arg3 : i32
      %5 = arith.index_cast %arg3 : i32 to index
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %18 = scf.for %arg5 = %arg4 to %5 step %3 iter_args(%arg6 = %cst) -> (f32) {
          %19 = arith.subi %arg5, %arg4 : index
          %20 = arith.divui %19, %3 : index
          %21 = arith.muli %20, %3 : index
          %22 = arith.addi %arg4, %21 : index
          %23 = arith.index_cast %22 : index to i32
          %24 = arith.addi %4, %23 : i32
          %25 = arith.index_cast %24 : i32 to index
          %26 = memref.load %arg0[%25] : memref<?xf32>
          %27 = arith.cmpf ogt, %26, %arg6 : f32
          %28 = arith.select %27, %26, %arg6 : f32
          scf.yield %28 : f32
        }
        memref.store %18, %alloca[%arg4] : memref<1xf32, 5>
        scf.yield
      }
      %6 = gpu.block_dim  x
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.divui %7, %c2_i32 : i32
      %9 = math.ctlz %8 : i32
      %10 = arith.index_cast %9 : i32 to index
      %11 = arith.subi %c32, %10 : index
      scf.for %arg4 = %c0 to %11 step %c1 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.shrui %8, %18 : i32
        scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
          %20 = arith.index_cast %arg5 : index to i32
          %21 = arith.cmpi ult, %20, %19 : i32
          scf.if %21 {
            %22 = memref.load %alloca[%arg5] : memref<1xf32, 5>
            %23 = arith.addi %20, %19 : i32
            %24 = arith.index_cast %23 : i32 to index
            %25 = memref.load %alloca[%24] : memref<1xf32, 5>
            %26 = arith.cmpf olt, %22, %25 : f32
            scf.if %26 {
              memref.store %25, %alloca[%arg5] : memref<1xf32, 5>
            }
          }
          scf.yield
        }
      }
      %12 = memref.load %alloca[%c0] : memref<1xf32, 5>
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        memref.store %12, %alloca_1[%arg4] : memref<32xf32>
        scf.yield
      }
      %13 = arith.muli %1, %arg3 : i32
      %14 = arith.index_cast %arg3 : i32 to index
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %18 = memref.load %alloca_1[%arg4] : memref<32xf32>
        %19 = scf.for %arg5 = %arg4 to %14 step %6 iter_args(%arg6 = %cst_0) -> (f32) {
          %21 = arith.subi %arg5, %arg4 : index
          %22 = arith.divui %21, %6 : index
          %23 = arith.muli %22, %6 : index
          %24 = arith.addi %arg4, %23 : index
          %25 = arith.index_cast %24 : index to i32
          %26 = arith.addi %13, %25 : i32
          %27 = arith.index_cast %26 : i32 to index
          %28 = memref.load %arg0[%27] : memref<?xf32>
          %29 = arith.subf %28, %18 : f32
          %30 = math.exp %29 : f32
          memref.store %30, %arg1[%27] : memref<?xf32>
          %31 = arith.addf %arg6, %30 : f32
          scf.yield %31 : f32
        }
        %20 = arith.addi %arg4, %6 : index
        memref.store %19, %alloca[%20] : memref<1xf32, 5>
        scf.yield
      }
      scf.for %arg4 = %c0 to %11 step %c1 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.shrui %8, %18 : i32
        scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
          %20 = arith.addi %arg5, %6 : index
          %21 = arith.index_cast %arg5 : index to i32
          %22 = arith.cmpi ult, %21, %19 : i32
          scf.if %22 {
            %23 = arith.addi %21, %19 : i32
            %24 = arith.index_cast %23 : i32 to index
            %25 = arith.addi %24, %6 : index
            %26 = memref.load %alloca[%25] : memref<1xf32, 5>
            %27 = memref.load %alloca[%20] : memref<1xf32, 5>
            %28 = arith.addf %27, %26 : f32
            memref.store %28, %alloca[%20] : memref<1xf32, 5>
          }
          scf.yield
        }
      }
      %15 = arith.muli %1, %arg3 : i32
      %16 = arith.index_cast %arg3 : i32 to index
      %17 = arith.cmpi slt, %c0, %c32 : index
      scf.if %17 {
        %18 = memref.load %alloca[%6] : memref<1xf32, 5>
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          scf.for %arg5 = %arg4 to %16 step %6 {
            %19 = arith.subi %arg5, %arg4 : index
            %20 = arith.divui %19, %6 : index
            %21 = arith.muli %20, %6 : index
            %22 = arith.addi %arg4, %21 : index
            %23 = arith.index_cast %22 : index to i32
            %24 = arith.addi %15, %23 : i32
            %25 = arith.index_cast %24 : i32 to index
            %26 = memref.load %arg1[%25] : memref<?xf32>
            %27 = arith.divf %26, %18 : f32
            memref.store %27, %arg1[%25] : memref<?xf32>
          }
          scf.yield
        }
      }
    }
    return
  }
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20softmax_kernel_batchPKfPfii_0 {
    gpu.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant -3.40282347E+38 : f32
      %c2_i32 = arith.constant 2 : i32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<1xf32, 5>
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.cmpi slt, %1, %arg2 : i32
      scf.if %2 {
        %alloca_1 = memref.alloca() : memref<32xf32>
        %3 = gpu.block_dim  x
        %4 = arith.muli %1, %arg3 : i32
        %5 = arith.index_cast %arg3 : i32 to index
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          %13 = scf.for %arg5 = %arg4 to %5 step %3 iter_args(%arg6 = %cst) -> (f32) {
            %14 = arith.subi %arg5, %arg4 : index
            %15 = arith.divui %14, %3 : index
            %16 = arith.muli %15, %3 : index
            %17 = arith.addi %arg4, %16 : index
            %18 = arith.index_cast %17 : index to i32
            %19 = arith.addi %4, %18 : i32
            %20 = arith.index_cast %19 : i32 to index
            %21 = memref.load %arg0[%20] : memref<?xf32>
            %22 = arith.cmpf ogt, %21, %arg6 : f32
            %23 = arith.select %22, %21, %arg6 : f32
            scf.yield %23 : f32
          }
          memref.store %13, %alloca[%arg4] : memref<1xf32, 5>
          scf.yield
        }
        %6 = arith.index_cast %3 : index to i32
        %7 = arith.divui %6, %c2_i32 : i32
        %8 = math.ctlz %7 : i32
        %9 = arith.index_cast %8 : i32 to index
        %10 = arith.subi %c32, %9 : index
        scf.for %arg4 = %c0 to %10 step %c1 {
          %13 = arith.index_cast %arg4 : index to i32
          %14 = arith.shrui %7, %13 : i32
          scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
            %15 = arith.index_cast %arg5 : index to i32
            %16 = arith.cmpi ult, %15, %14 : i32
            scf.if %16 {
              %17 = memref.load %alloca[%arg5] : memref<1xf32, 5>
              %18 = arith.addi %15, %14 : i32
              %19 = arith.index_cast %18 : i32 to index
              %20 = memref.load %alloca[%19] : memref<1xf32, 5>
              %21 = arith.cmpf olt, %17, %20 : f32
              scf.if %21 {
                memref.store %20, %alloca[%arg5] : memref<1xf32, 5>
              }
            }
            scf.yield
          }
        }
        %11 = memref.load %alloca[%c0] : memref<1xf32, 5>
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          memref.store %11, %alloca_1[%arg4] : memref<32xf32>
          scf.yield
        }
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          %13 = memref.load %alloca_1[%arg4] : memref<32xf32>
          %14 = scf.for %arg5 = %arg4 to %5 step %3 iter_args(%arg6 = %cst_0) -> (f32) {
            %16 = arith.subi %arg5, %arg4 : index
            %17 = arith.divui %16, %3 : index
            %18 = arith.muli %17, %3 : index
            %19 = arith.addi %arg4, %18 : index
            %20 = arith.index_cast %19 : index to i32
            %21 = arith.addi %4, %20 : i32
            %22 = arith.index_cast %21 : i32 to index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.subf %23, %13 : f32
            %25 = math.exp %24 : f32
            memref.store %25, %arg1[%22] : memref<?xf32>
            %26 = arith.addf %arg6, %25 : f32
            scf.yield %26 : f32
          }
          %15 = arith.addi %arg4, %3 : index
          memref.store %14, %alloca[%15] : memref<1xf32, 5>
          scf.yield
        }
        scf.for %arg4 = %c0 to %10 step %c1 {
          %13 = arith.index_cast %arg4 : index to i32
          %14 = arith.shrui %7, %13 : i32
          scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
            %15 = arith.addi %arg5, %3 : index
            %16 = arith.index_cast %arg5 : index to i32
            %17 = arith.cmpi ult, %16, %14 : i32
            scf.if %17 {
              %18 = arith.addi %16, %14 : i32
              %19 = arith.index_cast %18 : i32 to index
              %20 = arith.addi %19, %3 : index
              %21 = memref.load %alloca[%20] : memref<1xf32, 5>
              %22 = memref.load %alloca[%15] : memref<1xf32, 5>
              %23 = arith.addf %22, %21 : f32
              memref.store %23, %alloca[%15] : memref<1xf32, 5>
            }
            scf.yield
          }
        }
        %12 = memref.load %alloca[%3] : memref<1xf32, 5>
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          scf.for %arg5 = %arg4 to %5 step %3 {
            %13 = arith.subi %arg5, %arg4 : index
            %14 = arith.divui %13, %3 : index
            %15 = arith.muli %14, %3 : index
            %16 = arith.addi %arg4, %15 : index
            %17 = arith.index_cast %16 : index to i32
            %18 = arith.addi %4, %17 : i32
            %19 = arith.index_cast %18 : i32 to index
            %20 = memref.load %arg1[%19] : memref<?xf32>
            %21 = arith.divf %20, %12 : f32
            memref.store %21, %arg1[%19] : memref<?xf32>
          }
          scf.yield
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20softmax_kernel_batchPKfPfii_0 {
    gpu.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant -3.40282347E+38 : f32
      %c2_i32 = arith.constant 2 : i32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<1xf32, 5>
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.cmpi slt, %1, %arg2 : i32
      scf.if %2 {
        %alloca_1 = memref.alloca() : memref<32xf32>
        %c32_2 = arith.constant 32 : index
        %3 = arith.muli %1, %arg3 : i32
        %4 = arith.index_cast %arg3 : i32 to index
        %c1_3 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_3 {
          %12 = scf.for %arg5 = %arg4 to %4 step %c32_2 iter_args(%arg6 = %cst) -> (f32) {
            %13 = arith.subi %arg5, %arg4 : index
            %14 = arith.divui %13, %c32_2 : index
            %15 = arith.muli %14, %c32_2 : index
            %16 = arith.addi %arg4, %15 : index
            %17 = arith.index_cast %16 : index to i32
            %18 = arith.addi %3, %17 : i32
            %19 = arith.index_cast %18 : i32 to index
            %20 = memref.load %arg0[%19] : memref<?xf32>
            %21 = arith.cmpf ogt, %20, %arg6 : f32
            %22 = arith.select %21, %20, %arg6 : f32
            scf.yield %22 : f32
          }
          memref.store %12, %alloca[%arg4] : memref<1xf32, 5>
        }
        %5 = arith.index_cast %c32_2 : index to i32
        %6 = arith.divui %5, %c2_i32 : i32
        %7 = math.ctlz %6 : i32
        %8 = arith.index_cast %7 : i32 to index
        %9 = arith.subi %c32, %8 : index
        scf.for %arg4 = %c0 to %9 step %c1 {
          %12 = arith.index_cast %arg4 : index to i32
          %13 = arith.shrui %6, %12 : i32
          %c1_7 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_7 {
            %14 = arith.index_cast %arg5 : index to i32
            %15 = arith.cmpi ult, %14, %13 : i32
            scf.if %15 {
              %16 = memref.load %alloca[%arg5] : memref<1xf32, 5>
              %17 = arith.addi %14, %13 : i32
              %18 = arith.index_cast %17 : i32 to index
              %19 = memref.load %alloca[%18] : memref<1xf32, 5>
              %20 = arith.cmpf olt, %16, %19 : f32
              scf.if %20 {
                memref.store %19, %alloca[%arg5] : memref<1xf32, 5>
              }
            }
          }
        }
        %10 = memref.load %alloca[%c0] : memref<1xf32, 5>
        %c1_4 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_4 {
          memref.store %10, %alloca_1[%arg4] : memref<32xf32>
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_5 {
          %12 = memref.load %alloca_1[%arg4] : memref<32xf32>
          %13 = scf.for %arg5 = %arg4 to %4 step %c32_2 iter_args(%arg6 = %cst_0) -> (f32) {
            %15 = arith.subi %arg5, %arg4 : index
            %16 = arith.divui %15, %c32_2 : index
            %17 = arith.muli %16, %c32_2 : index
            %18 = arith.addi %arg4, %17 : index
            %19 = arith.index_cast %18 : index to i32
            %20 = arith.addi %3, %19 : i32
            %21 = arith.index_cast %20 : i32 to index
            %22 = memref.load %arg0[%21] : memref<?xf32>
            %23 = arith.subf %22, %12 : f32
            %24 = math.exp %23 : f32
            memref.store %24, %arg1[%21] : memref<?xf32>
            %25 = arith.addf %arg6, %24 : f32
            scf.yield %25 : f32
          }
          %14 = arith.addi %arg4, %c32_2 : index
          memref.store %13, %alloca[%14] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %9 step %c1 {
          %12 = arith.index_cast %arg4 : index to i32
          %13 = arith.shrui %6, %12 : i32
          %c1_7 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_7 {
            %14 = arith.addi %arg5, %c32_2 : index
            %15 = arith.index_cast %arg5 : index to i32
            %16 = arith.cmpi ult, %15, %13 : i32
            scf.if %16 {
              %17 = arith.addi %15, %13 : i32
              %18 = arith.index_cast %17 : i32 to index
              %19 = arith.addi %18, %c32_2 : index
              %20 = memref.load %alloca[%19] : memref<1xf32, 5>
              %21 = memref.load %alloca[%14] : memref<1xf32, 5>
              %22 = arith.addf %21, %20 : f32
              memref.store %22, %alloca[%14] : memref<1xf32, 5>
            }
          }
        }
        %11 = memref.load %alloca[%c32_2] : memref<1xf32, 5>
        %c1_6 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_6 {
          scf.for %arg5 = %arg4 to %4 step %c32_2 {
            %12 = arith.subi %arg5, %arg4 : index
            %13 = arith.divui %12, %c32_2 : index
            %14 = arith.muli %13, %c32_2 : index
            %15 = arith.addi %arg4, %14 : index
            %16 = arith.index_cast %15 : index to i32
            %17 = arith.addi %3, %16 : i32
            %18 = arith.index_cast %17 : i32 to index
            %19 = memref.load %arg1[%18] : memref<?xf32>
            %20 = arith.divf %19, %11 : f32
            memref.store %20, %arg1[%18] : memref<?xf32>
          }
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca = memref.alloca() : memref<1xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca = memref.alloca() : memref<1xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20softmax_kernel_batchPKfPfii_0 {
    gpu.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant -3.40282347E+38 : f32
      %c2_i32 = arith.constant 2 : i32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = arith.cmpi slt, %2, %arg2 : i32
      scf.if %3 {
        %alloca_1 = memref.alloca() : memref<32xf32, 5>
        %c32_2 = arith.constant 32 : index
        %4 = arith.muli %2, %arg3 : i32
        %5 = arith.index_cast %arg3 : i32 to index
        %c1_3 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_3 {
          %13 = scf.for %arg5 = %arg4 to %5 step %c32_2 iter_args(%arg6 = %cst) -> (f32) {
            %14 = arith.subi %arg5, %arg4 : index
            %15 = arith.divui %14, %c32_2 : index
            %16 = arith.muli %15, %c32_2 : index
            %17 = arith.addi %arg4, %16 : index
            %18 = arith.index_cast %17 : index to i32
            %19 = arith.addi %4, %18 : i32
            %20 = arith.index_cast %19 : i32 to index
            %21 = memref.load %arg0[%20] : memref<?xf32>
            %22 = arith.cmpf ogt, %21, %arg6 : f32
            %23 = arith.select %22, %21, %arg6 : f32
            scf.yield %23 : f32
          }
          memref.store %13, %alloca[%arg4] : memref<1xf32, 5>
        }
        %6 = arith.index_cast %c32_2 : index to i32
        %7 = arith.divui %6, %c2_i32 : i32
        %8 = math.ctlz %7 : i32
        %9 = arith.index_cast %8 : i32 to index
        %10 = arith.subi %c32, %9 : index
        scf.for %arg4 = %c0 to %10 step %c1 {
          %13 = arith.index_cast %arg4 : index to i32
          %14 = arith.shrui %7, %13 : i32
          %c1_7 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_7 {
            %15 = arith.index_cast %arg5 : index to i32
            %16 = arith.cmpi ult, %15, %14 : i32
            scf.if %16 {
              %17 = memref.load %alloca[%arg5] : memref<1xf32, 5>
              %18 = arith.addi %15, %14 : i32
              %19 = arith.index_cast %18 : i32 to index
              %20 = memref.load %alloca[%19] : memref<1xf32, 5>
              %21 = arith.cmpf olt, %17, %20 : f32
              scf.if %21 {
                memref.store %20, %alloca[%arg5] : memref<1xf32, 5>
              }
            }
          }
        }
        %11 = memref.load %alloca[%c0] : memref<1xf32, 5>
        %c1_4 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_4 {
          memref.store %11, %alloca_1[%arg4] : memref<32xf32, 5>
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_5 {
          %13 = memref.load %alloca_1[%arg4] : memref<32xf32, 5>
          %14 = scf.for %arg5 = %arg4 to %5 step %c32_2 iter_args(%arg6 = %cst_0) -> (f32) {
            %16 = arith.subi %arg5, %arg4 : index
            %17 = arith.divui %16, %c32_2 : index
            %18 = arith.muli %17, %c32_2 : index
            %19 = arith.addi %arg4, %18 : index
            %20 = arith.index_cast %19 : index to i32
            %21 = arith.addi %4, %20 : i32
            %22 = arith.index_cast %21 : i32 to index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.subf %23, %13 : f32
            %25 = math.exp %24 : f32
            memref.store %25, %arg1[%22] : memref<?xf32>
            %26 = arith.addf %arg6, %25 : f32
            scf.yield %26 : f32
          }
          %15 = arith.addi %arg4, %c32_2 : index
          memref.store %14, %alloca[%15] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %10 step %c1 {
          %13 = arith.index_cast %arg4 : index to i32
          %14 = arith.shrui %7, %13 : i32
          %c1_7 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_7 {
            %15 = arith.addi %arg5, %c32_2 : index
            %16 = arith.index_cast %arg5 : index to i32
            %17 = arith.cmpi ult, %16, %14 : i32
            scf.if %17 {
              %18 = arith.addi %16, %14 : i32
              %19 = arith.index_cast %18 : i32 to index
              %20 = arith.addi %19, %c32_2 : index
              %21 = memref.load %alloca[%20] : memref<1xf32, 5>
              %22 = memref.load %alloca[%15] : memref<1xf32, 5>
              %23 = arith.addf %22, %21 : f32
              memref.store %23, %alloca[%15] : memref<1xf32, 5>
            }
          }
        }
        %12 = memref.load %alloca[%c32_2] : memref<1xf32, 5>
        %c1_6 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_6 {
          scf.for %arg5 = %arg4 to %5 step %c32_2 {
            %13 = arith.subi %arg5, %arg4 : index
            %14 = arith.divui %13, %c32_2 : index
            %15 = arith.muli %14, %c32_2 : index
            %16 = arith.addi %arg4, %15 : index
            %17 = arith.index_cast %16 : index to i32
            %18 = arith.addi %4, %17 : i32
            %19 = arith.index_cast %18 : i32 to index
            %20 = memref.load %arg1[%19] : memref<?xf32>
            %21 = arith.divf %20, %12 : f32
            memref.store %21, %arg1[%19] : memref<?xf32>
          }
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] GPUBlockIdToNPULowering: process op: 

%1 = gpu.block_id  x
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_1 = memref.alloca() : memref<32xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%5 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_1 = memref.alloca() : memref<32xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20softmax_kernel_batchPKfPfii_0 {
    gpu.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant -3.40282347E+38 : f32
      %c2_i32 = arith.constant 2 : i32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %2 = gpu.block_id  x
      %3 = arith.index_cast %2 : index to i32
      %4 = arith.cmpi slt, %3, %arg2 : i32
      scf.if %4 {
        %5 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %alloca_1 = memref.alloca() : memref<32xf32, 5>
        %c32_2 = arith.constant 32 : index
        %6 = arith.muli %3, %arg3 : i32
        %7 = arith.index_cast %arg3 : i32 to index
        %c1_3 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_3 {
          %15 = scf.for %arg5 = %arg4 to %7 step %c32_2 iter_args(%arg6 = %cst) -> (f32) {
            %16 = arith.subi %arg5, %arg4 : index
            %17 = arith.divui %16, %c32_2 : index
            %18 = arith.muli %17, %c32_2 : index
            %19 = arith.addi %arg4, %18 : index
            %20 = arith.index_cast %19 : index to i32
            %21 = arith.addi %6, %20 : i32
            %22 = arith.index_cast %21 : i32 to index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.cmpf ogt, %23, %arg6 : f32
            %25 = arith.select %24, %23, %arg6 : f32
            scf.yield %25 : f32
          }
          memref.store %15, %alloca[%arg4] : memref<1xf32, 5>
        }
        %8 = arith.index_cast %c32_2 : index to i32
        %9 = arith.divui %8, %c2_i32 : i32
        %10 = math.ctlz %9 : i32
        %11 = arith.index_cast %10 : i32 to index
        %12 = arith.subi %c32, %11 : index
        scf.for %arg4 = %c0 to %12 step %c1 {
          %15 = arith.index_cast %arg4 : index to i32
          %16 = arith.shrui %9, %15 : i32
          %c1_7 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_7 {
            %17 = arith.index_cast %arg5 : index to i32
            %18 = arith.cmpi ult, %17, %16 : i32
            scf.if %18 {
              %19 = memref.load %alloca[%arg5] : memref<1xf32, 5>
              %20 = arith.addi %17, %16 : i32
              %21 = arith.index_cast %20 : i32 to index
              %22 = memref.load %alloca[%21] : memref<1xf32, 5>
              %23 = arith.cmpf olt, %19, %22 : f32
              scf.if %23 {
                memref.store %22, %alloca[%arg5] : memref<1xf32, 5>
              }
            }
          }
        }
        %13 = memref.load %alloca[%c0] : memref<1xf32, 5>
        %c1_4 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_4 {
          memref.store %13, %alloca_1[%arg4] : memref<32xf32, 5>
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_5 {
          %15 = memref.load %alloca_1[%arg4] : memref<32xf32, 5>
          %16 = scf.for %arg5 = %arg4 to %7 step %c32_2 iter_args(%arg6 = %cst_0) -> (f32) {
            %18 = arith.subi %arg5, %arg4 : index
            %19 = arith.divui %18, %c32_2 : index
            %20 = arith.muli %19, %c32_2 : index
            %21 = arith.addi %arg4, %20 : index
            %22 = arith.index_cast %21 : index to i32
            %23 = arith.addi %6, %22 : i32
            %24 = arith.index_cast %23 : i32 to index
            %25 = memref.load %arg0[%24] : memref<?xf32>
            %26 = arith.subf %25, %15 : f32
            %27 = math.exp %26 : f32
            memref.store %27, %arg1[%24] : memref<?xf32>
            %28 = arith.addf %arg6, %27 : f32
            scf.yield %28 : f32
          }
          %17 = arith.addi %arg4, %c32_2 : index
          memref.store %16, %alloca[%17] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %12 step %c1 {
          %15 = arith.index_cast %arg4 : index to i32
          %16 = arith.shrui %9, %15 : i32
          %c1_7 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_7 {
            %17 = arith.addi %arg5, %c32_2 : index
            %18 = arith.index_cast %arg5 : index to i32
            %19 = arith.cmpi ult, %18, %16 : i32
            scf.if %19 {
              %20 = arith.addi %18, %16 : i32
              %21 = arith.index_cast %20 : i32 to index
              %22 = arith.addi %21, %c32_2 : index
              %23 = memref.load %alloca[%22] : memref<1xf32, 5>
              %24 = memref.load %alloca[%17] : memref<1xf32, 5>
              %25 = arith.addf %24, %23 : f32
              memref.store %25, %alloca[%17] : memref<1xf32, 5>
            }
          }
        }
        %14 = memref.load %alloca[%c32_2] : memref<1xf32, 5>
        %c1_6 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_6 {
          scf.for %arg5 = %arg4 to %7 step %c32_2 {
            %15 = arith.subi %arg5, %arg4 : index
            %16 = arith.divui %15, %c32_2 : index
            %17 = arith.muli %16, %c32_2 : index
            %18 = arith.addi %arg4, %17 : index
            %19 = arith.index_cast %18 : index to i32
            %20 = arith.addi %6, %19 : i32
            %21 = arith.index_cast %20 : i32 to index
            %22 = memref.load %arg1[%21] : memref<?xf32>
            %23 = arith.divf %22, %14 : f32
            memref.store %23, %arg1[%21] : memref<?xf32>
          }
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] ArithUnaryOpToNPULowering: process op: 

%28 = math.exp %27 : f32
[ict-debug] ArithUnaryOpToNPULowering: met scalar unary op, need vector help process.

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20softmax_kernel_batchPKfPfii_0 {
    gpu.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant -3.40282347E+38 : f32
      %c2_i32 = arith.constant 2 : i32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %1 = builtin.unrealized_conversion_cast %0 : !llvm.ptr<6> to memref<1xf32, 5>
      %2 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %3 = builtin.unrealized_conversion_cast %2 : i64 to index
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.cmpi slt, %4, %arg2 : i32
      scf.if %5 {
        %6 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %7 = builtin.unrealized_conversion_cast %6 : !llvm.ptr<6> to memref<32xf32, 5>
        %c32_1 = arith.constant 32 : index
        %8 = arith.muli %4, %arg3 : i32
        %9 = arith.index_cast %arg3 : i32 to index
        %c1_2 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_2 {
          %17 = scf.for %arg5 = %arg4 to %9 step %c32_1 iter_args(%arg6 = %cst) -> (f32) {
            %18 = arith.subi %arg5, %arg4 : index
            %19 = arith.divui %18, %c32_1 : index
            %20 = arith.muli %19, %c32_1 : index
            %21 = arith.addi %arg4, %20 : index
            %22 = arith.index_cast %21 : index to i32
            %23 = arith.addi %8, %22 : i32
            %24 = arith.index_cast %23 : i32 to index
            %25 = memref.load %arg0[%24] : memref<?xf32>
            %26 = arith.cmpf ogt, %25, %arg6 : f32
            %27 = arith.select %26, %25, %arg6 : f32
            scf.yield %27 : f32
          }
          memref.store %17, %1[%arg4] : memref<1xf32, 5>
        }
        %10 = arith.index_cast %c32_1 : index to i32
        %11 = arith.divui %10, %c2_i32 : i32
        %12 = math.ctlz %11 : i32
        %13 = arith.index_cast %12 : i32 to index
        %14 = arith.subi %c32, %13 : index
        scf.for %arg4 = %c0 to %14 step %c1 {
          %17 = arith.index_cast %arg4 : index to i32
          %18 = arith.shrui %11, %17 : i32
          %c1_6 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_6 {
            %19 = arith.index_cast %arg5 : index to i32
            %20 = arith.cmpi ult, %19, %18 : i32
            scf.if %20 {
              %21 = memref.load %1[%arg5] : memref<1xf32, 5>
              %22 = arith.addi %19, %18 : i32
              %23 = arith.index_cast %22 : i32 to index
              %24 = memref.load %1[%23] : memref<1xf32, 5>
              %25 = arith.cmpf olt, %21, %24 : f32
              scf.if %25 {
                memref.store %24, %1[%arg5] : memref<1xf32, 5>
              }
            }
          }
        }
        %15 = memref.load %1[%c0] : memref<1xf32, 5>
        %c1_3 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_3 {
          memref.store %15, %7[%arg4] : memref<32xf32, 5>
        }
        %c1_4 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_4 {
          %17 = memref.load %7[%arg4] : memref<32xf32, 5>
          %18 = scf.for %arg5 = %arg4 to %9 step %c32_1 iter_args(%arg6 = %cst_0) -> (f32) {
            %20 = arith.subi %arg5, %arg4 : index
            %21 = arith.divui %20, %c32_1 : index
            %22 = arith.muli %21, %c32_1 : index
            %23 = arith.addi %arg4, %22 : index
            %24 = arith.index_cast %23 : index to i32
            %25 = arith.addi %8, %24 : i32
            %26 = arith.index_cast %25 : i32 to index
            %27 = memref.load %arg0[%26] : memref<?xf32>
            %28 = emitc.sub %27, %17 : (f32, f32) -> f32
            %29 = emitc.call "expf"(%28) : (f32) -> f32
            memref.store %29, %arg1[%26] : memref<?xf32>
            %30 = emitc.add %arg6, %29 : (f32, f32) -> f32
            scf.yield %30 : f32
          }
          %19 = arith.addi %arg4, %c32_1 : index
          memref.store %18, %1[%19] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %14 step %c1 {
          %17 = arith.index_cast %arg4 : index to i32
          %18 = arith.shrui %11, %17 : i32
          %c1_6 = arith.constant 1 : index
          scf.for %arg5 = %c0 to %c32 step %c1_6 {
            %19 = arith.addi %arg5, %c32_1 : index
            %20 = arith.index_cast %arg5 : index to i32
            %21 = arith.cmpi ult, %20, %18 : i32
            scf.if %21 {
              %22 = arith.addi %20, %18 : i32
              %23 = arith.index_cast %22 : i32 to index
              %24 = arith.addi %23, %c32_1 : index
              %25 = memref.load %1[%24] : memref<1xf32, 5>
              %26 = memref.load %1[%19] : memref<1xf32, 5>
              %27 = emitc.add %26, %25 : (f32, f32) -> f32
              memref.store %27, %1[%19] : memref<1xf32, 5>
            }
          }
        }
        %16 = memref.load %1[%c32_1] : memref<1xf32, 5>
        %c1_5 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_5 {
          scf.for %arg5 = %arg4 to %9 step %c32_1 {
            %17 = arith.subi %arg5, %arg4 : index
            %18 = arith.divui %17, %c32_1 : index
            %19 = arith.muli %18, %c32_1 : index
            %20 = arith.addi %arg4, %19 : index
            %21 = arith.index_cast %20 : index to i32
            %22 = arith.addi %8, %21 : i32
            %23 = arith.index_cast %22 : i32 to index
            %24 = memref.load %arg1[%23] : memref<?xf32>
            %25 = emitc.div %24, %16 : (f32, f32) -> f32
            memref.store %25, %arg1[%23] : memref<?xf32>
          }
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU: end

[ict-debug] driver.cc: Before convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20softmax_kernel_batchPKfPfii_0 {
    gpu.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c5 = arith.constant 5 : index
      %c16_i32 = arith.constant 16 : i32
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %1 = builtin.unrealized_conversion_cast %0 : !llvm.ptr<6> to memref<1xf32, 5>
      %2 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %3 = builtin.unrealized_conversion_cast %2 : i64 to index
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.cmpi slt, %4, %arg2 : i32
      scf.if %5 {
        %6 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %7 = builtin.unrealized_conversion_cast %6 : !llvm.ptr<6> to memref<32xf32, 5>
        %8 = arith.muli %4, %arg3 : i32
        %9 = arith.index_cast %arg3 : i32 to index
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %12 = scf.for %arg5 = %arg4 to %9 step %c32 iter_args(%arg6 = %cst) -> (f32) {
            %13 = arith.subi %arg5, %arg4 : index
            %14 = arith.divui %13, %c32 : index
            %15 = arith.muli %14, %c32 : index
            %16 = arith.addi %arg4, %15 : index
            %17 = arith.index_cast %16 : index to i32
            %18 = arith.addi %8, %17 : i32
            %19 = arith.index_cast %18 : i32 to index
            %20 = memref.load %arg0[%19] : memref<?xf32>
            %21 = arith.cmpf ogt, %20, %arg6 : f32
            %22 = arith.select %21, %20, %arg6 : f32
            scf.yield %22 : f32
          }
          memref.store %12, %1[%arg4] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %c5 step %c1 {
          %12 = arith.index_cast %arg4 : index to i32
          %13 = arith.shrui %c16_i32, %12 : i32
          scf.for %arg5 = %c0 to %c32 step %c1 {
            %14 = arith.index_cast %arg5 : index to i32
            %15 = arith.cmpi ult, %14, %13 : i32
            scf.if %15 {
              %16 = memref.load %1[%arg5] : memref<1xf32, 5>
              %17 = arith.addi %14, %13 : i32
              %18 = arith.index_cast %17 : i32 to index
              %19 = memref.load %1[%18] : memref<1xf32, 5>
              %20 = arith.cmpf olt, %16, %19 : f32
              scf.if %20 {
                memref.store %19, %1[%arg5] : memref<1xf32, 5>
              }
            }
          }
        }
        %10 = memref.load %1[%c0] : memref<1xf32, 5>
        scf.for %arg4 = %c0 to %c32 step %c1 {
          memref.store %10, %7[%arg4] : memref<32xf32, 5>
        }
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %12 = memref.load %7[%arg4] : memref<32xf32, 5>
          %13 = scf.for %arg5 = %arg4 to %9 step %c32 iter_args(%arg6 = %cst_0) -> (f32) {
            %15 = arith.subi %arg5, %arg4 : index
            %16 = arith.divui %15, %c32 : index
            %17 = arith.muli %16, %c32 : index
            %18 = arith.addi %arg4, %17 : index
            %19 = arith.index_cast %18 : index to i32
            %20 = arith.addi %8, %19 : i32
            %21 = arith.index_cast %20 : i32 to index
            %22 = memref.load %arg0[%21] : memref<?xf32>
            %23 = emitc.sub %22, %12 : (f32, f32) -> f32
            %24 = emitc.call "expf"(%23) : (f32) -> f32
            memref.store %24, %arg1[%21] : memref<?xf32>
            %25 = emitc.add %arg6, %24 : (f32, f32) -> f32
            scf.yield %25 : f32
          }
          %14 = arith.addi %arg4, %c32 : index
          memref.store %13, %1[%14] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %c5 step %c1 {
          %12 = arith.index_cast %arg4 : index to i32
          %13 = arith.shrui %c16_i32, %12 : i32
          scf.for %arg5 = %c0 to %c32 step %c1 {
            %14 = arith.addi %arg5, %c32 : index
            %15 = arith.index_cast %arg5 : index to i32
            %16 = arith.cmpi ult, %15, %13 : i32
            scf.if %16 {
              %17 = arith.addi %15, %13 : i32
              %18 = arith.index_cast %17 : i32 to index
              %19 = arith.addi %18, %c32 : index
              %20 = memref.load %1[%19] : memref<1xf32, 5>
              %21 = memref.load %1[%14] : memref<1xf32, 5>
              %22 = emitc.add %21, %20 : (f32, f32) -> f32
              memref.store %22, %1[%14] : memref<1xf32, 5>
            }
          }
        }
        %11 = memref.load %1[%c32] : memref<1xf32, 5>
        scf.for %arg4 = %c0 to %c32 step %c1 {
          scf.for %arg5 = %arg4 to %9 step %c32 {
            %12 = arith.subi %arg5, %arg4 : index
            %13 = arith.divui %12, %c32 : index
            %14 = arith.muli %13, %c32 : index
            %15 = arith.addi %arg4, %14 : index
            %16 = arith.index_cast %15 : index to i32
            %17 = arith.addi %8, %16 : i32
            %18 = arith.index_cast %17 : i32 to index
            %19 = memref.load %arg1[%18] : memref<?xf32>
            %20 = emitc.div %19, %11 : (f32, f32) -> f32
            memref.store %20, %arg1[%18] : memref<?xf32>
          }
        }
      }
      gpu.return
    }
  }
}
[ict-debug] driver.cc: Before convert to EmitC dialect: end

[ict-debug] driver.cc: After convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z20softmax_kernel_batchPKfPfii_0 {
    gpu.func @_Z20softmax_kernel_batchPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c5 = arith.constant 5 : index
      %c16_i32 = arith.constant 16 : i32
      %cst = arith.constant -3.40282347E+38 : f32
      %cst_0 = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %1 = builtin.unrealized_conversion_cast %0 : !llvm.ptr<6> to memref<1xf32, 5>
      %2 = "npu.block_id"() <{dimension = "X"}> : () -> i64
      %3 = builtin.unrealized_conversion_cast %2 : i64 to index
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.cmpi slt, %4, %arg2 : i32
      emitc.if %5 {
        %6 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %7 = builtin.unrealized_conversion_cast %6 : !llvm.ptr<6> to memref<32xf32, 5>
        %8 = arith.muli %4, %arg3 : i32
        %9 = arith.index_cast %arg3 : i32 to index
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %12 = scf.for %arg5 = %arg4 to %9 step %c32 iter_args(%arg6 = %cst) -> (f32) {
            %13 = arith.subi %arg5, %arg4 : index
            %14 = arith.divui %13, %c32 : index
            %15 = arith.muli %14, %c32 : index
            %16 = arith.addi %arg4, %15 : index
            %17 = arith.index_cast %16 : index to i32
            %18 = arith.addi %8, %17 : i32
            %19 = arith.index_cast %18 : i32 to index
            %20 = memref.load %arg0[%19] : memref<?xf32>
            %21 = arith.cmpf ogt, %20, %arg6 : f32
            %22 = arith.select %21, %20, %arg6 : f32
            scf.yield %22 : f32
          }
          memref.store %12, %1[%arg4] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %c5 step %c1 {
          %12 = arith.index_cast %arg4 : index to i32
          %13 = arith.shrui %c16_i32, %12 : i32
          scf.for %arg5 = %c0 to %c32 step %c1 {
            %14 = arith.index_cast %arg5 : index to i32
            %15 = arith.cmpi ult, %14, %13 : i32
            emitc.if %15 {
              %16 = memref.load %1[%arg5] : memref<1xf32, 5>
              %17 = arith.addi %14, %13 : i32
              %18 = arith.index_cast %17 : i32 to index
              %19 = memref.load %1[%18] : memref<1xf32, 5>
              %20 = arith.cmpf olt, %16, %19 : f32
              emitc.if %20 {
                memref.store %19, %1[%arg5] : memref<1xf32, 5>
              }
            }
          }
        }
        %10 = memref.load %1[%c0] : memref<1xf32, 5>
        scf.for %arg4 = %c0 to %c32 step %c1 {
          memref.store %10, %7[%arg4] : memref<32xf32, 5>
        }
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %12 = memref.load %7[%arg4] : memref<32xf32, 5>
          %13 = scf.for %arg5 = %arg4 to %9 step %c32 iter_args(%arg6 = %cst_0) -> (f32) {
            %15 = arith.subi %arg5, %arg4 : index
            %16 = arith.divui %15, %c32 : index
            %17 = arith.muli %16, %c32 : index
            %18 = arith.addi %arg4, %17 : index
            %19 = arith.index_cast %18 : index to i32
            %20 = arith.addi %8, %19 : i32
            %21 = arith.index_cast %20 : i32 to index
            %22 = memref.load %arg0[%21] : memref<?xf32>
            %23 = emitc.sub %22, %12 : (f32, f32) -> f32
            %24 = emitc.call "expf"(%23) : (f32) -> f32
            memref.store %24, %arg1[%21] : memref<?xf32>
            %25 = emitc.add %arg6, %24 : (f32, f32) -> f32
            scf.yield %25 : f32
          }
          %14 = arith.addi %arg4, %c32 : index
          memref.store %13, %1[%14] : memref<1xf32, 5>
        }
        scf.for %arg4 = %c0 to %c5 step %c1 {
          %12 = arith.index_cast %arg4 : index to i32
          %13 = arith.shrui %c16_i32, %12 : i32
          scf.for %arg5 = %c0 to %c32 step %c1 {
            %14 = arith.addi %arg5, %c32 : index
            %15 = arith.index_cast %arg5 : index to i32
            %16 = arith.cmpi ult, %15, %13 : i32
            emitc.if %16 {
              %17 = arith.addi %15, %13 : i32
              %18 = arith.index_cast %17 : i32 to index
              %19 = arith.addi %18, %c32 : index
              %20 = memref.load %1[%19] : memref<1xf32, 5>
              %21 = memref.load %1[%14] : memref<1xf32, 5>
              %22 = emitc.add %21, %20 : (f32, f32) -> f32
              memref.store %22, %1[%14] : memref<1xf32, 5>
            }
          }
        }
        %11 = memref.load %1[%c32] : memref<1xf32, 5>
        scf.for %arg4 = %c0 to %c32 step %c1 {
          scf.for %arg5 = %arg4 to %9 step %c32 {
            %12 = arith.subi %arg5, %arg4 : index
            %13 = arith.divui %12, %c32 : index
            %14 = arith.muli %13, %c32 : index
            %15 = arith.addi %arg4, %14 : index
            %16 = arith.index_cast %15 : index to i32
            %17 = arith.addi %8, %16 : i32
            %18 = arith.index_cast %17 : i32 to index
            %19 = memref.load %arg1[%18] : memref<?xf32>
            %20 = emitc.div %19, %11 : (f32, f32) -> f32
            memref.store %20, %arg1[%18] : memref<?xf32>
          }
        }
      }
      gpu.return
    }
  }
}
[ict-debug] driver.cc: After convert to EmitC dialect: end

loc("./Ascend_kernels/gen_cuda_kernels/level_1_prlblem_23_sample_0_Softmax.cu":8:17): error: 'arith.index_cast' op unable to find printer for op
[ict-debug] driver.cc: After emitc::translateToCpp:

