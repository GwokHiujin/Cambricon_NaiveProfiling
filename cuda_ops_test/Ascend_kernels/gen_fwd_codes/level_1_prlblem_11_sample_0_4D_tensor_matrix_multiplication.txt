torch::Tensor tensor_matrix_multiply_cuda(torch::Tensor A, torch::Tensor B)
{
    int b = A.size(0);
    int i = A.size(1);
    int j = A.size(2);
    int l = A.size(3);
    int k = B.size(1);

    TORCH_CHECK(B.size(0) == l, "B.size(0) must be equal to A.size(3)");

    // Ensure A and B are contiguous and on the correct device
    A = A.contiguous();
    B = B.contiguous();

    auto C = torch::zeros({b, i, j, k}, A.options());

    const float* A_ptr = A.data_ptr<float>();
    const float* B_ptr = B.data_ptr<float>();
    float* C_ptr = C.data_ptr<float>();

    int total_batches = b * i * j;

    int threads_per_block = 256;
    int blocks_per_k = (k + threads_per_block - 1) / threads_per_block;

    // Use a 2D grid: x dimension is total_batches, y dimension is blocks per k
    dim3 grid_dim(total_batches, blocks_per_k);
    dim3 block_dim(threads_per_block);

    // Launch kernel
    tensor_matrix_multiply_kernel<<<grid_dim, block_dim>>>(
        A_ptr, B_ptr, C_ptr, b, i, j, l, k);

    // Synchronize to ensure completion
    cudaDeviceSynchronize();

    return C;
}
