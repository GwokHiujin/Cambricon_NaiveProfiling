
torch::Tensor matvec_mul_cuda(torch::Tensor A, torch::Tensor B) {
    // Check device
    TORCH_CHECK(A.is_cuda(), "A must be a CUDA tensor");
    TORCH_CHECK(B.is_cuda(), "B must be a CUDA tensor");
    TORCH_CHECK(A.is_contiguous(), "A must be contiguous");
    TORCH_CHECK(B.is_contiguous(), "B must be contiguous");

    // Check dimensions
    int64_t M = A.size(0);
    int64_t K = A.size(1);
    TORCH_CHECK(B.size(0) == K && B.size(1) == 1, "B must have size K x 1");

    // Allocate output tensor
    auto C = torch::empty({M, 1}, A.options());

    // Launch kernel
    int threads = 256;
    int blocks = M;
    size_t shared_mem_size = threads * sizeof(float);

    matvec_mul_kernel<<<blocks, threads, shared_mem_size>>>(
        A.data_ptr<float>(), B.data_ptr<float>(), C.data_ptr<float>(), M, K);

    return C;
}
