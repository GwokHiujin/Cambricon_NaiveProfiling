warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z37__device_stub__softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z22softsign_kernel_sharedPKfPfi(%arg0, %arg1, %arg2) : (memref<?xf32>, memref<?xf32>, i32) -> ()
    return
  }
  func.func private @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.thread_id  x
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.cmpi slt, %8, %arg2 : i32
    scf.if %10 {
      %11 = affine.load %arg0[symbol(%9)] : memref<?xf32>
      affine.store %11, %alloca[symbol(%0)] : memref<1xf32, 5>
      nvvm.barrier0
      %12 = affine.load %alloca[symbol(%0)] : memref<1xf32, 5>
      %13 = math.absf %12 : f32
      %14 = arith.addf %13, %cst : f32
      %15 = arith.divf %12, %14 : f32
      affine.store %15, %arg1[symbol(%9)] : memref<?xf32>
    }
    return
  }
  func.func private @_Z37__device_stub__softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z22softsign_kernel_streamPKfPfii(%arg0, %arg1, %arg2, %arg3) : (memref<?xf32>, memref<?xf32>, i32, i32) -> ()
    return
  }
  func.func private @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg2 : i32 to index
    %2 = gpu.block_id  x
    %3 = arith.index_cast %2 : index to i32
    %4 = gpu.block_dim  x
    %5 = arith.index_cast %4 : index to i32
    %6 = arith.muli %3, %5 : i32
    %7 = gpu.thread_id  x
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.addi %6, %8 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %9 : i32 to index
    %12 = arith.cmpi slt, %9, %arg3 : i32
    scf.if %12 {
      %13 = affine.load %arg0[symbol(%0) + symbol(%10)] : memref<?xf32>
      %14 = math.absf %13 : f32
      %15 = arith.addf %14, %cst : f32
      %16 = arith.divf %13, %15 : f32
      affine.store %16, %arg1[symbol(%1) + symbol(%11)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.thread_id  x
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = arith.index_cast %0 : index to i32
    %7 = arith.addi %5, %6 : i32
    %8 = arith.index_cast %7 : i32 to index
    %9 = arith.cmpi slt, %7, %arg2 : i32
    scf.if %9 {
      %10 = affine.load %arg0[symbol(%8)] : memref<?xf32>
      affine.store %10, %alloca[symbol(%0)] : memref<1xf32, 5>
      nvvm.barrier0
      %11 = affine.load %alloca[symbol(%0)] : memref<1xf32, 5>
      %12 = math.absf %11 : f32
      %13 = arith.addf %12, %cst : f32
      %14 = arith.divf %11, %13 : f32
      affine.store %14, %arg1[symbol(%8)] : memref<?xf32>
    }
    return
  }
  func.func private @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.cmpi slt, %8, %arg3 : i32
    scf.if %10 {
      %11 = affine.load %arg0[symbol(%0) + symbol(%9)] : memref<?xf32>
      %12 = math.absf %11 : f32
      %13 = arith.addf %12, %cst : f32
      %14 = arith.divf %11, %13 : f32
      affine.store %14, %arg1[symbol(%0) + symbol(%9)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.thread_id  x
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = arith.index_cast %0 : index to i32
    %7 = arith.addi %5, %6 : i32
    %8 = arith.index_cast %7 : i32 to index
    %9 = arith.cmpi slt, %7, %arg2 : i32
    scf.if %9 {
      %10 = memref.load %arg0[%8] : memref<?xf32>
      memref.store %10, %alloca[%0] : memref<1xf32, 5>
      nvvm.barrier0
      %11 = memref.load %alloca[%0] : memref<1xf32, 5>
      %12 = math.absf %11 : f32
      %13 = arith.addf %12, %cst : f32
      %14 = arith.divf %11, %13 : f32
      memref.store %14, %arg1[%8] : memref<?xf32>
    }
    return
  }
  func.func private @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.cmpi slt, %8, %arg3 : i32
    scf.if %10 {
      %11 = arith.addi %0, %9 : index
      %12 = memref.load %arg0[%11] : memref<?xf32>
      %13 = math.absf %12 : f32
      %14 = arith.addf %13, %cst : f32
      %15 = arith.divf %12, %14 : f32
      memref.store %15, %arg1[%11] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg3) = (%c0) to (%c32) step (%c1) {
      %cst = arith.constant 1.000000e+00 : f32
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = gpu.block_dim  x
      %3 = arith.index_cast %2 : index to i32
      %4 = arith.muli %1, %3 : i32
      %5 = arith.index_cast %arg3 : index to i32
      %6 = arith.addi %4, %5 : i32
      %7 = arith.index_cast %6 : i32 to index
      %8 = arith.cmpi slt, %6, %arg2 : i32
      scf.if %8 {
        %9 = memref.load %arg0[%7] : memref<?xf32>
        memref.store %9, %alloca[%arg3] : memref<1xf32, 5>
        "polygeist.barrier"(%arg3) : (index) -> ()
        %10 = memref.load %alloca[%arg3] : memref<1xf32, 5>
        %11 = math.absf %10 : f32
        %12 = arith.addf %11, %cst : f32
        %13 = arith.divf %10, %12 : f32
        memref.store %13, %arg1[%7] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
  func.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %cst = arith.constant 1.000000e+00 : f32
      %0 = arith.index_cast %arg2 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      %6 = arith.index_cast %arg4 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.cmpi slt, %7, %arg3 : i32
      scf.if %9 {
        %10 = arith.addi %0, %8 : index
        %11 = memref.load %arg0[%10] : memref<?xf32>
        %12 = math.absf %11 : f32
        %13 = arith.addf %12, %cst : f32
        %14 = arith.divf %11, %13 : f32
        memref.store %14, %arg1[%10] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg3) = (%c0) to (%c32) step (%c1) {
      %cst = arith.constant 1.000000e+00 : f32
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = gpu.block_dim  x
      %3 = arith.index_cast %2 : index to i32
      %4 = arith.muli %1, %3 : i32
      %5 = arith.index_cast %arg3 : index to i32
      %6 = arith.addi %4, %5 : i32
      %7 = arith.index_cast %6 : i32 to index
      %8 = arith.cmpi slt, %6, %arg2 : i32
      scf.if %8 {
        %9 = memref.load %arg0[%7] : memref<?xf32>
        memref.store %9, %alloca[%arg3] : memref<1xf32, 5>
        "polygeist.barrier"(%arg3) : (index) -> ()
        %10 = memref.load %alloca[%arg3] : memref<1xf32, 5>
        %11 = math.absf %10 : f32
        %12 = arith.addf %11, %cst : f32
        %13 = arith.divf %10, %12 : f32
        memref.store %13, %arg1[%7] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
  func.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %cst = arith.constant 1.000000e+00 : f32
      %0 = arith.index_cast %arg2 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      %6 = arith.index_cast %arg4 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.cmpi slt, %7, %arg3 : i32
      scf.if %9 {
        %10 = arith.addi %0, %8 : index
        %11 = memref.load %arg0[%10] : memref<?xf32>
        %12 = math.absf %11 : f32
        %13 = arith.addf %12, %cst : f32
        %14 = arith.divf %11, %13 : f32
        memref.store %14, %arg1[%10] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %0 = gpu.block_id  x
    %1 = arith.index_cast %0 : index to i32
    %2 = gpu.block_dim  x
    %3 = arith.index_cast %2 : index to i32
    %4 = arith.muli %1, %3 : i32
    %5 = arith.cmpi slt, %4, %arg2 : i32
    scf.if %5 {
      %alloca = memref.alloca() : memref<32xf32>
      scf.parallel (%arg3) = (%c0) to (%c32) step (%c1) {
        %6 = arith.index_cast %arg3 : index to i32
        %7 = arith.addi %4, %6 : i32
        %8 = arith.index_cast %7 : i32 to index
        %9 = memref.load %arg0[%8] : memref<?xf32>
        memref.store %9, %alloca[%arg3] : memref<32xf32>
        scf.yield
      }
      scf.parallel (%arg3) = (%c0) to (%c32) step (%c1) {
        %6 = memref.load %alloca[%arg3] : memref<32xf32>
        %7 = arith.index_cast %arg3 : index to i32
        %8 = arith.addi %4, %7 : i32
        %9 = arith.index_cast %8 : i32 to index
        %10 = math.absf %6 : f32
        %11 = arith.addf %10, %cst : f32
        %12 = arith.divf %6, %11 : f32
        memref.store %12, %arg1[%9] : memref<?xf32>
        scf.yield
      }
    }
    return
  }
  func.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 1.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %6 = arith.index_cast %arg4 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.index_cast %7 : i32 to index
      %9 = arith.cmpi slt, %7, %arg3 : i32
      scf.if %9 {
        %10 = arith.addi %0, %8 : index
        %11 = memref.load %arg0[%10] : memref<?xf32>
        %12 = math.absf %11 : f32
        %13 = arith.addf %12, %cst : f32
        %14 = arith.divf %11, %13 : f32
        memref.store %14, %arg1[%10] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22softsign_kernel_sharedPKfPfi_0 {
    gpu.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = gpu.block_dim  x
      %3 = arith.index_cast %2 : index to i32
      %4 = arith.muli %1, %3 : i32
      %5 = arith.cmpi slt, %4, %arg2 : i32
      scf.if %5 {
        %alloca = memref.alloca() : memref<32xf32>
        scf.parallel (%arg3) = (%c0) to (%c32) step (%c1) {
          %6 = arith.index_cast %arg3 : index to i32
          %7 = arith.addi %4, %6 : i32
          %8 = arith.index_cast %7 : i32 to index
          %9 = memref.load %arg0[%8] : memref<?xf32>
          memref.store %9, %alloca[%arg3] : memref<32xf32>
          scf.yield
        }
        scf.parallel (%arg3) = (%c0) to (%c32) step (%c1) {
          %6 = memref.load %alloca[%arg3] : memref<32xf32>
          %7 = arith.index_cast %arg3 : index to i32
          %8 = arith.addi %4, %7 : i32
          %9 = arith.index_cast %8 : i32 to index
          %10 = math.absf %6 : f32
          %11 = arith.addf %10, %cst : f32
          %12 = arith.divf %6, %11 : f32
          memref.store %12, %arg1[%9] : memref<?xf32>
          scf.yield
        }
      }
      gpu.return
    }
  }
  gpu.module @_Z22softsign_kernel_streamPKfPfii_1 {
    gpu.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = arith.index_cast %arg2 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %6 = arith.index_cast %arg4 : index to i32
        %7 = arith.addi %5, %6 : i32
        %8 = arith.index_cast %7 : i32 to index
        %9 = arith.cmpi slt, %7, %arg3 : i32
        scf.if %9 {
          %10 = arith.addi %0, %8 : index
          %11 = memref.load %arg0[%10] : memref<?xf32>
          %12 = math.absf %11 : f32
          %13 = arith.addf %12, %cst : f32
          %14 = arith.divf %11, %13 : f32
          memref.store %14, %arg1[%10] : memref<?xf32>
        }
        scf.yield
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22softsign_kernel_sharedPKfPfi_0 {
    gpu.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %c32_0 = arith.constant 32 : index
      %2 = arith.index_cast %c32_0 : index to i32
      %3 = arith.muli %1, %2 : i32
      %4 = arith.cmpi slt, %3, %arg2 : i32
      scf.if %4 {
        %alloca = memref.alloca() : memref<32xf32>
        %c1_1 = arith.constant 1 : index
        scf.for %arg3 = %c0 to %c32 step %c1_1 {
          %5 = arith.index_cast %arg3 : index to i32
          %6 = arith.addi %3, %5 : i32
          %7 = arith.index_cast %6 : i32 to index
          %8 = memref.load %arg0[%7] : memref<?xf32>
          memref.store %8, %alloca[%arg3] : memref<32xf32>
        }
        %c1_2 = arith.constant 1 : index
        scf.for %arg3 = %c0 to %c32 step %c1_2 {
          %5 = memref.load %alloca[%arg3] : memref<32xf32>
          %6 = arith.index_cast %arg3 : index to i32
          %7 = arith.addi %3, %6 : i32
          %8 = arith.index_cast %7 : i32 to index
          %9 = math.absf %5 : f32
          %10 = arith.addf %9, %cst : f32
          %11 = arith.divf %5, %10 : f32
          memref.store %11, %arg1[%8] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
  gpu.module @_Z22softsign_kernel_streamPKfPfii_1 {
    gpu.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = arith.index_cast %arg2 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %c32_0 = arith.constant 32 : index
      %3 = arith.index_cast %c32_0 : index to i32
      %4 = arith.muli %2, %3 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_1 {
        %5 = arith.index_cast %arg4 : index to i32
        %6 = arith.addi %4, %5 : i32
        %7 = arith.index_cast %6 : i32 to index
        %8 = arith.cmpi slt, %6, %arg3 : i32
        scf.if %8 {
          %9 = arith.addi %0, %7 : index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          %11 = math.absf %10 : f32
          %12 = arith.addf %11, %cst : f32
          %13 = arith.divf %10, %12 : f32
          memref.store %13, %arg1[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] GPUBlockIdToNPULowering: process op: 

%0 = gpu.block_id  x
[ict-debug] CastLikeOpToNPULowering: process op: 

%2 = arith.index_cast %1 : index to i32
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca = memref.alloca() : memref<32xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%7 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca = memref.alloca() : memref<32xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22softsign_kernel_sharedPKfPfi_0 {
    gpu.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.block_id"() : () -> i64
      %1 = gpu.block_id  x
      %2 = emitc.cast %0 : i64 to i32
      %3 = arith.index_cast %1 : index to i32
      %c32_0 = arith.constant 32 : index
      %c32_i32 = arith.constant 32 : i32
      %4 = arith.index_cast %c32_0 : index to i32
      %5 = arith.muli %3, %4 : i32
      %6 = arith.cmpi slt, %5, %arg2 : i32
      scf.if %6 {
        %7 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %alloca = memref.alloca() : memref<32xf32, 5>
        %c1_1 = arith.constant 1 : index
        scf.for %arg3 = %c0 to %c32 step %c1_1 {
          %8 = arith.index_cast %arg3 : index to i32
          %9 = arith.addi %5, %8 : i32
          %10 = arith.index_cast %9 : i32 to index
          %11 = memref.load %arg0[%10] : memref<?xf32>
          memref.store %11, %alloca[%arg3] : memref<32xf32, 5>
        }
        %c1_2 = arith.constant 1 : index
        scf.for %arg3 = %c0 to %c32 step %c1_2 {
          %8 = memref.load %alloca[%arg3] : memref<32xf32, 5>
          %9 = arith.index_cast %arg3 : index to i32
          %10 = arith.addi %5, %9 : i32
          %11 = arith.index_cast %10 : i32 to index
          %12 = math.absf %8 : f32
          %13 = arith.addf %12, %cst : f32
          %14 = arith.divf %8, %13 : f32
          memref.store %14, %arg1[%11] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
  gpu.module @_Z22softsign_kernel_streamPKfPfii_1 {
    gpu.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = arith.index_cast %arg2 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %c32_0 = arith.constant 32 : index
      %3 = arith.index_cast %c32_0 : index to i32
      %4 = arith.muli %2, %3 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_1 {
        %5 = arith.index_cast %arg4 : index to i32
        %6 = arith.addi %4, %5 : i32
        %7 = arith.index_cast %6 : i32 to index
        %8 = arith.cmpi slt, %6, %arg3 : i32
        scf.if %8 {
          %9 = arith.addi %0, %7 : index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          %11 = math.absf %10 : f32
          %12 = arith.addf %11, %cst : f32
          %13 = arith.divf %10, %12 : f32
          memref.store %13, %arg1[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] CastLikeOpToNPULowering: process op: 

%9 = arith.index_cast %arg3 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%12 = arith.index_cast %11 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%10 = arith.index_cast %arg3 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%13 = arith.index_cast %12 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%0 = arith.index_cast %arg2 : i32 to index
[ict-debug] GPUBlockIdToNPULowering: process op: 

%2 = gpu.block_id  x
[ict-debug] CastLikeOpToNPULowering: process op: 

%4 = arith.index_cast %3 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%9 = arith.index_cast %arg4 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%12 = arith.index_cast %11 : i32 to index
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22softsign_kernel_sharedPKfPfi_0 {
    gpu.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.block_id"() : () -> i64
      %1 = emitc.cast %0 : i64 to i32
      %c32_0 = arith.constant 32 : index
      %c32_i32 = arith.constant 32 : i32
      %2 = arith.muli %1, %c32_i32 : i32
      %3 = arith.cmpi slt, %2, %arg2 : i32
      scf.if %3 {
        %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %5 = builtin.unrealized_conversion_cast %4 : !llvm.ptr<6> to memref<32xf32, 5>
        %c1_1 = arith.constant 1 : index
        scf.for %arg3 = %c0 to %c32 step %c1_1 {
          %6 = builtin.unrealized_conversion_cast %arg3 : index to i64
          %7 = emitc.cast %6 : i64 to i32
          %8 = arith.addi %2, %7 : i32
          %9 = emitc.cast %8 : i32 to index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          memref.store %10, %5[%arg3] : memref<32xf32, 5>
        }
        %c1_2 = arith.constant 1 : index
        scf.for %arg3 = %c0 to %c32 step %c1_2 {
          %6 = builtin.unrealized_conversion_cast %arg3 : index to i64
          %7 = memref.load %5[%arg3] : memref<32xf32, 5>
          %8 = emitc.cast %6 : i64 to i32
          %9 = arith.addi %2, %8 : i32
          %10 = emitc.cast %9 : i32 to index
          %11 = math.absf %7 : f32
          %12 = emitc.add %11, %cst : (f32, f32) -> f32
          %13 = emitc.div %7, %12 : (f32, f32) -> f32
          memref.store %13, %arg1[%10] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
  gpu.module @_Z22softsign_kernel_streamPKfPfii_1 {
    gpu.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = emitc.cast %arg2 : i32 to index
      %1 = "npu.block_id"() : () -> i64
      %2 = emitc.cast %1 : i64 to i32
      %c32_0 = arith.constant 32 : index
      %c32_i32 = arith.constant 32 : i32
      %3 = arith.muli %2, %c32_i32 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_1 {
        %4 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %5 = emitc.cast %4 : i64 to i32
        %6 = arith.addi %3, %5 : i32
        %7 = emitc.cast %6 : i32 to index
        %8 = arith.cmpi slt, %6, %arg3 : i32
        scf.if %8 {
          %9 = arith.addi %0, %7 : index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          %11 = math.absf %10 : f32
          %12 = emitc.add %11, %cst : (f32, f32) -> f32
          %13 = emitc.div %10, %12 : (f32, f32) -> f32
          memref.store %13, %arg1[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU: end

[ict-debug] driver.cc: Before convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22softsign_kernel_sharedPKfPfi_0 {
    gpu.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) {
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.block_id"() : () -> i64
      %1 = emitc.cast %0 : i64 to i32
      %2 = arith.muli %1, %c32_i32 : i32
      %3 = arith.cmpi slt, %2, %arg2 : i32
      scf.if %3 {
        %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %5 = builtin.unrealized_conversion_cast %4 : !llvm.ptr<6> to memref<32xf32, 5>
        scf.for %arg3 = %c0 to %c32 step %c1 {
          %6 = builtin.unrealized_conversion_cast %arg3 : index to i64
          %7 = emitc.cast %6 : i64 to i32
          %8 = arith.addi %2, %7 : i32
          %9 = emitc.cast %8 : i32 to index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          memref.store %10, %5[%arg3] : memref<32xf32, 5>
        }
        scf.for %arg3 = %c0 to %c32 step %c1 {
          %6 = builtin.unrealized_conversion_cast %arg3 : index to i64
          %7 = memref.load %5[%arg3] : memref<32xf32, 5>
          %8 = emitc.cast %6 : i64 to i32
          %9 = arith.addi %2, %8 : i32
          %10 = emitc.cast %9 : i32 to index
          %11 = math.absf %7 : f32
          %12 = emitc.add %11, %cst : (f32, f32) -> f32
          %13 = emitc.div %7, %12 : (f32, f32) -> f32
          memref.store %13, %arg1[%10] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
  gpu.module @_Z22softsign_kernel_streamPKfPfii_1 {
    gpu.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = emitc.cast %arg2 : i32 to index
      %1 = "npu.block_id"() : () -> i64
      %2 = emitc.cast %1 : i64 to i32
      %3 = arith.muli %2, %c32_i32 : i32
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %4 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %5 = emitc.cast %4 : i64 to i32
        %6 = arith.addi %3, %5 : i32
        %7 = emitc.cast %6 : i32 to index
        %8 = arith.cmpi slt, %6, %arg3 : i32
        scf.if %8 {
          %9 = arith.addi %0, %7 : index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          %11 = math.absf %10 : f32
          %12 = emitc.add %11, %cst : (f32, f32) -> f32
          %13 = emitc.div %10, %12 : (f32, f32) -> f32
          memref.store %13, %arg1[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] driver.cc: Before convert to EmitC dialect: end

[ict-debug] driver.cc: After convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z22softsign_kernel_sharedPKfPfi_0 {
    gpu.func @_Z22softsign_kernel_sharedPKfPfi(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32) {
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.block_id"() : () -> i64
      %1 = emitc.cast %0 : i64 to i32
      %2 = arith.muli %1, %c32_i32 : i32
      %3 = arith.cmpi slt, %2, %arg2 : i32
      emitc.if %3 {
        %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
        %5 = builtin.unrealized_conversion_cast %4 : !llvm.ptr<6> to memref<32xf32, 5>
        scf.for %arg3 = %c0 to %c32 step %c1 {
          %6 = builtin.unrealized_conversion_cast %arg3 : index to i64
          %7 = emitc.cast %6 : i64 to i32
          %8 = arith.addi %2, %7 : i32
          %9 = emitc.cast %8 : i32 to index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          memref.store %10, %5[%arg3] : memref<32xf32, 5>
        }
        scf.for %arg3 = %c0 to %c32 step %c1 {
          %6 = builtin.unrealized_conversion_cast %arg3 : index to i64
          %7 = memref.load %5[%arg3] : memref<32xf32, 5>
          %8 = emitc.cast %6 : i64 to i32
          %9 = arith.addi %2, %8 : i32
          %10 = emitc.cast %9 : i32 to index
          %11 = math.absf %7 : f32
          %12 = emitc.add %11, %cst : (f32, f32) -> f32
          %13 = emitc.div %7, %12 : (f32, f32) -> f32
          memref.store %13, %arg1[%10] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
  gpu.module @_Z22softsign_kernel_streamPKfPfii_1 {
    gpu.func @_Z22softsign_kernel_streamPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 1.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = emitc.cast %arg2 : i32 to index
      %1 = "npu.block_id"() : () -> i64
      %2 = emitc.cast %1 : i64 to i32
      %3 = arith.muli %2, %c32_i32 : i32
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %4 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %5 = emitc.cast %4 : i64 to i32
        %6 = arith.addi %3, %5 : i32
        %7 = emitc.cast %6 : i32 to index
        %8 = arith.cmpi slt, %6, %arg3 : i32
        emitc.if %8 {
          %9 = arith.addi %0, %7 : index
          %10 = memref.load %arg0[%9] : memref<?xf32>
          %11 = math.absf %10 : f32
          %12 = emitc.add %11, %cst : (f32, f32) -> f32
          %13 = emitc.div %10, %12 : (f32, f32) -> f32
          memref.store %13, %arg1[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
  }
}
[ict-debug] driver.cc: After convert to EmitC dialect: end

loc("./cuda_ops/30_Softsign.cu":22:47): error: 'math.absf' op unable to find printer for op
[ict-debug] driver.cc: After emitc::translateToCpp:

