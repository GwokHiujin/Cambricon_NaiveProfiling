warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z37__device_stub__matmul_double_bufferedPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z22matmul_double_bufferedPKfS0_Pfiii(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, i32, i32, i32) -> ()
    return
  }
  func.func private @_Z22matmul_double_bufferedPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c31_i32 = arith.constant 31 : i32
    %c1_i32 = arith.constant 1 : i32
    %false = arith.constant false
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c32_i32 = arith.constant 32 : i32
    %alloca = memref.alloca() : memref<2x32x32xf32>
    %alloca_0 = memref.alloca() : memref<2x32x32xf32>
    %0 = gpu.block_id  y
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.muli %1, %c32_i32 : i32
    %3 = gpu.thread_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.addi %2, %4 : i32
    %6 = arith.muli %5, %arg5 : i32
    %7 = arith.index_cast %6 : i32 to index
    %8 = gpu.block_id  x
    %9 = arith.index_cast %8 : index to i32
    %10 = arith.muli %9, %c32_i32 : i32
    %11 = gpu.thread_id  x
    %12 = arith.index_cast %11 : index to i32
    %13 = arith.addi %10, %12 : i32
    %14 = arith.index_cast %13 : i32 to index
    %15 = arith.cmpi slt, %5, %arg3 : i32
    %16 = scf.if %15 -> (i1) {
      %30 = gpu.thread_id  x
      %31 = arith.index_cast %30 : index to i32
      %32 = arith.cmpi ult, %31, %arg4 : i32
      scf.yield %32 : i1
    } else {
      scf.yield %false : i1
    }
    scf.if %16 {
      %30 = gpu.thread_id  y
      %31 = gpu.thread_id  x
      %32 = arith.index_cast %31 : index to i32
      %33 = arith.muli %5, %arg4 : i32
      %34 = arith.addi %33, %32 : i32
      %35 = arith.index_cast %34 : i32 to index
      %36 = memref.load %arg0[%35] : memref<?xf32>
      memref.store %36, %alloca_0[%c0, %30, %31] : memref<2x32x32xf32>
    } else {
      %30 = gpu.thread_id  y
      %31 = gpu.thread_id  x
      memref.store %cst, %alloca_0[%c0, %30, %31] : memref<2x32x32xf32>
    }
    %17 = arith.cmpi slt, %13, %arg5 : i32
    %18 = scf.if %17 -> (i1) {
      %30 = gpu.thread_id  y
      %31 = arith.index_cast %30 : index to i32
      %32 = arith.cmpi ult, %31, %arg4 : i32
      scf.yield %32 : i1
    } else {
      scf.yield %false : i1
    }
    scf.if %18 {
      %30 = gpu.thread_id  y
      %31 = arith.index_cast %30 : index to i32
      %32 = gpu.thread_id  x
      %33 = arith.muli %31, %arg5 : i32
      %34 = arith.addi %33, %13 : i32
      %35 = arith.index_cast %34 : i32 to index
      %36 = memref.load %arg1[%35] : memref<?xf32>
      memref.store %36, %alloca[%c0, %30, %32] : memref<2x32x32xf32>
    } else {
      %30 = gpu.thread_id  y
      %31 = gpu.thread_id  x
      memref.store %cst, %alloca[%c0, %30, %31] : memref<2x32x32xf32>
    }
    %19 = arith.addi %arg4, %c31_i32 : i32
    %20 = arith.divsi %19, %c32_i32 : i32
    %21 = arith.addi %20, %c-1_i32 : i32
    %22:4 = scf.while (%arg6 = %c0_i32, %arg7 = %c0_i32, %arg8 = %cst) : (i32, i32, f32) -> (i32, i32, f32, f32) {
      %30 = arith.cmpi slt, %arg6, %21 : i32
      %31:4 = scf.if %30 -> (i32, i32, f32, f32) {
        %32 = arith.subi %c1_i32, %arg7 : i32
        %33 = arith.cmpi slt, %5, %arg3 : i32
        %34 = scf.if %33 -> (i1) {
          %43 = arith.addi %arg6, %c1_i32 : i32
          %44 = arith.muli %43, %c32_i32 : i32
          %45 = gpu.thread_id  x
          %46 = arith.index_cast %45 : index to i32
          %47 = arith.addi %44, %46 : i32
          %48 = arith.cmpi ult, %47, %arg4 : i32
          scf.yield %48 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %34 {
          %43 = arith.index_cast %32 : i32 to index
          %44 = gpu.thread_id  y
          %45 = gpu.thread_id  x
          %46 = arith.index_cast %45 : index to i32
          %47 = arith.muli %5, %arg4 : i32
          %48 = arith.addi %arg6, %c1_i32 : i32
          %49 = arith.muli %48, %c32_i32 : i32
          %50 = arith.addi %47, %49 : i32
          %51 = arith.addi %50, %46 : i32
          %52 = arith.index_cast %51 : i32 to index
          %53 = memref.load %arg0[%52] : memref<?xf32>
          memref.store %53, %alloca_0[%43, %44, %45] : memref<2x32x32xf32>
        } else {
          %43 = arith.index_cast %32 : i32 to index
          %44 = gpu.thread_id  y
          %45 = gpu.thread_id  x
          memref.store %cst, %alloca_0[%43, %44, %45] : memref<2x32x32xf32>
        }
        %35 = arith.cmpi slt, %13, %arg5 : i32
        %36 = scf.if %35 -> (i1) {
          %43 = arith.addi %arg6, %c1_i32 : i32
          %44 = arith.muli %43, %c32_i32 : i32
          %45 = gpu.thread_id  y
          %46 = arith.index_cast %45 : index to i32
          %47 = arith.addi %44, %46 : i32
          %48 = arith.cmpi ult, %47, %arg4 : i32
          scf.yield %48 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %36 {
          %43 = arith.index_cast %32 : i32 to index
          %44 = gpu.thread_id  y
          %45 = arith.index_cast %44 : index to i32
          %46 = gpu.thread_id  x
          %47 = arith.addi %arg6, %c1_i32 : i32
          %48 = arith.muli %47, %c32_i32 : i32
          %49 = arith.addi %48, %45 : i32
          %50 = arith.muli %49, %arg5 : i32
          %51 = arith.addi %50, %13 : i32
          %52 = arith.index_cast %51 : i32 to index
          %53 = memref.load %arg1[%52] : memref<?xf32>
          memref.store %53, %alloca[%43, %44, %46] : memref<2x32x32xf32>
        } else {
          %43 = arith.index_cast %32 : i32 to index
          %44 = gpu.thread_id  y
          %45 = gpu.thread_id  x
          memref.store %cst, %alloca[%43, %44, %45] : memref<2x32x32xf32>
        }
        %37 = arith.index_cast %arg7 : i32 to index
        %38 = gpu.thread_id  y
        %39 = gpu.thread_id  x
        %40 = affine.for %arg9 = 0 to 32 iter_args(%arg10 = %arg8) -> (f32) {
          %43 = memref.load %alloca_0[%37, %38, %arg9] : memref<2x32x32xf32>
          %44 = memref.load %alloca[%37, %arg9, %39] : memref<2x32x32xf32>
          %45 = arith.mulf %43, %44 : f32
          %46 = arith.addf %arg10, %45 : f32
          affine.yield %46 : f32
        }
        %41 = arith.addi %arg6, %c1_i32 : i32
        %42 = llvm.mlir.undef : f32
        scf.yield %41, %32, %40, %42 : i32, i32, f32, f32
      } else {
        scf.yield %arg6, %arg7, %arg8, %arg8 : i32, i32, f32, f32
      }
      scf.condition(%30) %31#0, %31#1, %31#2, %31#3 : i32, i32, f32, f32
    } do {
    ^bb0(%arg6: i32, %arg7: i32, %arg8: f32, %arg9: f32):
      scf.yield %arg6, %arg7, %arg8 : i32, i32, f32
    }
    %23 = arith.index_cast %22#1 : i32 to index
    %24 = gpu.thread_id  y
    %25 = gpu.thread_id  x
    %26 = affine.for %arg6 = 0 to 32 iter_args(%arg7 = %22#3) -> (f32) {
      %30 = affine.load %alloca_0[symbol(%23), symbol(%24), %arg6] : memref<2x32x32xf32>
      %31 = affine.load %alloca[symbol(%23), %arg6, symbol(%25)] : memref<2x32x32xf32>
      %32 = arith.mulf %30, %31 : f32
      %33 = arith.addf %arg7, %32 : f32
      affine.yield %33 : f32
    }
    %27 = arith.cmpi slt, %5, %arg3 : i32
    %28 = arith.cmpi slt, %13, %arg5 : i32
    %29 = arith.andi %27, %28 : i1
    scf.if %29 {
      affine.store %26, %arg2[symbol(%7) + symbol(%14)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z22matmul_double_bufferedPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c-1_i32 = arith.constant -1 : i32
    %c31_i32 = arith.constant 31 : i32
    %c1_i32 = arith.constant 1 : i32
    %false = arith.constant false
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c32_i32 = arith.constant 32 : i32
    %alloca = memref.alloca() : memref<2x32x32xf32>
    %alloca_0 = memref.alloca() : memref<2x32x32xf32>
    %0 = gpu.block_id  y
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.muli %1, %c32_i32 : i32
    %3 = gpu.thread_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %4, %arg5 : i32
    %6 = arith.index_cast %5 : i32 to index
    %7 = arith.addi %2, %4 : i32
    %8 = arith.muli %7, %arg4 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %7, %arg5 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = gpu.block_id  x
    %13 = arith.index_cast %12 : index to i32
    %14 = arith.muli %13, %c32_i32 : i32
    %15 = gpu.thread_id  x
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.addi %14, %16 : i32
    %18 = arith.index_cast %17 : i32 to index
    %19 = arith.cmpi slt, %7, %arg3 : i32
    %20 = scf.if %19 -> (i1) {
      %30 = arith.cmpi ult, %16, %arg4 : i32
      scf.yield %30 : i1
    } else {
      scf.yield %false : i1
    }
    scf.if %20 {
      %30 = affine.load %arg0[symbol(%9) + symbol(%15)] : memref<?xf32>
      affine.store %30, %alloca_0[0, symbol(%3), symbol(%15)] : memref<2x32x32xf32>
    } else {
      affine.store %cst, %alloca_0[0, symbol(%3), symbol(%15)] : memref<2x32x32xf32>
    }
    %21 = arith.cmpi slt, %17, %arg5 : i32
    %22 = scf.if %21 -> (i1) {
      %30 = arith.cmpi ult, %4, %arg4 : i32
      scf.yield %30 : i1
    } else {
      scf.yield %false : i1
    }
    scf.if %22 {
      %30 = affine.load %arg1[symbol(%6) + symbol(%18)] : memref<?xf32>
      affine.store %30, %alloca[0, symbol(%3), symbol(%15)] : memref<2x32x32xf32>
    } else {
      affine.store %cst, %alloca[0, symbol(%3), symbol(%15)] : memref<2x32x32xf32>
    }
    %23 = arith.addi %arg4, %c31_i32 : i32
    %24 = arith.divsi %23, %c32_i32 : i32
    %25 = arith.addi %24, %c-1_i32 : i32
    %26:4 = scf.while (%arg6 = %c0_i32, %arg7 = %c0_i32, %arg8 = %cst) : (i32, i32, f32) -> (i32, i32, f32, f32) {
      %30 = arith.cmpi slt, %arg6, %25 : i32
      %31:4 = scf.if %30 -> (i32, i32, f32, f32) {
        %32 = arith.subi %c1_i32, %arg7 : i32
        %33 = scf.if %19 -> (i1) {
          %39 = arith.addi %arg6, %c1_i32 : i32
          %40 = arith.muli %39, %c32_i32 : i32
          %41 = arith.addi %40, %16 : i32
          %42 = arith.cmpi ult, %41, %arg4 : i32
          scf.yield %42 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %33 {
          %39 = arith.index_cast %32 : i32 to index
          %40 = arith.addi %arg6, %c1_i32 : i32
          %41 = arith.muli %40, %c32_i32 : i32
          %42 = arith.addi %8, %41 : i32
          %43 = arith.addi %42, %16 : i32
          %44 = arith.index_cast %43 : i32 to index
          %45 = memref.load %arg0[%44] : memref<?xf32>
          memref.store %45, %alloca_0[%39, %3, %15] : memref<2x32x32xf32>
        } else {
          %39 = arith.index_cast %32 : i32 to index
          memref.store %cst, %alloca_0[%39, %3, %15] : memref<2x32x32xf32>
        }
        %34 = scf.if %21 -> (i1) {
          %39 = arith.addi %arg6, %c1_i32 : i32
          %40 = arith.muli %39, %c32_i32 : i32
          %41 = arith.addi %40, %4 : i32
          %42 = arith.cmpi ult, %41, %arg4 : i32
          scf.yield %42 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %34 {
          %39 = arith.index_cast %32 : i32 to index
          %40 = arith.addi %arg6, %c1_i32 : i32
          %41 = arith.muli %40, %c32_i32 : i32
          %42 = arith.addi %41, %4 : i32
          %43 = arith.muli %42, %arg5 : i32
          %44 = arith.addi %43, %17 : i32
          %45 = arith.index_cast %44 : i32 to index
          %46 = memref.load %arg1[%45] : memref<?xf32>
          memref.store %46, %alloca[%39, %3, %15] : memref<2x32x32xf32>
        } else {
          %39 = arith.index_cast %32 : i32 to index
          memref.store %cst, %alloca[%39, %3, %15] : memref<2x32x32xf32>
        }
        %35 = arith.index_cast %arg7 : i32 to index
        %36 = affine.for %arg9 = 0 to 32 iter_args(%arg10 = %arg8) -> (f32) {
          %39 = memref.load %alloca_0[%35, %3, %arg9] : memref<2x32x32xf32>
          %40 = memref.load %alloca[%35, %arg9, %15] : memref<2x32x32xf32>
          %41 = arith.mulf %39, %40 : f32
          %42 = arith.addf %arg10, %41 : f32
          affine.yield %42 : f32
        }
        %37 = arith.addi %arg6, %c1_i32 : i32
        %38 = llvm.mlir.undef : f32
        scf.yield %37, %32, %36, %38 : i32, i32, f32, f32
      } else {
        scf.yield %arg6, %arg7, %arg8, %arg8 : i32, i32, f32, f32
      }
      scf.condition(%30) %31#0, %31#1, %31#2, %31#3 : i32, i32, f32, f32
    } do {
    ^bb0(%arg6: i32, %arg7: i32, %arg8: f32, %arg9: f32):
      scf.yield %arg6, %arg7, %arg8 : i32, i32, f32
    }
    %27 = arith.index_cast %26#1 : i32 to index
    %28 = affine.for %arg6 = 0 to 32 iter_args(%arg7 = %26#3) -> (f32) {
      %30 = affine.load %alloca_0[symbol(%27), symbol(%3), %arg6] : memref<2x32x32xf32>
      %31 = affine.load %alloca[symbol(%27), %arg6, symbol(%15)] : memref<2x32x32xf32>
      %32 = arith.mulf %30, %31 : f32
      %33 = arith.addf %arg7, %32 : f32
      affine.yield %33 : f32
    }
    %29 = arith.andi %19, %21 : i1
    scf.if %29 {
      affine.store %28, %arg2[symbol(%11) + symbol(%18)] : memref<?xf32>
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z22matmul_double_bufferedPKfS0_Pfiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c31_i32 = arith.constant 31 : i32
    %c1_i32 = arith.constant 1 : i32
    %false = arith.constant false
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c32_i32 = arith.constant 32 : i32
    %alloca = memref.alloca() : memref<2x32x32xf32>
    %alloca_0 = memref.alloca() : memref<2x32x32xf32>
    %0 = gpu.block_id  y
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.muli %1, %c32_i32 : i32
    %3 = gpu.thread_id  y
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %4, %arg5 : i32
    %6 = arith.index_cast %5 : i32 to index
    %7 = arith.addi %2, %4 : i32
    %8 = arith.muli %7, %arg4 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %7, %arg5 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = gpu.block_id  x
    %13 = arith.index_cast %12 : index to i32
    %14 = arith.muli %13, %c32_i32 : i32
    %15 = gpu.thread_id  x
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.addi %14, %16 : i32
    %18 = arith.index_cast %17 : i32 to index
    %19 = arith.cmpi slt, %7, %arg3 : i32
    %20 = scf.if %19 -> (i1) {
      %30 = arith.cmpi ult, %16, %arg4 : i32
      scf.yield %30 : i1
    } else {
      scf.yield %false : i1
    }
    scf.if %20 {
      %30 = arith.addi %9, %15 : index
      %31 = memref.load %arg0[%30] : memref<?xf32>
      memref.store %31, %alloca_0[%c0, %3, %15] : memref<2x32x32xf32>
    } else {
      memref.store %cst, %alloca_0[%c0, %3, %15] : memref<2x32x32xf32>
    }
    %21 = arith.cmpi slt, %17, %arg5 : i32
    %22 = scf.if %21 -> (i1) {
      %30 = arith.cmpi ult, %4, %arg4 : i32
      scf.yield %30 : i1
    } else {
      scf.yield %false : i1
    }
    scf.if %22 {
      %30 = arith.addi %6, %18 : index
      %31 = memref.load %arg1[%30] : memref<?xf32>
      memref.store %31, %alloca[%c0, %3, %15] : memref<2x32x32xf32>
    } else {
      memref.store %cst, %alloca[%c0, %3, %15] : memref<2x32x32xf32>
    }
    %23 = arith.addi %arg4, %c31_i32 : i32
    %24 = arith.divsi %23, %c32_i32 : i32
    %25 = arith.addi %24, %c-1_i32 : i32
    %26:4 = scf.while (%arg6 = %c0_i32, %arg7 = %c0_i32, %arg8 = %cst) : (i32, i32, f32) -> (i32, i32, f32, f32) {
      %30 = arith.cmpi slt, %arg6, %25 : i32
      %31:4 = scf.if %30 -> (i32, i32, f32, f32) {
        %32 = arith.subi %c1_i32, %arg7 : i32
        %33 = scf.if %19 -> (i1) {
          %39 = arith.addi %arg6, %c1_i32 : i32
          %40 = arith.muli %39, %c32_i32 : i32
          %41 = arith.addi %40, %16 : i32
          %42 = arith.cmpi ult, %41, %arg4 : i32
          scf.yield %42 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %33 {
          %39 = arith.index_cast %32 : i32 to index
          %40 = arith.addi %arg6, %c1_i32 : i32
          %41 = arith.muli %40, %c32_i32 : i32
          %42 = arith.addi %8, %41 : i32
          %43 = arith.addi %42, %16 : i32
          %44 = arith.index_cast %43 : i32 to index
          %45 = memref.load %arg0[%44] : memref<?xf32>
          memref.store %45, %alloca_0[%39, %3, %15] : memref<2x32x32xf32>
        } else {
          %39 = arith.index_cast %32 : i32 to index
          memref.store %cst, %alloca_0[%39, %3, %15] : memref<2x32x32xf32>
        }
        %34 = scf.if %21 -> (i1) {
          %39 = arith.addi %arg6, %c1_i32 : i32
          %40 = arith.muli %39, %c32_i32 : i32
          %41 = arith.addi %40, %4 : i32
          %42 = arith.cmpi ult, %41, %arg4 : i32
          scf.yield %42 : i1
        } else {
          scf.yield %false : i1
        }
        scf.if %34 {
          %39 = arith.index_cast %32 : i32 to index
          %40 = arith.addi %arg6, %c1_i32 : i32
          %41 = arith.muli %40, %c32_i32 : i32
          %42 = arith.addi %41, %4 : i32
          %43 = arith.muli %42, %arg5 : i32
          %44 = arith.addi %43, %17 : i32
          %45 = arith.index_cast %44 : i32 to index
          %46 = memref.load %arg1[%45] : memref<?xf32>
          memref.store %46, %alloca[%39, %3, %15] : memref<2x32x32xf32>
        } else {
          %39 = arith.index_cast %32 : i32 to index
          memref.store %cst, %alloca[%39, %3, %15] : memref<2x32x32xf32>
        }
        %35 = arith.index_cast %arg7 : i32 to index
        %36 = scf.for %arg9 = %c0 to %c32 step %c1 iter_args(%arg10 = %arg8) -> (f32) {
          %39 = memref.load %alloca_0[%35, %3, %arg9] : memref<2x32x32xf32>
          %40 = memref.load %alloca[%35, %arg9, %15] : memref<2x32x32xf32>
          %41 = arith.mulf %39, %40 : f32
          %42 = arith.addf %arg10, %41 : f32
          scf.yield %42 : f32
        }
        %37 = arith.addi %arg6, %c1_i32 : i32
        %38 = llvm.mlir.undef : f32
        scf.yield %37, %32, %36, %38 : i32, i32, f32, f32
      } else {
        scf.yield %arg6, %arg7, %arg8, %arg8 : i32, i32, f32, f32
      }
      scf.condition(%30) %31#0, %31#1, %31#2, %31#3 : i32, i32, f32, f32
    } do {
    ^bb0(%arg6: i32, %arg7: i32, %arg8: f32, %arg9: f32):
      scf.yield %arg6, %arg7, %arg8 : i32, i32, f32
    }
    %27 = arith.index_cast %26#1 : i32 to index
    %28 = scf.for %arg6 = %c0 to %c32 step %c1 iter_args(%arg7 = %26#3) -> (f32) {
      %30 = memref.load %alloca_0[%27, %3, %arg6] : memref<2x32x32xf32>
      %31 = memref.load %alloca[%27, %arg6, %15] : memref<2x32x32xf32>
      %32 = arith.mulf %30, %31 : f32
      %33 = arith.addf %arg7, %32 : f32
      scf.yield %33 : f32
    }
    %29 = arith.andi %19, %21 : i1
    scf.if %29 {
      %30 = arith.addi %11, %18 : index
      memref.store %28, %arg2[%30] : memref<?xf32>
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-error] WrapAndReplaceBarrierPass::runOnOperation(): gpuThreadIdOp.getDimension() != gpu::Dimension::x

