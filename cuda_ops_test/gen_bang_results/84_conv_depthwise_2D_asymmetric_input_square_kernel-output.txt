warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z63__device_stub__depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, memref<?xf32>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) -> ()
    return
  }
  func.func private @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c32_i32 = arith.constant 32 : i32
    %c31_i32 = arith.constant 31 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i32 = arith.constant 0 : i32
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = arith.index_cast %arg9 : i32 to index
    %1 = arith.index_cast %arg12 : i32 to index
    %2 = arith.index_cast %arg12 : i32 to index
    %3 = arith.index_cast %arg12 : i32 to index
    %4 = arith.index_cast %arg12 : i32 to index
    %5 = arith.index_cast %arg12 : i32 to index
    %6 = arith.index_cast %arg12 : i32 to index
    %7 = arith.index_cast %arg12 : i32 to index
    %8 = arith.index_cast %arg12 : i32 to index
    %9 = arith.index_cast %arg12 : i32 to index
    %10 = arith.index_cast %arg12 : i32 to index
    %11 = arith.index_cast %arg11 : i32 to index
    %12 = arith.index_cast %arg10 : i32 to index
    %13 = llvm.mlir.undef : i32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %14 = gpu.block_id  z
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.divsi %15, %arg8 : i32
    %17 = arith.remsi %15, %arg8 : i32
    %18 = arith.index_cast %17 : i32 to index
    %19 = arith.divsi %17, %arg14 : i32
    %20 = arith.remsi %17, %arg14 : i32
    %21 = gpu.block_id  x
    %22 = arith.index_cast %21 : index to i32
    %23 = arith.muli %22, %c32_i32 : i32
    %24 = gpu.block_id  y
    %25 = arith.index_cast %24 : index to i32
    %26 = arith.muli %25, %c32_i32 : i32
    %27 = arith.muli %23, %arg12 : i32
    %28 = arith.subi %27, %arg13 : i32
    %29 = arith.muli %26, %arg12 : i32
    %30 = arith.subi %29, %arg13 : i32
    %31 = arith.muli %arg12, %c31_i32 : i32
    %32 = arith.addi %31, %arg11 : i32
    %33 = arith.index_cast %32 : i32 to index
    %34 = arith.index_cast %32 : i32 to index
    %35 = arith.index_cast %32 : i32 to index
    %36 = arith.index_cast %32 : i32 to index
    %37 = arith.index_cast %32 : i32 to index
    %38 = arith.index_cast %32 : i32 to index
    %39 = arith.index_cast %32 : i32 to index
    %40 = arith.index_cast %32 : i32 to index
    %41 = arith.index_cast %32 : i32 to index
    %42 = arith.index_cast %32 : i32 to index
    %43 = arith.muli %32, %32 : i32
    %44 = arith.index_cast %43 : i32 to index
    %45 = gpu.thread_id  x
    %46 = gpu.block_dim  x
    %47 = arith.muli %arg11, %arg11 : i32
    %48 = arith.index_cast %47 : i32 to index
    %49 = arith.muli %arg14, %arg11 : i32
    %50 = arith.muli %49, %arg11 : i32
    %51 = arith.muli %19, %50 : i32
    %52 = arith.muli %arg11, %arg11 : i32
    %53 = arith.muli %20, %52 : i32
    %54 = arith.addi %51, %53 : i32
    %55 = arith.index_cast %54 : i32 to index
    %56 = arith.subi %48, %45 : index
    %57 = arith.subi %46, %c1 : index
    %58 = arith.addi %57, %56 : index
    %59 = arith.divui %58, %46 : index
    affine.for %arg15 = 0 to %59 {
      %89 = affine.load %arg1[%arg15 * symbol(%46) + symbol(%55) + symbol(%45)] : memref<?xf32>
      affine.store %89, %alloca[%arg15 * symbol(%46) + symbol(%45) + symbol(%44)] : memref<1xf32, 5>
    }
    %60 = arith.muli %32, %32 : i32
    %61 = arith.index_cast %60 : i32 to index
    %62 = arith.muli %arg5, %arg6 : i32
    %63 = arith.muli %62, %arg7 : i32
    %64 = arith.muli %16, %63 : i32
    %65 = arith.muli %arg6, %arg7 : i32
    %66 = arith.muli %19, %65 : i32
    %67 = arith.addi %64, %66 : i32
    %68 = arith.subi %61, %45 : index
    %69 = arith.subi %46, %c1 : index
    %70 = arith.addi %69, %68 : index
    %71 = arith.divui %70, %46 : index
    affine.for %arg15 = 0 to %71 {
      %89 = arith.muli %arg15, %46 : index
      %90 = arith.divui %89, %46 : index
      %91 = arith.muli %90, %46 : index
      %92 = arith.addi %45, %91 : index
      %93 = arith.index_cast %92 : index to i32
      %94 = arith.divsi %93, %32 : i32
      %95 = arith.remsi %93, %32 : i32
      %96 = arith.addi %30, %94 : i32
      %97 = arith.addi %28, %95 : i32
      %98 = arith.cmpi sge, %96, %c0_i32 : i32
      %99 = arith.cmpi slt, %96, %arg6 : i32
      %100 = arith.cmpi sge, %97, %c0_i32 : i32
      %101 = arith.cmpi slt, %97, %arg7 : i32
      %102 = arith.andi %100, %101 : i1
      %103 = arith.andi %99, %102 : i1
      %104 = arith.andi %98, %103 : i1
      %105 = scf.if %104 -> (f32) {
        %106 = arith.muli %96, %arg7 : i32
        %107 = arith.addi %67, %106 : i32
        %108 = arith.addi %107, %97 : i32
        %109 = arith.index_cast %108 : i32 to index
        %110 = memref.load %arg0[%109] : memref<?xf32>
        scf.yield %110 : f32
      } else {
        scf.yield %cst : f32
      }
      affine.store %105, %alloca[%arg15 * symbol(%46) + symbol(%45)] : memref<1xf32, 5>
    }
    nvvm.barrier0
    %72 = arith.index_cast %arg11 : i32 to index
    %73 = arith.index_cast %arg11 : i32 to index
    %74 = llvm.mlir.zero : !llvm.ptr
    %75 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
    %76 = llvm.icmp "ne" %75, %74 : !llvm.ptr
    %77 = arith.muli %arg8, %arg9 : i32
    %78 = arith.muli %77, %arg10 : i32
    %79 = arith.muli %16, %78 : i32
    %80 = arith.muli %arg9, %arg10 : i32
    %81 = arith.muli %17, %80 : i32
    %82 = arith.addi %79, %81 : i32
    %83 = arith.index_cast %82 : i32 to index
    %84 = arith.subi %c1024, %45 : index
    %85 = arith.subi %46, %c1 : index
    %86 = arith.addi %85, %84 : index
    %87 = arith.divui %86, %46 : index
    %88:3 = affine.for %arg15 = 0 to %87 iter_args(%arg16 = %13, %arg17 = %13, %arg18 = %13) -> (i32, i32, i32) {
      %89 = arith.muli %arg15, %46 : index
      %90 = arith.divui %89, %46 : index
      %91 = arith.muli %90, %46 : index
      %92 = arith.addi %45, %91 : index
      %93 = arith.index_cast %92 : index to i32
      %94 = arith.divsi %93, %c32_i32 : i32
      %95 = arith.remsi %93, %c32_i32 : i32
      %96:3 = affine.if affine_set<(d0)[s0, s1, s2, s3, s4, s5] : (-(d0 * s2) - s0 * 32 - s1 + s3 + ((d0 * s2 + s1) floordiv 32) * 32 - 1 >= 0, -((d0 * s2 + s1) floordiv 32) + s4 * -32 + s5 - 1 >= 0)>(%arg15)[%21, %45, %46, %12, %24, %0] -> (i32, i32, i32) {
        %97:4 = affine.if affine_set<()[s0] : (s0 - 3 == 0)>()[%11] -> (i32, i32, i32, f32) {
          %99 = affine.load %alloca[((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%1) + (((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%1)) * symbol(%33)] : memref<1xf32, 5>
          %100 = affine.load %alloca[symbol(%44)] : memref<1xf32, 5>
          %101 = arith.mulf %99, %100 : f32
          %102 = arith.addf %101, %cst : f32
          %103 = affine.load %alloca[(((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%2)) * symbol(%34) + ((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%2) + 1] : memref<1xf32, 5>
          %104 = affine.load %alloca[symbol(%44) + 1] : memref<1xf32, 5>
          %105 = arith.mulf %103, %104 : f32
          %106 = arith.addf %102, %105 : f32
          %107 = affine.load %alloca[(((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%3)) * symbol(%35) + ((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%3) + 2] : memref<1xf32, 5>
          %108 = affine.load %alloca[symbol(%44) + 2] : memref<1xf32, 5>
          %109 = arith.mulf %107, %108 : f32
          %110 = arith.addf %106, %109 : f32
          %111 = affine.load %alloca[((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%4) + (((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%4) + 1) * symbol(%36)] : memref<1xf32, 5>
          %112 = affine.load %alloca[symbol(%44) + 3] : memref<1xf32, 5>
          %113 = arith.mulf %111, %112 : f32
          %114 = arith.addf %110, %113 : f32
          %115 = affine.load %alloca[((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%5) + (((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%5) + 1) * symbol(%37) + 1] : memref<1xf32, 5>
          %116 = affine.load %alloca[symbol(%44) + 4] : memref<1xf32, 5>
          %117 = arith.mulf %115, %116 : f32
          %118 = arith.addf %114, %117 : f32
          %119 = affine.load %alloca[((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%6) + (((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%6) + 1) * symbol(%38) + 2] : memref<1xf32, 5>
          %120 = affine.load %alloca[symbol(%44) + 5] : memref<1xf32, 5>
          %121 = arith.mulf %119, %120 : f32
          %122 = arith.addf %118, %121 : f32
          %123 = affine.load %alloca[((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%7) + (((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%7) + 2) * symbol(%39)] : memref<1xf32, 5>
          %124 = affine.load %alloca[symbol(%44) + 6] : memref<1xf32, 5>
          %125 = arith.mulf %123, %124 : f32
          %126 = arith.addf %122, %125 : f32
          %127 = affine.load %alloca[((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%8) + (((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%8) + 2) * symbol(%40) + 1] : memref<1xf32, 5>
          %128 = affine.load %alloca[symbol(%44) + 7] : memref<1xf32, 5>
          %129 = arith.mulf %127, %128 : f32
          %130 = arith.addf %126, %129 : f32
          %131 = affine.load %alloca[((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%9) + (((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%9) + 2) * symbol(%41) + 2] : memref<1xf32, 5>
          %132 = affine.load %alloca[symbol(%44) + 8] : memref<1xf32, 5>
          %133 = arith.mulf %131, %132 : f32
          %134 = arith.addf %130, %133 : f32
          affine.yield %arg16, %arg17, %arg18, %134 : i32, i32, i32, f32
        } else {
          %99 = arith.muli %94, %arg12 : i32
          %100 = arith.muli %95, %arg12 : i32
          %101:4 = affine.for %arg19 = 0 to %72 iter_args(%arg20 = %arg16, %arg21 = %arg17, %arg22 = %cst, %arg23 = %arg18) -> (i32, i32, f32, i32) {
            %102 = arith.index_cast %arg19 : index to i32
            %103 = arith.addi %99, %102 : i32
            %104:3 = affine.for %arg24 = 0 to %73 iter_args(%arg25 = %arg22, %arg26 = %arg20, %arg27 = %arg21) -> (f32, i32, i32) {
              %105 = arith.index_cast %arg24 : index to i32
              %106 = arith.addi %100, %105 : i32
              %107 = affine.load %alloca[%arg24 + ((%arg15 * symbol(%46) + symbol(%45)) mod 32) * symbol(%10) + (%arg19 + ((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * symbol(%10)) * symbol(%42)] : memref<1xf32, 5>
              %108 = affine.load %alloca[%arg24 + %arg19 * symbol(%11) + symbol(%44)] : memref<1xf32, 5>
              %109 = arith.mulf %107, %108 : f32
              %110 = arith.addf %arg25, %109 : f32
              affine.yield %110, %106, %103 : f32, i32, i32
            }
            affine.yield %104#1, %104#2, %104#0, %arg11 : i32, i32, f32, i32
          }
          affine.yield %101#0, %101#1, %101#3, %101#2 : i32, i32, i32, f32
        }
        %98 = scf.if %76 -> (f32) {
          %99 = affine.load %arg2[symbol(%18)] : memref<?xf32>
          %100 = arith.addf %97#3, %99 : f32
          scf.yield %100 : f32
        } else {
          scf.yield %97#3 : f32
        }
        affine.store %98, %arg3[%arg15 * symbol(%46) + symbol(%83) + symbol(%45) + symbol(%21) * 32 - ((%arg15 * symbol(%46) + symbol(%45)) floordiv 32) * 32 + ((%arg15 * symbol(%46) + symbol(%45)) floordiv 32 + symbol(%24) * 32) * symbol(%12)] : memref<?xf32>
        affine.yield %97#0, %97#1, %97#2 : i32, i32, i32
      } else {
        affine.yield %arg16, %arg17, %arg18 : i32, i32, i32
      }
      affine.yield %96#0, %96#1, %96#2 : i32, i32, i32
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c32_i32 = arith.constant 32 : i32
    %c31_i32 = arith.constant 31 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i32 = arith.constant 0 : i32
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = arith.index_cast %arg9 : i32 to index
    %1 = arith.index_cast %arg12 : i32 to index
    %2 = arith.index_cast %arg11 : i32 to index
    %3 = arith.index_cast %arg10 : i32 to index
    %4 = llvm.mlir.undef : i32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %5 = gpu.block_id  z
    %6 = arith.index_cast %5 : index to i32
    %7 = arith.divsi %6, %arg8 : i32
    %8 = arith.remsi %6, %arg8 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.divsi %8, %arg14 : i32
    %11 = arith.remsi %8, %arg14 : i32
    %12 = gpu.block_id  x
    %13 = arith.index_cast %12 : index to i32
    %14 = arith.muli %13, %c32_i32 : i32
    %15 = gpu.block_id  y
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.muli %16, %c32_i32 : i32
    %18 = arith.muli %14, %arg12 : i32
    %19 = arith.subi %18, %arg13 : i32
    %20 = arith.muli %17, %arg12 : i32
    %21 = arith.subi %20, %arg13 : i32
    %22 = arith.muli %arg12, %c31_i32 : i32
    %23 = arith.addi %22, %arg11 : i32
    %24 = arith.index_cast %23 : i32 to index
    %25 = arith.muli %23, %23 : i32
    %26 = arith.index_cast %25 : i32 to index
    %27 = gpu.thread_id  x
    %28 = gpu.block_dim  x
    %29 = arith.muli %arg11, %arg11 : i32
    %30 = arith.index_cast %29 : i32 to index
    %31 = arith.muli %arg14, %arg11 : i32
    %32 = arith.muli %31, %arg11 : i32
    %33 = arith.muli %10, %32 : i32
    %34 = arith.muli %11, %29 : i32
    %35 = arith.addi %33, %34 : i32
    %36 = arith.index_cast %35 : i32 to index
    %37 = arith.subi %30, %27 : index
    %38 = arith.subi %28, %c1 : index
    %39 = arith.addi %38, %37 : index
    %40 = arith.divui %39, %28 : index
    affine.for %arg15 = 0 to %40 {
      %69 = affine.load %arg1[%arg15 * symbol(%28) + symbol(%36) + symbol(%27)] : memref<?xf32>
      affine.store %69, %alloca[%arg15 * symbol(%28) + symbol(%27) + symbol(%26)] : memref<1xf32, 5>
    }
    %41 = arith.muli %arg5, %arg6 : i32
    %42 = arith.muli %41, %arg7 : i32
    %43 = arith.muli %7, %42 : i32
    %44 = arith.muli %arg6, %arg7 : i32
    %45 = arith.muli %10, %44 : i32
    %46 = arith.addi %43, %45 : i32
    %47 = arith.subi %26, %27 : index
    %48 = arith.addi %38, %47 : index
    %49 = arith.divui %48, %28 : index
    affine.for %arg15 = 0 to %49 {
      %69 = arith.muli %arg15, %28 : index
      %70 = arith.addi %27, %69 : index
      %71 = arith.index_cast %70 : index to i32
      %72 = arith.divsi %71, %23 : i32
      %73 = arith.remsi %71, %23 : i32
      %74 = arith.addi %21, %72 : i32
      %75 = arith.addi %19, %73 : i32
      %76 = arith.cmpi sge, %74, %c0_i32 : i32
      %77 = arith.cmpi slt, %74, %arg6 : i32
      %78 = arith.cmpi sge, %75, %c0_i32 : i32
      %79 = arith.cmpi slt, %75, %arg7 : i32
      %80 = arith.andi %78, %79 : i1
      %81 = arith.andi %77, %80 : i1
      %82 = arith.andi %76, %81 : i1
      %83 = scf.if %82 -> (f32) {
        %84 = arith.muli %74, %arg7 : i32
        %85 = arith.addi %46, %84 : i32
        %86 = arith.addi %85, %75 : i32
        %87 = arith.index_cast %86 : i32 to index
        %88 = memref.load %arg0[%87] : memref<?xf32>
        scf.yield %88 : f32
      } else {
        scf.yield %cst : f32
      }
      affine.store %83, %alloca[%arg15 * symbol(%28) + symbol(%27)] : memref<1xf32, 5>
    }
    nvvm.barrier0
    %50 = llvm.mlir.zero : !llvm.ptr
    %51 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
    %52 = llvm.icmp "ne" %51, %50 : !llvm.ptr
    %53 = arith.muli %arg8, %arg9 : i32
    %54 = arith.muli %53, %arg10 : i32
    %55 = arith.muli %7, %54 : i32
    %56 = arith.muli %arg9, %arg10 : i32
    %57 = arith.muli %8, %56 : i32
    %58 = arith.addi %55, %57 : i32
    %59 = arith.index_cast %58 : i32 to index
    %60 = arith.subi %c1024, %27 : index
    %61 = arith.addi %38, %60 : index
    %62 = arith.divui %61, %28 : index
    %63 = arith.muli %12, %c-32 : index
    %64 = arith.muli %15, %c-32 : index
    %65 = arith.addi %64, %0 : index
    %66 = arith.muli %12, %c32 : index
    %67 = arith.muli %15, %c32 : index
    %68:3 = affine.for %arg15 = 0 to %62 iter_args(%arg16 = %4, %arg17 = %4, %arg18 = %4) -> (i32, i32, i32) {
      %69 = arith.muli %arg15, %28 : index
      %70 = arith.addi %27, %69 : index
      %71 = arith.index_cast %70 : index to i32
      %72 = arith.divsi %71, %c32_i32 : i32
      %73 = arith.remsi %71, %c32_i32 : i32
      %74 = arith.subi %63, %69 : index
      %75 = arith.subi %74, %27 : index
      %76 = arith.addi %75, %3 : index
      %77 = arith.addi %69, %27 : index
      %78 = arith.cmpi slt, %77, %c0 : index
      %79 = arith.subi %c-1, %77 : index
      %80 = arith.select %78, %79, %77 : index
      %81 = arith.divsi %80, %c32 : index
      %82 = arith.subi %c-1, %81 : index
      %83 = arith.select %78, %82, %81 : index
      %84 = arith.muli %83, %c32 : index
      %85 = arith.addi %76, %84 : index
      %86 = arith.addi %85, %c-1 : index
      %87 = arith.cmpi sge, %86, %c0 : index
      %88 = arith.subi %65, %83 : index
      %89 = arith.addi %88, %c-1 : index
      %90 = arith.cmpi sge, %89, %c0 : index
      %91 = arith.andi %87, %90 : i1
      %92:3 = scf.if %91 -> (i32, i32, i32) {
        %93:4 = affine.if affine_set<()[s0] : (s0 - 3 == 0)>()[%2] -> (i32, i32, i32, f32) {
          %103 = arith.remsi %77, %c32 : index
          %104 = arith.cmpi slt, %103, %c0 : index
          %105 = arith.addi %103, %c32 : index
          %106 = arith.select %104, %105, %103 : index
          %107 = arith.muli %106, %1 : index
          %108 = arith.muli %83, %1 : index
          %109 = arith.muli %108, %24 : index
          %110 = arith.addi %107, %109 : index
          %111 = memref.load %alloca[%110] : memref<1xf32, 5>
          %112 = affine.load %alloca[symbol(%26)] : memref<1xf32, 5>
          %113 = arith.mulf %111, %112 : f32
          %114 = arith.addf %113, %cst : f32
          %115 = arith.addi %109, %107 : index
          %116 = arith.addi %115, %c1 : index
          %117 = memref.load %alloca[%116] : memref<1xf32, 5>
          %118 = affine.load %alloca[symbol(%26) + 1] : memref<1xf32, 5>
          %119 = arith.mulf %117, %118 : f32
          %120 = arith.addf %114, %119 : f32
          %121 = arith.addi %115, %c2 : index
          %122 = memref.load %alloca[%121] : memref<1xf32, 5>
          %123 = affine.load %alloca[symbol(%26) + 2] : memref<1xf32, 5>
          %124 = arith.mulf %122, %123 : f32
          %125 = arith.addf %120, %124 : f32
          %126 = arith.addi %108, %c1 : index
          %127 = arith.muli %126, %24 : index
          %128 = arith.addi %107, %127 : index
          %129 = memref.load %alloca[%128] : memref<1xf32, 5>
          %130 = affine.load %alloca[symbol(%26) + 3] : memref<1xf32, 5>
          %131 = arith.mulf %129, %130 : f32
          %132 = arith.addf %125, %131 : f32
          %133 = arith.addi %128, %c1 : index
          %134 = memref.load %alloca[%133] : memref<1xf32, 5>
          %135 = affine.load %alloca[symbol(%26) + 4] : memref<1xf32, 5>
          %136 = arith.mulf %134, %135 : f32
          %137 = arith.addf %132, %136 : f32
          %138 = arith.addi %128, %c2 : index
          %139 = memref.load %alloca[%138] : memref<1xf32, 5>
          %140 = affine.load %alloca[symbol(%26) + 5] : memref<1xf32, 5>
          %141 = arith.mulf %139, %140 : f32
          %142 = arith.addf %137, %141 : f32
          %143 = arith.addi %108, %c2 : index
          %144 = arith.muli %143, %24 : index
          %145 = arith.addi %107, %144 : index
          %146 = memref.load %alloca[%145] : memref<1xf32, 5>
          %147 = affine.load %alloca[symbol(%26) + 6] : memref<1xf32, 5>
          %148 = arith.mulf %146, %147 : f32
          %149 = arith.addf %142, %148 : f32
          %150 = arith.addi %145, %c1 : index
          %151 = memref.load %alloca[%150] : memref<1xf32, 5>
          %152 = affine.load %alloca[symbol(%26) + 7] : memref<1xf32, 5>
          %153 = arith.mulf %151, %152 : f32
          %154 = arith.addf %149, %153 : f32
          %155 = arith.addi %145, %c2 : index
          %156 = memref.load %alloca[%155] : memref<1xf32, 5>
          %157 = affine.load %alloca[symbol(%26) + 8] : memref<1xf32, 5>
          %158 = arith.mulf %156, %157 : f32
          %159 = arith.addf %154, %158 : f32
          affine.yield %arg16, %arg17, %arg18, %159 : i32, i32, i32, f32
        } else {
          %103 = arith.muli %72, %arg12 : i32
          %104 = arith.muli %73, %arg12 : i32
          %105 = arith.remsi %77, %c32 : index
          %106 = arith.cmpi slt, %105, %c0 : index
          %107 = arith.addi %105, %c32 : index
          %108 = arith.select %106, %107, %105 : index
          %109 = arith.muli %108, %1 : index
          %110 = arith.muli %83, %1 : index
          %111:4 = affine.for %arg19 = 0 to %2 iter_args(%arg20 = %arg16, %arg21 = %arg17, %arg22 = %cst, %arg23 = %arg18) -> (i32, i32, f32, i32) {
            %112 = arith.index_cast %arg19 : index to i32
            %113 = arith.addi %103, %112 : i32
            %114 = arith.addi %arg19, %110 : index
            %115 = arith.muli %114, %24 : index
            %116:3 = affine.for %arg24 = 0 to %2 iter_args(%arg25 = %arg22, %arg26 = %arg20, %arg27 = %arg21) -> (f32, i32, i32) {
              %117 = arith.index_cast %arg24 : index to i32
              %118 = arith.addi %104, %117 : i32
              %119 = arith.addi %arg24, %109 : index
              %120 = arith.addi %119, %115 : index
              %121 = memref.load %alloca[%120] : memref<1xf32, 5>
              %122 = affine.load %alloca[%arg24 + %arg19 * symbol(%2) + symbol(%26)] : memref<1xf32, 5>
              %123 = arith.mulf %121, %122 : f32
              %124 = arith.addf %arg25, %123 : f32
              affine.yield %124, %118, %113 : f32, i32, i32
            }
            affine.yield %116#1, %116#2, %116#0, %arg11 : i32, i32, f32, i32
          }
          affine.yield %111#0, %111#1, %111#3, %111#2 : i32, i32, i32, f32
        }
        %94 = scf.if %52 -> (f32) {
          %103 = affine.load %arg2[symbol(%9)] : memref<?xf32>
          %104 = arith.addf %93#3, %103 : f32
          scf.yield %104 : f32
        } else {
          scf.yield %93#3 : f32
        }
        %95 = arith.addi %69, %59 : index
        %96 = arith.addi %95, %27 : index
        %97 = arith.addi %96, %66 : index
        %98 = arith.muli %83, %c-32 : index
        %99 = arith.addi %97, %98 : index
        %100 = arith.addi %83, %67 : index
        %101 = arith.muli %100, %3 : index
        %102 = arith.addi %99, %101 : index
        memref.store %94, %arg3[%102] : memref<?xf32>
        scf.yield %93#0, %93#1, %93#2 : i32, i32, i32
      } else {
        scf.yield %arg16, %arg17, %arg18 : i32, i32, i32
      }
      affine.yield %92#0, %92#1, %92#2 : i32, i32, i32
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c8 = arith.constant 8 : index
    %c7 = arith.constant 7 : index
    %c6 = arith.constant 6 : index
    %c5 = arith.constant 5 : index
    %c4 = arith.constant 4 : index
    %c3 = arith.constant 3 : index
    %c-3 = arith.constant -3 : index
    %c2 = arith.constant 2 : index
    %c32 = arith.constant 32 : index
    %c-32 = arith.constant -32 : index
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c32_i32 = arith.constant 32 : i32
    %c31_i32 = arith.constant 31 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i32 = arith.constant 0 : i32
    %c1024 = arith.constant 1024 : index
    %c1 = arith.constant 1 : index
    %0 = arith.index_cast %arg9 : i32 to index
    %1 = arith.index_cast %arg12 : i32 to index
    %2 = arith.index_cast %arg11 : i32 to index
    %3 = arith.index_cast %arg10 : i32 to index
    %4 = llvm.mlir.undef : i32
    %alloca = memref.alloca() : memref<1xf32, 5>
    %5 = gpu.block_id  z
    %6 = arith.index_cast %5 : index to i32
    %7 = arith.divsi %6, %arg8 : i32
    %8 = arith.remsi %6, %arg8 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.divsi %8, %arg14 : i32
    %11 = arith.remsi %8, %arg14 : i32
    %12 = gpu.block_id  x
    %13 = arith.index_cast %12 : index to i32
    %14 = arith.muli %13, %c32_i32 : i32
    %15 = gpu.block_id  y
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.muli %16, %c32_i32 : i32
    %18 = arith.muli %14, %arg12 : i32
    %19 = arith.subi %18, %arg13 : i32
    %20 = arith.muli %17, %arg12 : i32
    %21 = arith.subi %20, %arg13 : i32
    %22 = arith.muli %arg12, %c31_i32 : i32
    %23 = arith.addi %22, %arg11 : i32
    %24 = arith.index_cast %23 : i32 to index
    %25 = arith.muli %23, %23 : i32
    %26 = arith.index_cast %25 : i32 to index
    %27 = gpu.thread_id  x
    %28 = gpu.block_dim  x
    %29 = arith.muli %arg11, %arg11 : i32
    %30 = arith.index_cast %29 : i32 to index
    %31 = arith.muli %arg14, %arg11 : i32
    %32 = arith.muli %31, %arg11 : i32
    %33 = arith.muli %10, %32 : i32
    %34 = arith.muli %11, %29 : i32
    %35 = arith.addi %33, %34 : i32
    %36 = arith.index_cast %35 : i32 to index
    %37 = arith.subi %30, %27 : index
    %38 = arith.subi %28, %c1 : index
    %39 = arith.addi %38, %37 : index
    %40 = arith.divui %39, %28 : index
    scf.for %arg15 = %c0 to %40 step %c1 {
      %69 = arith.muli %arg15, %28 : index
      %70 = arith.addi %69, %36 : index
      %71 = arith.addi %70, %27 : index
      %72 = memref.load %arg1[%71] : memref<?xf32>
      %73 = arith.addi %69, %27 : index
      %74 = arith.addi %73, %26 : index
      memref.store %72, %alloca[%74] : memref<1xf32, 5>
    }
    %41 = arith.muli %arg5, %arg6 : i32
    %42 = arith.muli %41, %arg7 : i32
    %43 = arith.muli %7, %42 : i32
    %44 = arith.muli %arg6, %arg7 : i32
    %45 = arith.muli %10, %44 : i32
    %46 = arith.addi %43, %45 : i32
    %47 = arith.subi %26, %27 : index
    %48 = arith.addi %38, %47 : index
    %49 = arith.divui %48, %28 : index
    scf.for %arg15 = %c0 to %49 step %c1 {
      %69 = arith.muli %arg15, %28 : index
      %70 = arith.addi %27, %69 : index
      %71 = arith.index_cast %70 : index to i32
      %72 = arith.divsi %71, %23 : i32
      %73 = arith.remsi %71, %23 : i32
      %74 = arith.addi %21, %72 : i32
      %75 = arith.addi %19, %73 : i32
      %76 = arith.cmpi sge, %74, %c0_i32 : i32
      %77 = arith.cmpi slt, %74, %arg6 : i32
      %78 = arith.cmpi sge, %75, %c0_i32 : i32
      %79 = arith.cmpi slt, %75, %arg7 : i32
      %80 = arith.andi %78, %79 : i1
      %81 = arith.andi %77, %80 : i1
      %82 = arith.andi %76, %81 : i1
      %83 = scf.if %82 -> (f32) {
        %85 = arith.muli %74, %arg7 : i32
        %86 = arith.addi %46, %85 : i32
        %87 = arith.addi %86, %75 : i32
        %88 = arith.index_cast %87 : i32 to index
        %89 = memref.load %arg0[%88] : memref<?xf32>
        scf.yield %89 : f32
      } else {
        scf.yield %cst : f32
      }
      %84 = arith.addi %69, %27 : index
      memref.store %83, %alloca[%84] : memref<1xf32, 5>
    }
    nvvm.barrier0
    %50 = llvm.mlir.zero : !llvm.ptr
    %51 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
    %52 = llvm.icmp "ne" %51, %50 : !llvm.ptr
    %53 = arith.muli %arg8, %arg9 : i32
    %54 = arith.muli %53, %arg10 : i32
    %55 = arith.muli %7, %54 : i32
    %56 = arith.muli %arg9, %arg10 : i32
    %57 = arith.muli %8, %56 : i32
    %58 = arith.addi %55, %57 : i32
    %59 = arith.index_cast %58 : i32 to index
    %60 = arith.subi %c1024, %27 : index
    %61 = arith.addi %38, %60 : index
    %62 = arith.divui %61, %28 : index
    %63 = arith.muli %12, %c-32 : index
    %64 = arith.muli %15, %c-32 : index
    %65 = arith.addi %64, %0 : index
    %66 = arith.muli %12, %c32 : index
    %67 = arith.muli %15, %c32 : index
    %68:3 = scf.for %arg15 = %c0 to %62 step %c1 iter_args(%arg16 = %4, %arg17 = %4, %arg18 = %4) -> (i32, i32, i32) {
      %69 = arith.muli %arg15, %28 : index
      %70 = arith.addi %27, %69 : index
      %71 = arith.index_cast %70 : index to i32
      %72 = arith.divsi %71, %c32_i32 : i32
      %73 = arith.remsi %71, %c32_i32 : i32
      %74 = arith.subi %63, %69 : index
      %75 = arith.subi %74, %27 : index
      %76 = arith.addi %75, %3 : index
      %77 = arith.addi %69, %27 : index
      %78 = arith.cmpi slt, %77, %c0 : index
      %79 = arith.subi %c-1, %77 : index
      %80 = arith.select %78, %79, %77 : index
      %81 = arith.divsi %80, %c32 : index
      %82 = arith.subi %c-1, %81 : index
      %83 = arith.select %78, %82, %81 : index
      %84 = arith.muli %83, %c32 : index
      %85 = arith.addi %76, %84 : index
      %86 = arith.addi %85, %c-1 : index
      %87 = arith.cmpi sge, %86, %c0 : index
      %88 = arith.subi %65, %83 : index
      %89 = arith.addi %88, %c-1 : index
      %90 = arith.cmpi sge, %89, %c0 : index
      %91 = arith.andi %87, %90 : i1
      %92:3 = scf.if %91 -> (i32, i32, i32) {
        %93 = arith.addi %2, %c-3 : index
        %94 = arith.cmpi eq, %93, %c0 : index
        %95:4 = scf.if %94 -> (i32, i32, i32, f32) {
          %105 = arith.remsi %77, %c32 : index
          %106 = arith.cmpi slt, %105, %c0 : index
          %107 = arith.addi %105, %c32 : index
          %108 = arith.select %106, %107, %105 : index
          %109 = arith.muli %108, %1 : index
          %110 = arith.muli %83, %1 : index
          %111 = arith.muli %110, %24 : index
          %112 = arith.addi %109, %111 : index
          %113 = memref.load %alloca[%112] : memref<1xf32, 5>
          %114 = memref.load %alloca[%26] : memref<1xf32, 5>
          %115 = arith.mulf %113, %114 : f32
          %116 = arith.addf %115, %cst : f32
          %117 = arith.addi %111, %109 : index
          %118 = arith.addi %117, %c1 : index
          %119 = memref.load %alloca[%118] : memref<1xf32, 5>
          %120 = arith.addi %26, %c1 : index
          %121 = memref.load %alloca[%120] : memref<1xf32, 5>
          %122 = arith.mulf %119, %121 : f32
          %123 = arith.addf %116, %122 : f32
          %124 = arith.addi %117, %c2 : index
          %125 = memref.load %alloca[%124] : memref<1xf32, 5>
          %126 = arith.addi %26, %c2 : index
          %127 = memref.load %alloca[%126] : memref<1xf32, 5>
          %128 = arith.mulf %125, %127 : f32
          %129 = arith.addf %123, %128 : f32
          %130 = arith.addi %110, %c1 : index
          %131 = arith.muli %130, %24 : index
          %132 = arith.addi %109, %131 : index
          %133 = memref.load %alloca[%132] : memref<1xf32, 5>
          %134 = arith.addi %26, %c3 : index
          %135 = memref.load %alloca[%134] : memref<1xf32, 5>
          %136 = arith.mulf %133, %135 : f32
          %137 = arith.addf %129, %136 : f32
          %138 = arith.addi %132, %c1 : index
          %139 = memref.load %alloca[%138] : memref<1xf32, 5>
          %140 = arith.addi %26, %c4 : index
          %141 = memref.load %alloca[%140] : memref<1xf32, 5>
          %142 = arith.mulf %139, %141 : f32
          %143 = arith.addf %137, %142 : f32
          %144 = arith.addi %132, %c2 : index
          %145 = memref.load %alloca[%144] : memref<1xf32, 5>
          %146 = arith.addi %26, %c5 : index
          %147 = memref.load %alloca[%146] : memref<1xf32, 5>
          %148 = arith.mulf %145, %147 : f32
          %149 = arith.addf %143, %148 : f32
          %150 = arith.addi %110, %c2 : index
          %151 = arith.muli %150, %24 : index
          %152 = arith.addi %109, %151 : index
          %153 = memref.load %alloca[%152] : memref<1xf32, 5>
          %154 = arith.addi %26, %c6 : index
          %155 = memref.load %alloca[%154] : memref<1xf32, 5>
          %156 = arith.mulf %153, %155 : f32
          %157 = arith.addf %149, %156 : f32
          %158 = arith.addi %152, %c1 : index
          %159 = memref.load %alloca[%158] : memref<1xf32, 5>
          %160 = arith.addi %26, %c7 : index
          %161 = memref.load %alloca[%160] : memref<1xf32, 5>
          %162 = arith.mulf %159, %161 : f32
          %163 = arith.addf %157, %162 : f32
          %164 = arith.addi %152, %c2 : index
          %165 = memref.load %alloca[%164] : memref<1xf32, 5>
          %166 = arith.addi %26, %c8 : index
          %167 = memref.load %alloca[%166] : memref<1xf32, 5>
          %168 = arith.mulf %165, %167 : f32
          %169 = arith.addf %163, %168 : f32
          scf.yield %arg16, %arg17, %arg18, %169 : i32, i32, i32, f32
        } else {
          %105 = arith.muli %72, %arg12 : i32
          %106 = arith.muli %73, %arg12 : i32
          %107 = arith.remsi %77, %c32 : index
          %108 = arith.cmpi slt, %107, %c0 : index
          %109 = arith.addi %107, %c32 : index
          %110 = arith.select %108, %109, %107 : index
          %111 = arith.muli %110, %1 : index
          %112 = arith.muli %83, %1 : index
          %113:4 = scf.for %arg19 = %c0 to %2 step %c1 iter_args(%arg20 = %arg16, %arg21 = %arg17, %arg22 = %cst, %arg23 = %arg18) -> (i32, i32, f32, i32) {
            %114 = arith.index_cast %arg19 : index to i32
            %115 = arith.addi %105, %114 : i32
            %116 = arith.addi %arg19, %112 : index
            %117 = arith.muli %116, %24 : index
            %118:3 = scf.for %arg24 = %c0 to %2 step %c1 iter_args(%arg25 = %arg22, %arg26 = %arg20, %arg27 = %arg21) -> (f32, i32, i32) {
              %119 = arith.index_cast %arg24 : index to i32
              %120 = arith.addi %106, %119 : i32
              %121 = arith.addi %arg24, %111 : index
              %122 = arith.addi %121, %117 : index
              %123 = memref.load %alloca[%122] : memref<1xf32, 5>
              %124 = arith.muli %arg19, %2 : index
              %125 = arith.addi %arg24, %124 : index
              %126 = arith.addi %125, %26 : index
              %127 = memref.load %alloca[%126] : memref<1xf32, 5>
              %128 = arith.mulf %123, %127 : f32
              %129 = arith.addf %arg25, %128 : f32
              scf.yield %129, %120, %115 : f32, i32, i32
            }
            scf.yield %118#1, %118#2, %118#0, %arg11 : i32, i32, f32, i32
          }
          scf.yield %113#0, %113#1, %113#3, %113#2 : i32, i32, i32, f32
        }
        %96 = scf.if %52 -> (f32) {
          %105 = memref.load %arg2[%9] : memref<?xf32>
          %106 = arith.addf %95#3, %105 : f32
          scf.yield %106 : f32
        } else {
          scf.yield %95#3 : f32
        }
        %97 = arith.addi %69, %59 : index
        %98 = arith.addi %97, %27 : index
        %99 = arith.addi %98, %66 : index
        %100 = arith.muli %83, %c-32 : index
        %101 = arith.addi %99, %100 : index
        %102 = arith.addi %83, %67 : index
        %103 = arith.muli %102, %3 : index
        %104 = arith.addi %101, %103 : index
        memref.store %96, %arg3[%104] : memref<?xf32>
        scf.yield %95#0, %95#1, %95#2 : i32, i32, i32
      } else {
        scf.yield %arg16, %arg17, %arg18 : i32, i32, i32
      }
      scf.yield %92#0, %92#1, %92#2 : i32, i32, i32
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg15) = (%c0) to (%c32) step (%c1) {
      %c8 = arith.constant 8 : index
      %c7 = arith.constant 7 : index
      %c6 = arith.constant 6 : index
      %c5 = arith.constant 5 : index
      %c4 = arith.constant 4 : index
      %c3 = arith.constant 3 : index
      %c-3 = arith.constant -3 : index
      %c2 = arith.constant 2 : index
      %c32_0 = arith.constant 32 : index
      %c-32 = arith.constant -32 : index
      %c-1 = arith.constant -1 : index
      %c0_1 = arith.constant 0 : index
      %c32_i32 = arith.constant 32 : i32
      %c31_i32 = arith.constant 31 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c0_i32 = arith.constant 0 : i32
      %c1024 = arith.constant 1024 : index
      %c1_2 = arith.constant 1 : index
      %0 = arith.index_cast %arg9 : i32 to index
      %1 = arith.index_cast %arg12 : i32 to index
      %2 = arith.index_cast %arg11 : i32 to index
      %3 = arith.index_cast %arg10 : i32 to index
      %4 = llvm.mlir.undef : i32
      %5 = gpu.block_id  z
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.divsi %6, %arg8 : i32
      %8 = arith.remsi %6, %arg8 : i32
      %9 = arith.index_cast %8 : i32 to index
      %10 = arith.divsi %8, %arg14 : i32
      %11 = arith.remsi %8, %arg14 : i32
      %12 = gpu.block_id  x
      %13 = arith.index_cast %12 : index to i32
      %14 = arith.muli %13, %c32_i32 : i32
      %15 = gpu.block_id  y
      %16 = arith.index_cast %15 : index to i32
      %17 = arith.muli %16, %c32_i32 : i32
      %18 = arith.muli %14, %arg12 : i32
      %19 = arith.subi %18, %arg13 : i32
      %20 = arith.muli %17, %arg12 : i32
      %21 = arith.subi %20, %arg13 : i32
      %22 = arith.muli %arg12, %c31_i32 : i32
      %23 = arith.addi %22, %arg11 : i32
      %24 = arith.index_cast %23 : i32 to index
      %25 = arith.muli %23, %23 : i32
      %26 = arith.index_cast %25 : i32 to index
      %27 = gpu.block_dim  x
      %28 = arith.muli %arg11, %arg11 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.muli %arg14, %arg11 : i32
      %31 = arith.muli %30, %arg11 : i32
      %32 = arith.muli %10, %31 : i32
      %33 = arith.muli %11, %28 : i32
      %34 = arith.addi %32, %33 : i32
      %35 = arith.index_cast %34 : i32 to index
      %36 = arith.subi %29, %arg15 : index
      %37 = arith.subi %27, %c1_2 : index
      %38 = arith.addi %37, %36 : index
      %39 = arith.divui %38, %27 : index
      scf.for %arg16 = %c0_1 to %39 step %c1_2 {
        %68 = arith.muli %arg16, %27 : index
        %69 = arith.addi %68, %35 : index
        %70 = arith.addi %69, %arg15 : index
        %71 = memref.load %arg1[%70] : memref<?xf32>
        %72 = arith.addi %68, %arg15 : index
        %73 = arith.addi %72, %26 : index
        memref.store %71, %alloca[%73] : memref<1xf32, 5>
      }
      %40 = arith.muli %arg5, %arg6 : i32
      %41 = arith.muli %40, %arg7 : i32
      %42 = arith.muli %7, %41 : i32
      %43 = arith.muli %arg6, %arg7 : i32
      %44 = arith.muli %10, %43 : i32
      %45 = arith.addi %42, %44 : i32
      %46 = arith.subi %26, %arg15 : index
      %47 = arith.addi %37, %46 : index
      %48 = arith.divui %47, %27 : index
      scf.for %arg16 = %c0_1 to %48 step %c1_2 {
        %68 = arith.muli %arg16, %27 : index
        %69 = arith.addi %arg15, %68 : index
        %70 = arith.index_cast %69 : index to i32
        %71 = arith.divsi %70, %23 : i32
        %72 = arith.remsi %70, %23 : i32
        %73 = arith.addi %21, %71 : i32
        %74 = arith.addi %19, %72 : i32
        %75 = arith.cmpi sge, %73, %c0_i32 : i32
        %76 = arith.cmpi slt, %73, %arg6 : i32
        %77 = arith.cmpi sge, %74, %c0_i32 : i32
        %78 = arith.cmpi slt, %74, %arg7 : i32
        %79 = arith.andi %77, %78 : i1
        %80 = arith.andi %76, %79 : i1
        %81 = arith.andi %75, %80 : i1
        %82 = scf.if %81 -> (f32) {
          %84 = arith.muli %73, %arg7 : i32
          %85 = arith.addi %45, %84 : i32
          %86 = arith.addi %85, %74 : i32
          %87 = arith.index_cast %86 : i32 to index
          %88 = memref.load %arg0[%87] : memref<?xf32>
          scf.yield %88 : f32
        } else {
          scf.yield %cst : f32
        }
        %83 = arith.addi %68, %arg15 : index
        memref.store %82, %alloca[%83] : memref<1xf32, 5>
      }
      "polygeist.barrier"(%arg15) : (index) -> ()
      %49 = llvm.mlir.zero : !llvm.ptr
      %50 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %51 = llvm.icmp "ne" %50, %49 : !llvm.ptr
      %52 = arith.muli %arg8, %arg9 : i32
      %53 = arith.muli %52, %arg10 : i32
      %54 = arith.muli %7, %53 : i32
      %55 = arith.muli %arg9, %arg10 : i32
      %56 = arith.muli %8, %55 : i32
      %57 = arith.addi %54, %56 : i32
      %58 = arith.index_cast %57 : i32 to index
      %59 = arith.subi %c1024, %arg15 : index
      %60 = arith.addi %37, %59 : index
      %61 = arith.divui %60, %27 : index
      %62 = arith.muli %12, %c-32 : index
      %63 = arith.muli %15, %c-32 : index
      %64 = arith.addi %63, %0 : index
      %65 = arith.muli %12, %c32_0 : index
      %66 = arith.muli %15, %c32_0 : index
      %67:3 = scf.for %arg16 = %c0_1 to %61 step %c1_2 iter_args(%arg17 = %4, %arg18 = %4, %arg19 = %4) -> (i32, i32, i32) {
        %68 = arith.muli %arg16, %27 : index
        %69 = arith.addi %arg15, %68 : index
        %70 = arith.index_cast %69 : index to i32
        %71 = arith.divsi %70, %c32_i32 : i32
        %72 = arith.remsi %70, %c32_i32 : i32
        %73 = arith.subi %62, %68 : index
        %74 = arith.subi %73, %arg15 : index
        %75 = arith.addi %74, %3 : index
        %76 = arith.addi %68, %arg15 : index
        %77 = arith.cmpi slt, %76, %c0_1 : index
        %78 = arith.subi %c-1, %76 : index
        %79 = arith.select %77, %78, %76 : index
        %80 = arith.divsi %79, %c32_0 : index
        %81 = arith.subi %c-1, %80 : index
        %82 = arith.select %77, %81, %80 : index
        %83 = arith.muli %82, %c32_0 : index
        %84 = arith.addi %75, %83 : index
        %85 = arith.addi %84, %c-1 : index
        %86 = arith.cmpi sge, %85, %c0_1 : index
        %87 = arith.subi %64, %82 : index
        %88 = arith.addi %87, %c-1 : index
        %89 = arith.cmpi sge, %88, %c0_1 : index
        %90 = arith.andi %86, %89 : i1
        %91:3 = scf.if %90 -> (i32, i32, i32) {
          %92 = arith.addi %2, %c-3 : index
          %93 = arith.cmpi eq, %92, %c0_1 : index
          %94:4 = scf.if %93 -> (i32, i32, i32, f32) {
            %104 = arith.remsi %76, %c32_0 : index
            %105 = arith.cmpi slt, %104, %c0_1 : index
            %106 = arith.addi %104, %c32_0 : index
            %107 = arith.select %105, %106, %104 : index
            %108 = arith.muli %107, %1 : index
            %109 = arith.muli %82, %1 : index
            %110 = arith.muli %109, %24 : index
            %111 = arith.addi %108, %110 : index
            %112 = memref.load %alloca[%111] : memref<1xf32, 5>
            %113 = memref.load %alloca[%26] : memref<1xf32, 5>
            %114 = arith.mulf %112, %113 : f32
            %115 = arith.addf %114, %cst : f32
            %116 = arith.addi %110, %108 : index
            %117 = arith.addi %116, %c1_2 : index
            %118 = memref.load %alloca[%117] : memref<1xf32, 5>
            %119 = arith.addi %26, %c1_2 : index
            %120 = memref.load %alloca[%119] : memref<1xf32, 5>
            %121 = arith.mulf %118, %120 : f32
            %122 = arith.addf %115, %121 : f32
            %123 = arith.addi %116, %c2 : index
            %124 = memref.load %alloca[%123] : memref<1xf32, 5>
            %125 = arith.addi %26, %c2 : index
            %126 = memref.load %alloca[%125] : memref<1xf32, 5>
            %127 = arith.mulf %124, %126 : f32
            %128 = arith.addf %122, %127 : f32
            %129 = arith.addi %109, %c1_2 : index
            %130 = arith.muli %129, %24 : index
            %131 = arith.addi %108, %130 : index
            %132 = memref.load %alloca[%131] : memref<1xf32, 5>
            %133 = arith.addi %26, %c3 : index
            %134 = memref.load %alloca[%133] : memref<1xf32, 5>
            %135 = arith.mulf %132, %134 : f32
            %136 = arith.addf %128, %135 : f32
            %137 = arith.addi %131, %c1_2 : index
            %138 = memref.load %alloca[%137] : memref<1xf32, 5>
            %139 = arith.addi %26, %c4 : index
            %140 = memref.load %alloca[%139] : memref<1xf32, 5>
            %141 = arith.mulf %138, %140 : f32
            %142 = arith.addf %136, %141 : f32
            %143 = arith.addi %131, %c2 : index
            %144 = memref.load %alloca[%143] : memref<1xf32, 5>
            %145 = arith.addi %26, %c5 : index
            %146 = memref.load %alloca[%145] : memref<1xf32, 5>
            %147 = arith.mulf %144, %146 : f32
            %148 = arith.addf %142, %147 : f32
            %149 = arith.addi %109, %c2 : index
            %150 = arith.muli %149, %24 : index
            %151 = arith.addi %108, %150 : index
            %152 = memref.load %alloca[%151] : memref<1xf32, 5>
            %153 = arith.addi %26, %c6 : index
            %154 = memref.load %alloca[%153] : memref<1xf32, 5>
            %155 = arith.mulf %152, %154 : f32
            %156 = arith.addf %148, %155 : f32
            %157 = arith.addi %151, %c1_2 : index
            %158 = memref.load %alloca[%157] : memref<1xf32, 5>
            %159 = arith.addi %26, %c7 : index
            %160 = memref.load %alloca[%159] : memref<1xf32, 5>
            %161 = arith.mulf %158, %160 : f32
            %162 = arith.addf %156, %161 : f32
            %163 = arith.addi %151, %c2 : index
            %164 = memref.load %alloca[%163] : memref<1xf32, 5>
            %165 = arith.addi %26, %c8 : index
            %166 = memref.load %alloca[%165] : memref<1xf32, 5>
            %167 = arith.mulf %164, %166 : f32
            %168 = arith.addf %162, %167 : f32
            scf.yield %arg17, %arg18, %arg19, %168 : i32, i32, i32, f32
          } else {
            %104 = arith.muli %71, %arg12 : i32
            %105 = arith.muli %72, %arg12 : i32
            %106 = arith.remsi %76, %c32_0 : index
            %107 = arith.cmpi slt, %106, %c0_1 : index
            %108 = arith.addi %106, %c32_0 : index
            %109 = arith.select %107, %108, %106 : index
            %110 = arith.muli %109, %1 : index
            %111 = arith.muli %82, %1 : index
            %112:4 = scf.for %arg20 = %c0_1 to %2 step %c1_2 iter_args(%arg21 = %arg17, %arg22 = %arg18, %arg23 = %cst, %arg24 = %arg19) -> (i32, i32, f32, i32) {
              %113 = arith.index_cast %arg20 : index to i32
              %114 = arith.addi %104, %113 : i32
              %115 = arith.addi %arg20, %111 : index
              %116 = arith.muli %115, %24 : index
              %117:3 = scf.for %arg25 = %c0_1 to %2 step %c1_2 iter_args(%arg26 = %arg23, %arg27 = %arg21, %arg28 = %arg22) -> (f32, i32, i32) {
                %118 = arith.index_cast %arg25 : index to i32
                %119 = arith.addi %105, %118 : i32
                %120 = arith.addi %arg25, %110 : index
                %121 = arith.addi %120, %116 : index
                %122 = memref.load %alloca[%121] : memref<1xf32, 5>
                %123 = arith.muli %arg20, %2 : index
                %124 = arith.addi %arg25, %123 : index
                %125 = arith.addi %124, %26 : index
                %126 = memref.load %alloca[%125] : memref<1xf32, 5>
                %127 = arith.mulf %122, %126 : f32
                %128 = arith.addf %arg26, %127 : f32
                scf.yield %128, %119, %114 : f32, i32, i32
              }
              scf.yield %117#1, %117#2, %117#0, %arg11 : i32, i32, f32, i32
            }
            scf.yield %112#0, %112#1, %112#3, %112#2 : i32, i32, i32, f32
          }
          %95 = scf.if %51 -> (f32) {
            %104 = memref.load %arg2[%9] : memref<?xf32>
            %105 = arith.addf %94#3, %104 : f32
            scf.yield %105 : f32
          } else {
            scf.yield %94#3 : f32
          }
          %96 = arith.addi %68, %58 : index
          %97 = arith.addi %96, %arg15 : index
          %98 = arith.addi %97, %65 : index
          %99 = arith.muli %82, %c-32 : index
          %100 = arith.addi %98, %99 : index
          %101 = arith.addi %82, %66 : index
          %102 = arith.muli %101, %3 : index
          %103 = arith.addi %100, %102 : index
          memref.store %95, %arg3[%103] : memref<?xf32>
          scf.yield %94#0, %94#1, %94#2 : i32, i32, i32
        } else {
          scf.yield %arg17, %arg18, %arg19 : i32, i32, i32
        }
        scf.yield %91#0, %91#1, %91#2 : i32, i32, i32
      }
      scf.yield
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg15) = (%c0) to (%c32) step (%c1) {
      %c8 = arith.constant 8 : index
      %c7 = arith.constant 7 : index
      %c6 = arith.constant 6 : index
      %c5 = arith.constant 5 : index
      %c4 = arith.constant 4 : index
      %c3 = arith.constant 3 : index
      %c-3 = arith.constant -3 : index
      %c2 = arith.constant 2 : index
      %c32_0 = arith.constant 32 : index
      %c-32 = arith.constant -32 : index
      %c-1 = arith.constant -1 : index
      %c0_1 = arith.constant 0 : index
      %c32_i32 = arith.constant 32 : i32
      %c31_i32 = arith.constant 31 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c0_i32 = arith.constant 0 : i32
      %c1024 = arith.constant 1024 : index
      %c1_2 = arith.constant 1 : index
      %0 = arith.index_cast %arg9 : i32 to index
      %1 = arith.index_cast %arg12 : i32 to index
      %2 = arith.index_cast %arg11 : i32 to index
      %3 = arith.index_cast %arg10 : i32 to index
      %4 = llvm.mlir.undef : i32
      %5 = gpu.block_id  z
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.divsi %6, %arg8 : i32
      %8 = arith.remsi %6, %arg8 : i32
      %9 = arith.index_cast %8 : i32 to index
      %10 = arith.divsi %8, %arg14 : i32
      %11 = arith.remsi %8, %arg14 : i32
      %12 = gpu.block_id  x
      %13 = arith.index_cast %12 : index to i32
      %14 = arith.muli %13, %c32_i32 : i32
      %15 = gpu.block_id  y
      %16 = arith.index_cast %15 : index to i32
      %17 = arith.muli %16, %c32_i32 : i32
      %18 = arith.muli %14, %arg12 : i32
      %19 = arith.subi %18, %arg13 : i32
      %20 = arith.muli %17, %arg12 : i32
      %21 = arith.subi %20, %arg13 : i32
      %22 = arith.muli %arg12, %c31_i32 : i32
      %23 = arith.addi %22, %arg11 : i32
      %24 = arith.index_cast %23 : i32 to index
      %25 = arith.muli %23, %23 : i32
      %26 = arith.index_cast %25 : i32 to index
      %27 = gpu.block_dim  x
      %28 = arith.muli %arg11, %arg11 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.muli %arg14, %arg11 : i32
      %31 = arith.muli %30, %arg11 : i32
      %32 = arith.muli %10, %31 : i32
      %33 = arith.muli %11, %28 : i32
      %34 = arith.addi %32, %33 : i32
      %35 = arith.index_cast %34 : i32 to index
      %36 = arith.subi %29, %arg15 : index
      %37 = arith.subi %27, %c1_2 : index
      %38 = arith.addi %37, %36 : index
      %39 = arith.divui %38, %27 : index
      scf.for %arg16 = %c0_1 to %39 step %c1_2 {
        %68 = arith.muli %arg16, %27 : index
        %69 = arith.addi %68, %35 : index
        %70 = arith.addi %69, %arg15 : index
        %71 = memref.load %arg1[%70] : memref<?xf32>
        %72 = arith.addi %68, %arg15 : index
        %73 = arith.addi %72, %26 : index
        memref.store %71, %alloca[%73] : memref<1xf32, 5>
      }
      %40 = arith.muli %arg5, %arg6 : i32
      %41 = arith.muli %40, %arg7 : i32
      %42 = arith.muli %7, %41 : i32
      %43 = arith.muli %arg6, %arg7 : i32
      %44 = arith.muli %10, %43 : i32
      %45 = arith.addi %42, %44 : i32
      %46 = arith.subi %26, %arg15 : index
      %47 = arith.addi %37, %46 : index
      %48 = arith.divui %47, %27 : index
      scf.for %arg16 = %c0_1 to %48 step %c1_2 {
        %68 = arith.muli %arg16, %27 : index
        %69 = arith.addi %arg15, %68 : index
        %70 = arith.index_cast %69 : index to i32
        %71 = arith.divsi %70, %23 : i32
        %72 = arith.remsi %70, %23 : i32
        %73 = arith.addi %21, %71 : i32
        %74 = arith.addi %19, %72 : i32
        %75 = arith.cmpi sge, %73, %c0_i32 : i32
        %76 = arith.cmpi slt, %73, %arg6 : i32
        %77 = arith.cmpi sge, %74, %c0_i32 : i32
        %78 = arith.cmpi slt, %74, %arg7 : i32
        %79 = arith.andi %77, %78 : i1
        %80 = arith.andi %76, %79 : i1
        %81 = arith.andi %75, %80 : i1
        %82 = scf.if %81 -> (f32) {
          %84 = arith.muli %73, %arg7 : i32
          %85 = arith.addi %45, %84 : i32
          %86 = arith.addi %85, %74 : i32
          %87 = arith.index_cast %86 : i32 to index
          %88 = memref.load %arg0[%87] : memref<?xf32>
          scf.yield %88 : f32
        } else {
          scf.yield %cst : f32
        }
        %83 = arith.addi %68, %arg15 : index
        memref.store %82, %alloca[%83] : memref<1xf32, 5>
      }
      "polygeist.barrier"(%arg15) : (index) -> ()
      %49 = llvm.mlir.zero : !llvm.ptr
      %50 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %51 = llvm.icmp "ne" %50, %49 : !llvm.ptr
      %52 = arith.muli %arg8, %arg9 : i32
      %53 = arith.muli %52, %arg10 : i32
      %54 = arith.muli %7, %53 : i32
      %55 = arith.muli %arg9, %arg10 : i32
      %56 = arith.muli %8, %55 : i32
      %57 = arith.addi %54, %56 : i32
      %58 = arith.index_cast %57 : i32 to index
      %59 = arith.subi %c1024, %arg15 : index
      %60 = arith.addi %37, %59 : index
      %61 = arith.divui %60, %27 : index
      %62 = arith.muli %12, %c-32 : index
      %63 = arith.muli %15, %c-32 : index
      %64 = arith.addi %63, %0 : index
      %65 = arith.muli %12, %c32_0 : index
      %66 = arith.muli %15, %c32_0 : index
      %67:3 = scf.for %arg16 = %c0_1 to %61 step %c1_2 iter_args(%arg17 = %4, %arg18 = %4, %arg19 = %4) -> (i32, i32, i32) {
        %68 = arith.muli %arg16, %27 : index
        %69 = arith.addi %arg15, %68 : index
        %70 = arith.index_cast %69 : index to i32
        %71 = arith.divsi %70, %c32_i32 : i32
        %72 = arith.remsi %70, %c32_i32 : i32
        %73 = arith.subi %62, %68 : index
        %74 = arith.subi %73, %arg15 : index
        %75 = arith.addi %74, %3 : index
        %76 = arith.addi %68, %arg15 : index
        %77 = arith.cmpi slt, %76, %c0_1 : index
        %78 = arith.subi %c-1, %76 : index
        %79 = arith.select %77, %78, %76 : index
        %80 = arith.divsi %79, %c32_0 : index
        %81 = arith.subi %c-1, %80 : index
        %82 = arith.select %77, %81, %80 : index
        %83 = arith.muli %82, %c32_0 : index
        %84 = arith.addi %75, %83 : index
        %85 = arith.addi %84, %c-1 : index
        %86 = arith.cmpi sge, %85, %c0_1 : index
        %87 = arith.subi %64, %82 : index
        %88 = arith.addi %87, %c-1 : index
        %89 = arith.cmpi sge, %88, %c0_1 : index
        %90 = arith.andi %86, %89 : i1
        %91:3 = scf.if %90 -> (i32, i32, i32) {
          %92 = arith.addi %2, %c-3 : index
          %93 = arith.cmpi eq, %92, %c0_1 : index
          %94:4 = scf.if %93 -> (i32, i32, i32, f32) {
            %104 = arith.remsi %76, %c32_0 : index
            %105 = arith.cmpi slt, %104, %c0_1 : index
            %106 = arith.addi %104, %c32_0 : index
            %107 = arith.select %105, %106, %104 : index
            %108 = arith.muli %107, %1 : index
            %109 = arith.muli %82, %1 : index
            %110 = arith.muli %109, %24 : index
            %111 = arith.addi %108, %110 : index
            %112 = memref.load %alloca[%111] : memref<1xf32, 5>
            %113 = memref.load %alloca[%26] : memref<1xf32, 5>
            %114 = arith.mulf %112, %113 : f32
            %115 = arith.addf %114, %cst : f32
            %116 = arith.addi %110, %108 : index
            %117 = arith.addi %116, %c1_2 : index
            %118 = memref.load %alloca[%117] : memref<1xf32, 5>
            %119 = arith.addi %26, %c1_2 : index
            %120 = memref.load %alloca[%119] : memref<1xf32, 5>
            %121 = arith.mulf %118, %120 : f32
            %122 = arith.addf %115, %121 : f32
            %123 = arith.addi %116, %c2 : index
            %124 = memref.load %alloca[%123] : memref<1xf32, 5>
            %125 = arith.addi %26, %c2 : index
            %126 = memref.load %alloca[%125] : memref<1xf32, 5>
            %127 = arith.mulf %124, %126 : f32
            %128 = arith.addf %122, %127 : f32
            %129 = arith.addi %109, %c1_2 : index
            %130 = arith.muli %129, %24 : index
            %131 = arith.addi %108, %130 : index
            %132 = memref.load %alloca[%131] : memref<1xf32, 5>
            %133 = arith.addi %26, %c3 : index
            %134 = memref.load %alloca[%133] : memref<1xf32, 5>
            %135 = arith.mulf %132, %134 : f32
            %136 = arith.addf %128, %135 : f32
            %137 = arith.addi %131, %c1_2 : index
            %138 = memref.load %alloca[%137] : memref<1xf32, 5>
            %139 = arith.addi %26, %c4 : index
            %140 = memref.load %alloca[%139] : memref<1xf32, 5>
            %141 = arith.mulf %138, %140 : f32
            %142 = arith.addf %136, %141 : f32
            %143 = arith.addi %131, %c2 : index
            %144 = memref.load %alloca[%143] : memref<1xf32, 5>
            %145 = arith.addi %26, %c5 : index
            %146 = memref.load %alloca[%145] : memref<1xf32, 5>
            %147 = arith.mulf %144, %146 : f32
            %148 = arith.addf %142, %147 : f32
            %149 = arith.addi %109, %c2 : index
            %150 = arith.muli %149, %24 : index
            %151 = arith.addi %108, %150 : index
            %152 = memref.load %alloca[%151] : memref<1xf32, 5>
            %153 = arith.addi %26, %c6 : index
            %154 = memref.load %alloca[%153] : memref<1xf32, 5>
            %155 = arith.mulf %152, %154 : f32
            %156 = arith.addf %148, %155 : f32
            %157 = arith.addi %151, %c1_2 : index
            %158 = memref.load %alloca[%157] : memref<1xf32, 5>
            %159 = arith.addi %26, %c7 : index
            %160 = memref.load %alloca[%159] : memref<1xf32, 5>
            %161 = arith.mulf %158, %160 : f32
            %162 = arith.addf %156, %161 : f32
            %163 = arith.addi %151, %c2 : index
            %164 = memref.load %alloca[%163] : memref<1xf32, 5>
            %165 = arith.addi %26, %c8 : index
            %166 = memref.load %alloca[%165] : memref<1xf32, 5>
            %167 = arith.mulf %164, %166 : f32
            %168 = arith.addf %162, %167 : f32
            scf.yield %arg17, %arg18, %arg19, %168 : i32, i32, i32, f32
          } else {
            %104 = arith.muli %71, %arg12 : i32
            %105 = arith.muli %72, %arg12 : i32
            %106 = arith.remsi %76, %c32_0 : index
            %107 = arith.cmpi slt, %106, %c0_1 : index
            %108 = arith.addi %106, %c32_0 : index
            %109 = arith.select %107, %108, %106 : index
            %110 = arith.muli %109, %1 : index
            %111 = arith.muli %82, %1 : index
            %112:4 = scf.for %arg20 = %c0_1 to %2 step %c1_2 iter_args(%arg21 = %arg17, %arg22 = %arg18, %arg23 = %cst, %arg24 = %arg19) -> (i32, i32, f32, i32) {
              %113 = arith.index_cast %arg20 : index to i32
              %114 = arith.addi %104, %113 : i32
              %115 = arith.addi %arg20, %111 : index
              %116 = arith.muli %115, %24 : index
              %117:3 = scf.for %arg25 = %c0_1 to %2 step %c1_2 iter_args(%arg26 = %arg23, %arg27 = %arg21, %arg28 = %arg22) -> (f32, i32, i32) {
                %118 = arith.index_cast %arg25 : index to i32
                %119 = arith.addi %105, %118 : i32
                %120 = arith.addi %arg25, %110 : index
                %121 = arith.addi %120, %116 : index
                %122 = memref.load %alloca[%121] : memref<1xf32, 5>
                %123 = arith.muli %arg20, %2 : index
                %124 = arith.addi %arg25, %123 : index
                %125 = arith.addi %124, %26 : index
                %126 = memref.load %alloca[%125] : memref<1xf32, 5>
                %127 = arith.mulf %122, %126 : f32
                %128 = arith.addf %arg26, %127 : f32
                scf.yield %128, %119, %114 : f32, i32, i32
              }
              scf.yield %117#1, %117#2, %117#0, %arg11 : i32, i32, f32, i32
            }
            scf.yield %112#0, %112#1, %112#3, %112#2 : i32, i32, i32, f32
          }
          %95 = scf.if %51 -> (f32) {
            %104 = memref.load %arg2[%9] : memref<?xf32>
            %105 = arith.addf %94#3, %104 : f32
            scf.yield %105 : f32
          } else {
            scf.yield %94#3 : f32
          }
          %96 = arith.addi %68, %58 : index
          %97 = arith.addi %96, %arg15 : index
          %98 = arith.addi %97, %65 : index
          %99 = arith.muli %82, %c-32 : index
          %100 = arith.addi %98, %99 : index
          %101 = arith.addi %82, %66 : index
          %102 = arith.muli %101, %3 : index
          %103 = arith.addi %100, %102 : index
          memref.store %95, %arg3[%103] : memref<?xf32>
          scf.yield %94#0, %94#1, %94#2 : i32, i32, i32
        } else {
          scf.yield %arg17, %arg18, %arg19 : i32, i32, i32
        }
        scf.yield %91#0, %91#1, %91#2 : i32, i32, i32
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1024 = arith.constant 1024 : index
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c31_i32 = arith.constant 31 : i32
    %c32_i32 = arith.constant 32 : i32
    %c-1 = arith.constant -1 : index
    %c-32 = arith.constant -32 : index
    %c2 = arith.constant 2 : index
    %c-3 = arith.constant -3 : index
    %c3 = arith.constant 3 : index
    %c4 = arith.constant 4 : index
    %c5 = arith.constant 5 : index
    %c6 = arith.constant 6 : index
    %c7 = arith.constant 7 : index
    %c8 = arith.constant 8 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    %0 = gpu.block_id  z
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.remsi %1, %arg8 : i32
    %3 = arith.remsi %2, %arg14 : i32
    %4 = gpu.block_id  x
    %5 = arith.index_cast %4 : index to i32
    %6 = arith.muli %5, %c32_i32 : i32
    %7 = gpu.block_id  y
    %8 = arith.index_cast %7 : index to i32
    %9 = arith.muli %8, %c32_i32 : i32
    %10 = arith.muli %6, %arg12 : i32
    %11 = arith.subi %10, %arg13 : i32
    %12 = arith.muli %9, %arg12 : i32
    %13 = arith.subi %12, %arg13 : i32
    %14 = arith.muli %arg12, %c31_i32 : i32
    %15 = arith.addi %14, %arg11 : i32
    %16 = arith.muli %15, %15 : i32
    %17 = arith.index_cast %16 : i32 to index
    %18 = gpu.block_dim  x
    %19 = arith.muli %arg11, %arg11 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = arith.muli %arg14, %arg11 : i32
    %22 = arith.muli %21, %arg11 : i32
    %23 = arith.muli %3, %19 : i32
    %24 = arith.subi %18, %c1 : index
    %25 = arith.muli %arg5, %arg6 : i32
    %26 = arith.muli %25, %arg7 : i32
    %27 = arith.muli %arg6, %arg7 : i32
    %28 = arith.divsi %1, %arg8 : i32
    %29 = arith.divsi %2, %arg14 : i32
    %30 = arith.muli %29, %22 : i32
    %31 = arith.addi %30, %23 : i32
    %32 = arith.index_cast %31 : i32 to index
    %33 = arith.muli %28, %26 : i32
    %34 = arith.muli %29, %27 : i32
    %35 = arith.addi %33, %34 : i32
    scf.parallel (%arg15) = (%c0) to (%c32) step (%c1) {
      %80 = arith.subi %20, %arg15 : index
      %81 = arith.addi %24, %80 : index
      %82 = arith.divui %81, %18 : index
      scf.for %arg16 = %c0 to %82 step %c1 {
        %86 = arith.muli %arg16, %18 : index
        %87 = arith.addi %86, %32 : index
        %88 = arith.addi %87, %arg15 : index
        %89 = memref.load %arg1[%88] : memref<?xf32>
        %90 = arith.addi %86, %arg15 : index
        %91 = arith.addi %90, %17 : index
        memref.store %89, %alloca[%91] : memref<1xf32, 5>
      }
      %83 = arith.subi %17, %arg15 : index
      %84 = arith.addi %24, %83 : index
      %85 = arith.divui %84, %18 : index
      scf.for %arg16 = %c0 to %85 step %c1 {
        %86 = arith.muli %arg16, %18 : index
        %87 = arith.addi %arg15, %86 : index
        %88 = arith.index_cast %87 : index to i32
        %89 = arith.divsi %88, %15 : i32
        %90 = arith.remsi %88, %15 : i32
        %91 = arith.addi %13, %89 : i32
        %92 = arith.addi %11, %90 : i32
        %93 = arith.cmpi sge, %91, %c0_i32 : i32
        %94 = arith.cmpi slt, %91, %arg6 : i32
        %95 = arith.cmpi sge, %92, %c0_i32 : i32
        %96 = arith.cmpi slt, %92, %arg7 : i32
        %97 = arith.andi %95, %96 : i1
        %98 = arith.andi %94, %97 : i1
        %99 = arith.andi %93, %98 : i1
        %100 = scf.if %99 -> (f32) {
          %102 = arith.muli %91, %arg7 : i32
          %103 = arith.addi %35, %102 : i32
          %104 = arith.addi %103, %92 : i32
          %105 = arith.index_cast %104 : i32 to index
          %106 = memref.load %arg0[%105] : memref<?xf32>
          scf.yield %106 : f32
        } else {
          scf.yield %cst : f32
        }
        %101 = arith.addi %86, %arg15 : index
        memref.store %100, %alloca[%101] : memref<1xf32, 5>
      }
      scf.yield
    }
    %36 = gpu.block_dim  x
    %37 = arith.subi %36, %c1 : index
    %38 = arith.muli %arg12, %c31_i32 : i32
    %39 = arith.addi %38, %arg11 : i32
    %40 = arith.muli %39, %39 : i32
    %41 = arith.index_cast %40 : i32 to index
    %42 = arith.index_cast %39 : i32 to index
    %43 = gpu.block_id  y
    %44 = gpu.block_id  x
    %45 = gpu.block_id  z
    %46 = arith.index_cast %45 : index to i32
    %47 = arith.remsi %46, %arg8 : i32
    %48 = arith.index_cast %47 : i32 to index
    %49 = llvm.mlir.undef : i32
    %50 = arith.index_cast %arg10 : i32 to index
    %51 = arith.index_cast %arg11 : i32 to index
    %52 = arith.index_cast %arg12 : i32 to index
    %53 = arith.index_cast %arg9 : i32 to index
    %54 = llvm.mlir.zero : !llvm.ptr
    %55 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
    %56 = llvm.icmp "ne" %55, %54 : !llvm.ptr
    %57 = arith.muli %arg8, %arg9 : i32
    %58 = arith.muli %57, %arg10 : i32
    %59 = arith.muli %arg9, %arg10 : i32
    %60 = arith.muli %47, %59 : i32
    %61 = arith.muli %44, %c-32 : index
    %62 = arith.muli %43, %c-32 : index
    %63 = arith.addi %62, %53 : index
    %64 = arith.muli %44, %c32 : index
    %65 = arith.muli %43, %c32 : index
    %66 = arith.addi %51, %c-3 : index
    %67 = arith.cmpi eq, %66, %c0 : index
    %68 = arith.addi %41, %c1 : index
    %69 = arith.addi %41, %c2 : index
    %70 = arith.addi %41, %c3 : index
    %71 = arith.addi %41, %c4 : index
    %72 = arith.addi %41, %c5 : index
    %73 = arith.addi %41, %c6 : index
    %74 = arith.addi %41, %c7 : index
    %75 = arith.addi %41, %c8 : index
    %76 = arith.divsi %46, %arg8 : i32
    %77 = arith.muli %76, %58 : i32
    %78 = arith.addi %77, %60 : i32
    %79 = arith.index_cast %78 : i32 to index
    scf.parallel (%arg15) = (%c0) to (%c32) step (%c1) {
      %80 = arith.subi %c1024, %arg15 : index
      %81 = arith.addi %37, %80 : index
      %82 = arith.divui %81, %36 : index
      %83:3 = scf.for %arg16 = %c0 to %82 step %c1 iter_args(%arg17 = %49, %arg18 = %49, %arg19 = %49) -> (i32, i32, i32) {
        %84 = arith.muli %arg16, %36 : index
        %85 = arith.addi %arg15, %84 : index
        %86 = arith.index_cast %85 : index to i32
        %87 = arith.divsi %86, %c32_i32 : i32
        %88 = arith.remsi %86, %c32_i32 : i32
        %89 = arith.subi %61, %84 : index
        %90 = arith.subi %89, %arg15 : index
        %91 = arith.addi %90, %50 : index
        %92 = arith.addi %84, %arg15 : index
        %93 = arith.cmpi slt, %92, %c0 : index
        %94 = arith.subi %c-1, %92 : index
        %95 = arith.select %93, %94, %92 : index
        %96 = arith.divsi %95, %c32 : index
        %97 = arith.subi %c-1, %96 : index
        %98 = arith.select %93, %97, %96 : index
        %99 = arith.muli %98, %c32 : index
        %100 = arith.addi %91, %99 : index
        %101 = arith.addi %100, %c-1 : index
        %102 = arith.cmpi sge, %101, %c0 : index
        %103 = arith.subi %63, %98 : index
        %104 = arith.addi %103, %c-1 : index
        %105 = arith.cmpi sge, %104, %c0 : index
        %106 = arith.andi %102, %105 : i1
        %107:3 = scf.if %106 -> (i32, i32, i32) {
          %108:4 = scf.if %67 -> (i32, i32, i32, f32) {
            %118 = arith.remsi %92, %c32 : index
            %119 = arith.cmpi slt, %118, %c0 : index
            %120 = arith.addi %118, %c32 : index
            %121 = arith.select %119, %120, %118 : index
            %122 = arith.muli %121, %52 : index
            %123 = arith.muli %98, %52 : index
            %124 = arith.muli %123, %42 : index
            %125 = arith.addi %122, %124 : index
            %126 = memref.load %alloca[%125] : memref<1xf32, 5>
            %127 = memref.load %alloca[%41] : memref<1xf32, 5>
            %128 = arith.mulf %126, %127 : f32
            %129 = arith.addf %128, %cst : f32
            %130 = arith.addi %124, %122 : index
            %131 = arith.addi %130, %c1 : index
            %132 = memref.load %alloca[%131] : memref<1xf32, 5>
            %133 = memref.load %alloca[%68] : memref<1xf32, 5>
            %134 = arith.mulf %132, %133 : f32
            %135 = arith.addf %129, %134 : f32
            %136 = arith.addi %130, %c2 : index
            %137 = memref.load %alloca[%136] : memref<1xf32, 5>
            %138 = memref.load %alloca[%69] : memref<1xf32, 5>
            %139 = arith.mulf %137, %138 : f32
            %140 = arith.addf %135, %139 : f32
            %141 = arith.addi %123, %c1 : index
            %142 = arith.muli %141, %42 : index
            %143 = arith.addi %122, %142 : index
            %144 = memref.load %alloca[%143] : memref<1xf32, 5>
            %145 = memref.load %alloca[%70] : memref<1xf32, 5>
            %146 = arith.mulf %144, %145 : f32
            %147 = arith.addf %140, %146 : f32
            %148 = arith.addi %143, %c1 : index
            %149 = memref.load %alloca[%148] : memref<1xf32, 5>
            %150 = memref.load %alloca[%71] : memref<1xf32, 5>
            %151 = arith.mulf %149, %150 : f32
            %152 = arith.addf %147, %151 : f32
            %153 = arith.addi %143, %c2 : index
            %154 = memref.load %alloca[%153] : memref<1xf32, 5>
            %155 = memref.load %alloca[%72] : memref<1xf32, 5>
            %156 = arith.mulf %154, %155 : f32
            %157 = arith.addf %152, %156 : f32
            %158 = arith.addi %123, %c2 : index
            %159 = arith.muli %158, %42 : index
            %160 = arith.addi %122, %159 : index
            %161 = memref.load %alloca[%160] : memref<1xf32, 5>
            %162 = memref.load %alloca[%73] : memref<1xf32, 5>
            %163 = arith.mulf %161, %162 : f32
            %164 = arith.addf %157, %163 : f32
            %165 = arith.addi %160, %c1 : index
            %166 = memref.load %alloca[%165] : memref<1xf32, 5>
            %167 = memref.load %alloca[%74] : memref<1xf32, 5>
            %168 = arith.mulf %166, %167 : f32
            %169 = arith.addf %164, %168 : f32
            %170 = arith.addi %160, %c2 : index
            %171 = memref.load %alloca[%170] : memref<1xf32, 5>
            %172 = memref.load %alloca[%75] : memref<1xf32, 5>
            %173 = arith.mulf %171, %172 : f32
            %174 = arith.addf %169, %173 : f32
            scf.yield %arg17, %arg18, %arg19, %174 : i32, i32, i32, f32
          } else {
            %118 = arith.muli %87, %arg12 : i32
            %119 = arith.muli %88, %arg12 : i32
            %120 = arith.remsi %92, %c32 : index
            %121 = arith.cmpi slt, %120, %c0 : index
            %122 = arith.addi %120, %c32 : index
            %123 = arith.select %121, %122, %120 : index
            %124 = arith.muli %123, %52 : index
            %125 = arith.muli %98, %52 : index
            %126:4 = scf.for %arg20 = %c0 to %51 step %c1 iter_args(%arg21 = %arg17, %arg22 = %arg18, %arg23 = %cst, %arg24 = %arg19) -> (i32, i32, f32, i32) {
              %127 = arith.index_cast %arg20 : index to i32
              %128 = arith.addi %118, %127 : i32
              %129 = arith.addi %arg20, %125 : index
              %130 = arith.muli %129, %42 : index
              %131 = arith.muli %arg20, %51 : index
              %132:3 = scf.for %arg25 = %c0 to %51 step %c1 iter_args(%arg26 = %arg23, %arg27 = %arg21, %arg28 = %arg22) -> (f32, i32, i32) {
                %133 = arith.index_cast %arg25 : index to i32
                %134 = arith.addi %119, %133 : i32
                %135 = arith.addi %arg25, %124 : index
                %136 = arith.addi %135, %130 : index
                %137 = memref.load %alloca[%136] : memref<1xf32, 5>
                %138 = arith.addi %arg25, %131 : index
                %139 = arith.addi %138, %41 : index
                %140 = memref.load %alloca[%139] : memref<1xf32, 5>
                %141 = arith.mulf %137, %140 : f32
                %142 = arith.addf %arg26, %141 : f32
                scf.yield %142, %134, %128 : f32, i32, i32
              }
              scf.yield %132#1, %132#2, %132#0, %arg11 : i32, i32, f32, i32
            }
            scf.yield %126#0, %126#1, %126#3, %126#2 : i32, i32, i32, f32
          }
          %109 = scf.if %56 -> (f32) {
            %118 = memref.load %arg2[%48] : memref<?xf32>
            %119 = arith.addf %108#3, %118 : f32
            scf.yield %119 : f32
          } else {
            scf.yield %108#3 : f32
          }
          %110 = arith.addi %84, %79 : index
          %111 = arith.addi %110, %arg15 : index
          %112 = arith.addi %111, %64 : index
          %113 = arith.muli %98, %c-32 : index
          %114 = arith.addi %112, %113 : index
          %115 = arith.addi %98, %65 : index
          %116 = arith.muli %115, %50 : index
          %117 = arith.addi %114, %116 : index
          memref.store %109, %arg3[%117] : memref<?xf32>
          scf.yield %108#0, %108#1, %108#2 : i32, i32, i32
        } else {
          scf.yield %arg17, %arg18, %arg19 : i32, i32, i32
        }
        scf.yield %107#0, %107#1, %107#2 : i32, i32, i32
      }
      scf.yield
    }
    return
  }
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii_0 {
    gpu.func @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) {
      %c1024 = arith.constant 1024 : index
      %c0_i32 = arith.constant 0 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c31_i32 = arith.constant 31 : i32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c-32 = arith.constant -32 : index
      %c2 = arith.constant 2 : index
      %c-3 = arith.constant -3 : index
      %c3 = arith.constant 3 : index
      %c4 = arith.constant 4 : index
      %c5 = arith.constant 5 : index
      %c6 = arith.constant 6 : index
      %c7 = arith.constant 7 : index
      %c8 = arith.constant 8 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<1xf32, 5>
      %0 = gpu.block_id  z
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.remsi %1, %arg8 : i32
      %3 = arith.remsi %2, %arg14 : i32
      %4 = gpu.block_id  x
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.muli %5, %c32_i32 : i32
      %7 = gpu.block_id  y
      %8 = arith.index_cast %7 : index to i32
      %9 = arith.muli %8, %c32_i32 : i32
      %10 = arith.muli %6, %arg12 : i32
      %11 = arith.subi %10, %arg13 : i32
      %12 = arith.muli %9, %arg12 : i32
      %13 = arith.subi %12, %arg13 : i32
      %14 = arith.muli %arg12, %c31_i32 : i32
      %15 = arith.addi %14, %arg11 : i32
      %16 = arith.muli %15, %15 : i32
      %17 = arith.index_cast %16 : i32 to index
      %18 = gpu.block_dim  x
      %19 = arith.muli %arg11, %arg11 : i32
      %20 = arith.index_cast %19 : i32 to index
      %21 = arith.muli %arg14, %arg11 : i32
      %22 = arith.muli %21, %arg11 : i32
      %23 = arith.muli %3, %19 : i32
      %24 = arith.subi %18, %c1 : index
      %25 = arith.muli %arg5, %arg6 : i32
      %26 = arith.muli %25, %arg7 : i32
      %27 = arith.muli %arg6, %arg7 : i32
      %28 = arith.divsi %1, %arg8 : i32
      %29 = arith.divsi %2, %arg14 : i32
      %30 = arith.muli %29, %22 : i32
      %31 = arith.addi %30, %23 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.muli %28, %26 : i32
      %34 = arith.muli %29, %27 : i32
      %35 = arith.addi %33, %34 : i32
      scf.parallel (%arg15) = (%c0) to (%c32) step (%c1) {
        %68 = arith.subi %20, %arg15 : index
        %69 = arith.addi %24, %68 : index
        %70 = arith.divui %69, %18 : index
        scf.for %arg16 = %c0 to %70 step %c1 {
          %74 = arith.muli %arg16, %18 : index
          %75 = arith.addi %74, %32 : index
          %76 = arith.addi %75, %arg15 : index
          %77 = memref.load %arg1[%76] : memref<?xf32>
          %78 = arith.addi %74, %arg15 : index
          %79 = arith.addi %78, %17 : index
          memref.store %77, %alloca[%79] : memref<1xf32, 5>
        }
        %71 = arith.subi %17, %arg15 : index
        %72 = arith.addi %24, %71 : index
        %73 = arith.divui %72, %18 : index
        scf.for %arg16 = %c0 to %73 step %c1 {
          %74 = arith.muli %arg16, %18 : index
          %75 = arith.addi %arg15, %74 : index
          %76 = arith.index_cast %75 : index to i32
          %77 = arith.divsi %76, %15 : i32
          %78 = arith.remsi %76, %15 : i32
          %79 = arith.addi %13, %77 : i32
          %80 = arith.addi %11, %78 : i32
          %81 = arith.cmpi sge, %79, %c0_i32 : i32
          %82 = arith.cmpi slt, %79, %arg6 : i32
          %83 = arith.cmpi sge, %80, %c0_i32 : i32
          %84 = arith.cmpi slt, %80, %arg7 : i32
          %85 = arith.andi %83, %84 : i1
          %86 = arith.andi %82, %85 : i1
          %87 = arith.andi %81, %86 : i1
          %88 = scf.if %87 -> (f32) {
            %90 = arith.muli %79, %arg7 : i32
            %91 = arith.addi %35, %90 : i32
            %92 = arith.addi %91, %80 : i32
            %93 = arith.index_cast %92 : i32 to index
            %94 = memref.load %arg0[%93] : memref<?xf32>
            scf.yield %94 : f32
          } else {
            scf.yield %cst : f32
          }
          %89 = arith.addi %74, %arg15 : index
          memref.store %88, %alloca[%89] : memref<1xf32, 5>
        }
        scf.yield
      }
      %36 = arith.index_cast %15 : i32 to index
      %37 = arith.index_cast %2 : i32 to index
      %38 = llvm.mlir.undef : i32
      %39 = arith.index_cast %arg10 : i32 to index
      %40 = arith.index_cast %arg11 : i32 to index
      %41 = arith.index_cast %arg12 : i32 to index
      %42 = arith.index_cast %arg9 : i32 to index
      %43 = llvm.mlir.zero : !llvm.ptr
      %44 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %45 = llvm.icmp "ne" %44, %43 : !llvm.ptr
      %46 = arith.muli %arg8, %arg9 : i32
      %47 = arith.muli %46, %arg10 : i32
      %48 = arith.muli %arg9, %arg10 : i32
      %49 = arith.muli %2, %48 : i32
      %50 = arith.muli %4, %c-32 : index
      %51 = arith.muli %7, %c-32 : index
      %52 = arith.addi %51, %42 : index
      %53 = arith.muli %4, %c32 : index
      %54 = arith.muli %7, %c32 : index
      %55 = arith.addi %40, %c-3 : index
      %56 = arith.cmpi eq, %55, %c0 : index
      %57 = arith.addi %17, %c1 : index
      %58 = arith.addi %17, %c2 : index
      %59 = arith.addi %17, %c3 : index
      %60 = arith.addi %17, %c4 : index
      %61 = arith.addi %17, %c5 : index
      %62 = arith.addi %17, %c6 : index
      %63 = arith.addi %17, %c7 : index
      %64 = arith.addi %17, %c8 : index
      %65 = arith.muli %28, %47 : i32
      %66 = arith.addi %65, %49 : i32
      %67 = arith.index_cast %66 : i32 to index
      scf.parallel (%arg15) = (%c0) to (%c32) step (%c1) {
        %68 = arith.subi %c1024, %arg15 : index
        %69 = arith.addi %24, %68 : index
        %70 = arith.divui %69, %18 : index
        %71:3 = scf.for %arg16 = %c0 to %70 step %c1 iter_args(%arg17 = %38, %arg18 = %38, %arg19 = %38) -> (i32, i32, i32) {
          %72 = arith.muli %arg16, %18 : index
          %73 = arith.addi %arg15, %72 : index
          %74 = arith.index_cast %73 : index to i32
          %75 = arith.divsi %74, %c32_i32 : i32
          %76 = arith.remsi %74, %c32_i32 : i32
          %77 = arith.subi %50, %72 : index
          %78 = arith.subi %77, %arg15 : index
          %79 = arith.addi %78, %39 : index
          %80 = arith.addi %72, %arg15 : index
          %81 = arith.cmpi slt, %80, %c0 : index
          %82 = arith.subi %c-1, %80 : index
          %83 = arith.select %81, %82, %80 : index
          %84 = arith.divsi %83, %c32 : index
          %85 = arith.subi %c-1, %84 : index
          %86 = arith.select %81, %85, %84 : index
          %87 = arith.muli %86, %c32 : index
          %88 = arith.addi %79, %87 : index
          %89 = arith.addi %88, %c-1 : index
          %90 = arith.cmpi sge, %89, %c0 : index
          %91 = arith.subi %52, %86 : index
          %92 = arith.addi %91, %c-1 : index
          %93 = arith.cmpi sge, %92, %c0 : index
          %94 = arith.andi %90, %93 : i1
          %95:3 = scf.if %94 -> (i32, i32, i32) {
            %96:4 = scf.if %56 -> (i32, i32, i32, f32) {
              %106 = arith.remsi %80, %c32 : index
              %107 = arith.cmpi slt, %106, %c0 : index
              %108 = arith.addi %106, %c32 : index
              %109 = arith.select %107, %108, %106 : index
              %110 = arith.muli %109, %41 : index
              %111 = arith.muli %86, %41 : index
              %112 = arith.muli %111, %36 : index
              %113 = arith.addi %110, %112 : index
              %114 = memref.load %alloca[%113] : memref<1xf32, 5>
              %115 = memref.load %alloca[%17] : memref<1xf32, 5>
              %116 = arith.mulf %114, %115 : f32
              %117 = arith.addf %116, %cst : f32
              %118 = arith.addi %112, %110 : index
              %119 = arith.addi %118, %c1 : index
              %120 = memref.load %alloca[%119] : memref<1xf32, 5>
              %121 = memref.load %alloca[%57] : memref<1xf32, 5>
              %122 = arith.mulf %120, %121 : f32
              %123 = arith.addf %117, %122 : f32
              %124 = arith.addi %118, %c2 : index
              %125 = memref.load %alloca[%124] : memref<1xf32, 5>
              %126 = memref.load %alloca[%58] : memref<1xf32, 5>
              %127 = arith.mulf %125, %126 : f32
              %128 = arith.addf %123, %127 : f32
              %129 = arith.addi %111, %c1 : index
              %130 = arith.muli %129, %36 : index
              %131 = arith.addi %110, %130 : index
              %132 = memref.load %alloca[%131] : memref<1xf32, 5>
              %133 = memref.load %alloca[%59] : memref<1xf32, 5>
              %134 = arith.mulf %132, %133 : f32
              %135 = arith.addf %128, %134 : f32
              %136 = arith.addi %131, %c1 : index
              %137 = memref.load %alloca[%136] : memref<1xf32, 5>
              %138 = memref.load %alloca[%60] : memref<1xf32, 5>
              %139 = arith.mulf %137, %138 : f32
              %140 = arith.addf %135, %139 : f32
              %141 = arith.addi %131, %c2 : index
              %142 = memref.load %alloca[%141] : memref<1xf32, 5>
              %143 = memref.load %alloca[%61] : memref<1xf32, 5>
              %144 = arith.mulf %142, %143 : f32
              %145 = arith.addf %140, %144 : f32
              %146 = arith.addi %111, %c2 : index
              %147 = arith.muli %146, %36 : index
              %148 = arith.addi %110, %147 : index
              %149 = memref.load %alloca[%148] : memref<1xf32, 5>
              %150 = memref.load %alloca[%62] : memref<1xf32, 5>
              %151 = arith.mulf %149, %150 : f32
              %152 = arith.addf %145, %151 : f32
              %153 = arith.addi %148, %c1 : index
              %154 = memref.load %alloca[%153] : memref<1xf32, 5>
              %155 = memref.load %alloca[%63] : memref<1xf32, 5>
              %156 = arith.mulf %154, %155 : f32
              %157 = arith.addf %152, %156 : f32
              %158 = arith.addi %148, %c2 : index
              %159 = memref.load %alloca[%158] : memref<1xf32, 5>
              %160 = memref.load %alloca[%64] : memref<1xf32, 5>
              %161 = arith.mulf %159, %160 : f32
              %162 = arith.addf %157, %161 : f32
              scf.yield %arg17, %arg18, %arg19, %162 : i32, i32, i32, f32
            } else {
              %106 = arith.muli %75, %arg12 : i32
              %107 = arith.muli %76, %arg12 : i32
              %108 = arith.remsi %80, %c32 : index
              %109 = arith.cmpi slt, %108, %c0 : index
              %110 = arith.addi %108, %c32 : index
              %111 = arith.select %109, %110, %108 : index
              %112 = arith.muli %111, %41 : index
              %113 = arith.muli %86, %41 : index
              %114:4 = scf.for %arg20 = %c0 to %40 step %c1 iter_args(%arg21 = %arg17, %arg22 = %arg18, %arg23 = %cst, %arg24 = %arg19) -> (i32, i32, f32, i32) {
                %115 = arith.index_cast %arg20 : index to i32
                %116 = arith.addi %106, %115 : i32
                %117 = arith.addi %arg20, %113 : index
                %118 = arith.muli %117, %36 : index
                %119 = arith.muli %arg20, %40 : index
                %120:3 = scf.for %arg25 = %c0 to %40 step %c1 iter_args(%arg26 = %arg23, %arg27 = %arg21, %arg28 = %arg22) -> (f32, i32, i32) {
                  %121 = arith.index_cast %arg25 : index to i32
                  %122 = arith.addi %107, %121 : i32
                  %123 = arith.addi %arg25, %112 : index
                  %124 = arith.addi %123, %118 : index
                  %125 = memref.load %alloca[%124] : memref<1xf32, 5>
                  %126 = arith.addi %arg25, %119 : index
                  %127 = arith.addi %126, %17 : index
                  %128 = memref.load %alloca[%127] : memref<1xf32, 5>
                  %129 = arith.mulf %125, %128 : f32
                  %130 = arith.addf %arg26, %129 : f32
                  scf.yield %130, %122, %116 : f32, i32, i32
                }
                scf.yield %120#1, %120#2, %120#0, %arg11 : i32, i32, f32, i32
              }
              scf.yield %114#0, %114#1, %114#3, %114#2 : i32, i32, i32, f32
            }
            %97 = scf.if %45 -> (f32) {
              %106 = memref.load %arg2[%37] : memref<?xf32>
              %107 = arith.addf %96#3, %106 : f32
              scf.yield %107 : f32
            } else {
              scf.yield %96#3 : f32
            }
            %98 = arith.addi %72, %67 : index
            %99 = arith.addi %98, %arg15 : index
            %100 = arith.addi %99, %53 : index
            %101 = arith.muli %86, %c-32 : index
            %102 = arith.addi %100, %101 : index
            %103 = arith.addi %86, %54 : index
            %104 = arith.muli %103, %39 : index
            %105 = arith.addi %102, %104 : index
            memref.store %97, %arg3[%105] : memref<?xf32>
            scf.yield %96#0, %96#1, %96#2 : i32, i32, i32
          } else {
            scf.yield %arg17, %arg18, %arg19 : i32, i32, i32
          }
          scf.yield %95#0, %95#1, %95#2 : i32, i32, i32
        }
        scf.yield
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii_0 {
    gpu.func @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) {
      %c1024 = arith.constant 1024 : index
      %c0_i32 = arith.constant 0 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c31_i32 = arith.constant 31 : i32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c-32 = arith.constant -32 : index
      %c2 = arith.constant 2 : index
      %c-3 = arith.constant -3 : index
      %c3 = arith.constant 3 : index
      %c4 = arith.constant 4 : index
      %c5 = arith.constant 5 : index
      %c6 = arith.constant 6 : index
      %c7 = arith.constant 7 : index
      %c8 = arith.constant 8 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<1xf32, 5>
      %0 = gpu.block_id  z
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.remsi %1, %arg8 : i32
      %3 = arith.remsi %2, %arg14 : i32
      %4 = gpu.block_id  x
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.muli %5, %c32_i32 : i32
      %7 = gpu.block_id  y
      %8 = arith.index_cast %7 : index to i32
      %9 = arith.muli %8, %c32_i32 : i32
      %10 = arith.muli %6, %arg12 : i32
      %11 = arith.subi %10, %arg13 : i32
      %12 = arith.muli %9, %arg12 : i32
      %13 = arith.subi %12, %arg13 : i32
      %14 = arith.muli %arg12, %c31_i32 : i32
      %15 = arith.addi %14, %arg11 : i32
      %16 = arith.muli %15, %15 : i32
      %17 = arith.index_cast %16 : i32 to index
      %c32_0 = arith.constant 32 : index
      %18 = arith.muli %arg11, %arg11 : i32
      %19 = arith.index_cast %18 : i32 to index
      %20 = arith.muli %arg14, %arg11 : i32
      %21 = arith.muli %20, %arg11 : i32
      %22 = arith.muli %3, %18 : i32
      %23 = arith.subi %c32_0, %c1 : index
      %24 = arith.muli %arg5, %arg6 : i32
      %25 = arith.muli %24, %arg7 : i32
      %26 = arith.muli %arg6, %arg7 : i32
      %27 = arith.divsi %1, %arg8 : i32
      %28 = arith.divsi %2, %arg14 : i32
      %29 = arith.muli %28, %21 : i32
      %30 = arith.addi %29, %22 : i32
      %31 = arith.index_cast %30 : i32 to index
      %32 = arith.muli %27, %25 : i32
      %33 = arith.muli %28, %26 : i32
      %34 = arith.addi %32, %33 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg15 = %c0 to %c32 step %c1_1 {
        %67 = arith.subi %19, %arg15 : index
        %68 = arith.addi %23, %67 : index
        %69 = arith.divui %68, %c32_0 : index
        scf.for %arg16 = %c0 to %69 step %c1 {
          %73 = arith.muli %arg16, %c32_0 : index
          %74 = arith.addi %73, %31 : index
          %75 = arith.addi %74, %arg15 : index
          %76 = memref.load %arg1[%75] : memref<?xf32>
          %77 = arith.addi %73, %arg15 : index
          %78 = arith.addi %77, %17 : index
          memref.store %76, %alloca[%78] : memref<1xf32, 5>
        }
        %70 = arith.subi %17, %arg15 : index
        %71 = arith.addi %23, %70 : index
        %72 = arith.divui %71, %c32_0 : index
        scf.for %arg16 = %c0 to %72 step %c1 {
          %73 = arith.muli %arg16, %c32_0 : index
          %74 = arith.addi %arg15, %73 : index
          %75 = arith.index_cast %74 : index to i32
          %76 = arith.divsi %75, %15 : i32
          %77 = arith.remsi %75, %15 : i32
          %78 = arith.addi %13, %76 : i32
          %79 = arith.addi %11, %77 : i32
          %80 = arith.cmpi sge, %78, %c0_i32 : i32
          %81 = arith.cmpi slt, %78, %arg6 : i32
          %82 = arith.cmpi sge, %79, %c0_i32 : i32
          %83 = arith.cmpi slt, %79, %arg7 : i32
          %84 = arith.andi %82, %83 : i1
          %85 = arith.andi %81, %84 : i1
          %86 = arith.andi %80, %85 : i1
          %87 = scf.if %86 -> (f32) {
            %89 = arith.muli %78, %arg7 : i32
            %90 = arith.addi %34, %89 : i32
            %91 = arith.addi %90, %79 : i32
            %92 = arith.index_cast %91 : i32 to index
            %93 = memref.load %arg0[%92] : memref<?xf32>
            scf.yield %93 : f32
          } else {
            scf.yield %cst : f32
          }
          %88 = arith.addi %73, %arg15 : index
          memref.store %87, %alloca[%88] : memref<1xf32, 5>
        }
      }
      %35 = arith.index_cast %15 : i32 to index
      %36 = arith.index_cast %2 : i32 to index
      %37 = llvm.mlir.undef : i32
      %38 = arith.index_cast %arg10 : i32 to index
      %39 = arith.index_cast %arg11 : i32 to index
      %40 = arith.index_cast %arg12 : i32 to index
      %41 = arith.index_cast %arg9 : i32 to index
      %42 = llvm.mlir.zero : !llvm.ptr
      %43 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %44 = llvm.icmp "ne" %43, %42 : !llvm.ptr
      %45 = arith.muli %arg8, %arg9 : i32
      %46 = arith.muli %45, %arg10 : i32
      %47 = arith.muli %arg9, %arg10 : i32
      %48 = arith.muli %2, %47 : i32
      %49 = arith.muli %4, %c-32 : index
      %50 = arith.muli %7, %c-32 : index
      %51 = arith.addi %50, %41 : index
      %52 = arith.muli %4, %c32 : index
      %53 = arith.muli %7, %c32 : index
      %54 = arith.addi %39, %c-3 : index
      %55 = arith.cmpi eq, %54, %c0 : index
      %56 = arith.addi %17, %c1 : index
      %57 = arith.addi %17, %c2 : index
      %58 = arith.addi %17, %c3 : index
      %59 = arith.addi %17, %c4 : index
      %60 = arith.addi %17, %c5 : index
      %61 = arith.addi %17, %c6 : index
      %62 = arith.addi %17, %c7 : index
      %63 = arith.addi %17, %c8 : index
      %64 = arith.muli %27, %46 : i32
      %65 = arith.addi %64, %48 : i32
      %66 = arith.index_cast %65 : i32 to index
      %c1_2 = arith.constant 1 : index
      scf.for %arg15 = %c0 to %c32 step %c1_2 {
        %67 = arith.subi %c1024, %arg15 : index
        %68 = arith.addi %23, %67 : index
        %69 = arith.divui %68, %c32_0 : index
        %70:3 = scf.for %arg16 = %c0 to %69 step %c1 iter_args(%arg17 = %37, %arg18 = %37, %arg19 = %37) -> (i32, i32, i32) {
          %71 = arith.muli %arg16, %c32_0 : index
          %72 = arith.addi %arg15, %71 : index
          %73 = arith.index_cast %72 : index to i32
          %74 = arith.divsi %73, %c32_i32 : i32
          %75 = arith.remsi %73, %c32_i32 : i32
          %76 = arith.subi %49, %71 : index
          %77 = arith.subi %76, %arg15 : index
          %78 = arith.addi %77, %38 : index
          %79 = arith.addi %71, %arg15 : index
          %80 = arith.cmpi slt, %79, %c0 : index
          %81 = arith.subi %c-1, %79 : index
          %82 = arith.select %80, %81, %79 : index
          %83 = arith.divsi %82, %c32 : index
          %84 = arith.subi %c-1, %83 : index
          %85 = arith.select %80, %84, %83 : index
          %86 = arith.muli %85, %c32 : index
          %87 = arith.addi %78, %86 : index
          %88 = arith.addi %87, %c-1 : index
          %89 = arith.cmpi sge, %88, %c0 : index
          %90 = arith.subi %51, %85 : index
          %91 = arith.addi %90, %c-1 : index
          %92 = arith.cmpi sge, %91, %c0 : index
          %93 = arith.andi %89, %92 : i1
          %94:3 = scf.if %93 -> (i32, i32, i32) {
            %95:4 = scf.if %55 -> (i32, i32, i32, f32) {
              %105 = arith.remsi %79, %c32 : index
              %106 = arith.cmpi slt, %105, %c0 : index
              %107 = arith.addi %105, %c32 : index
              %108 = arith.select %106, %107, %105 : index
              %109 = arith.muli %108, %40 : index
              %110 = arith.muli %85, %40 : index
              %111 = arith.muli %110, %35 : index
              %112 = arith.addi %109, %111 : index
              %113 = memref.load %alloca[%112] : memref<1xf32, 5>
              %114 = memref.load %alloca[%17] : memref<1xf32, 5>
              %115 = arith.mulf %113, %114 : f32
              %116 = arith.addf %115, %cst : f32
              %117 = arith.addi %111, %109 : index
              %118 = arith.addi %117, %c1 : index
              %119 = memref.load %alloca[%118] : memref<1xf32, 5>
              %120 = memref.load %alloca[%56] : memref<1xf32, 5>
              %121 = arith.mulf %119, %120 : f32
              %122 = arith.addf %116, %121 : f32
              %123 = arith.addi %117, %c2 : index
              %124 = memref.load %alloca[%123] : memref<1xf32, 5>
              %125 = memref.load %alloca[%57] : memref<1xf32, 5>
              %126 = arith.mulf %124, %125 : f32
              %127 = arith.addf %122, %126 : f32
              %128 = arith.addi %110, %c1 : index
              %129 = arith.muli %128, %35 : index
              %130 = arith.addi %109, %129 : index
              %131 = memref.load %alloca[%130] : memref<1xf32, 5>
              %132 = memref.load %alloca[%58] : memref<1xf32, 5>
              %133 = arith.mulf %131, %132 : f32
              %134 = arith.addf %127, %133 : f32
              %135 = arith.addi %130, %c1 : index
              %136 = memref.load %alloca[%135] : memref<1xf32, 5>
              %137 = memref.load %alloca[%59] : memref<1xf32, 5>
              %138 = arith.mulf %136, %137 : f32
              %139 = arith.addf %134, %138 : f32
              %140 = arith.addi %130, %c2 : index
              %141 = memref.load %alloca[%140] : memref<1xf32, 5>
              %142 = memref.load %alloca[%60] : memref<1xf32, 5>
              %143 = arith.mulf %141, %142 : f32
              %144 = arith.addf %139, %143 : f32
              %145 = arith.addi %110, %c2 : index
              %146 = arith.muli %145, %35 : index
              %147 = arith.addi %109, %146 : index
              %148 = memref.load %alloca[%147] : memref<1xf32, 5>
              %149 = memref.load %alloca[%61] : memref<1xf32, 5>
              %150 = arith.mulf %148, %149 : f32
              %151 = arith.addf %144, %150 : f32
              %152 = arith.addi %147, %c1 : index
              %153 = memref.load %alloca[%152] : memref<1xf32, 5>
              %154 = memref.load %alloca[%62] : memref<1xf32, 5>
              %155 = arith.mulf %153, %154 : f32
              %156 = arith.addf %151, %155 : f32
              %157 = arith.addi %147, %c2 : index
              %158 = memref.load %alloca[%157] : memref<1xf32, 5>
              %159 = memref.load %alloca[%63] : memref<1xf32, 5>
              %160 = arith.mulf %158, %159 : f32
              %161 = arith.addf %156, %160 : f32
              scf.yield %arg17, %arg18, %arg19, %161 : i32, i32, i32, f32
            } else {
              %105 = arith.muli %74, %arg12 : i32
              %106 = arith.muli %75, %arg12 : i32
              %107 = arith.remsi %79, %c32 : index
              %108 = arith.cmpi slt, %107, %c0 : index
              %109 = arith.addi %107, %c32 : index
              %110 = arith.select %108, %109, %107 : index
              %111 = arith.muli %110, %40 : index
              %112 = arith.muli %85, %40 : index
              %113:4 = scf.for %arg20 = %c0 to %39 step %c1 iter_args(%arg21 = %arg17, %arg22 = %arg18, %arg23 = %cst, %arg24 = %arg19) -> (i32, i32, f32, i32) {
                %114 = arith.index_cast %arg20 : index to i32
                %115 = arith.addi %105, %114 : i32
                %116 = arith.addi %arg20, %112 : index
                %117 = arith.muli %116, %35 : index
                %118 = arith.muli %arg20, %39 : index
                %119:3 = scf.for %arg25 = %c0 to %39 step %c1 iter_args(%arg26 = %arg23, %arg27 = %arg21, %arg28 = %arg22) -> (f32, i32, i32) {
                  %120 = arith.index_cast %arg25 : index to i32
                  %121 = arith.addi %106, %120 : i32
                  %122 = arith.addi %arg25, %111 : index
                  %123 = arith.addi %122, %117 : index
                  %124 = memref.load %alloca[%123] : memref<1xf32, 5>
                  %125 = arith.addi %arg25, %118 : index
                  %126 = arith.addi %125, %17 : index
                  %127 = memref.load %alloca[%126] : memref<1xf32, 5>
                  %128 = arith.mulf %124, %127 : f32
                  %129 = arith.addf %arg26, %128 : f32
                  scf.yield %129, %121, %115 : f32, i32, i32
                }
                scf.yield %119#1, %119#2, %119#0, %arg11 : i32, i32, f32, i32
              }
              scf.yield %113#0, %113#1, %113#3, %113#2 : i32, i32, i32, f32
            }
            %96 = scf.if %44 -> (f32) {
              %105 = memref.load %arg2[%36] : memref<?xf32>
              %106 = arith.addf %95#3, %105 : f32
              scf.yield %106 : f32
            } else {
              scf.yield %95#3 : f32
            }
            %97 = arith.addi %71, %66 : index
            %98 = arith.addi %97, %arg15 : index
            %99 = arith.addi %98, %52 : index
            %100 = arith.muli %85, %c-32 : index
            %101 = arith.addi %99, %100 : index
            %102 = arith.addi %85, %53 : index
            %103 = arith.muli %102, %38 : index
            %104 = arith.addi %101, %103 : index
            memref.store %96, %arg3[%104] : memref<?xf32>
            scf.yield %95#0, %95#1, %95#2 : i32, i32, i32
          } else {
            scf.yield %arg17, %arg18, %arg19 : i32, i32, i32
          }
          scf.yield %94#0, %94#1, %94#2 : i32, i32, i32
        }
      }
      gpu.return
    }
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca = memref.alloca() : memref<1xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca = memref.alloca() : memref<1xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii_0 {
    gpu.func @_Z48depthwise_conv2d_unroll_gridstride_shared_kernelPKfS0_S0_Pfiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32) {
      %c1024 = arith.constant 1024 : index
      %c0_i32 = arith.constant 0 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c31_i32 = arith.constant 31 : i32
      %c32_i32 = arith.constant 32 : i32
      %c-1 = arith.constant -1 : index
      %c-32 = arith.constant -32 : index
      %c2 = arith.constant 2 : index
      %c-3 = arith.constant -3 : index
      %c3 = arith.constant 3 : index
      %c4 = arith.constant 4 : index
      %c5 = arith.constant 5 : index
      %c6 = arith.constant 6 : index
      %c7 = arith.constant 7 : index
      %c8 = arith.constant 8 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = gpu.block_id  z
      %2 = arith.index_cast %1 : index to i32
      %3 = arith.remsi %2, %arg8 : i32
      %4 = arith.remsi %3, %arg14 : i32
      %5 = gpu.block_id  x
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.muli %6, %c32_i32 : i32
      %8 = gpu.block_id  y
      %9 = arith.index_cast %8 : index to i32
      %10 = arith.muli %9, %c32_i32 : i32
      %11 = arith.muli %7, %arg12 : i32
      %12 = arith.subi %11, %arg13 : i32
      %13 = arith.muli %10, %arg12 : i32
      %14 = arith.subi %13, %arg13 : i32
      %15 = arith.muli %arg12, %c31_i32 : i32
      %16 = arith.addi %15, %arg11 : i32
      %17 = arith.muli %16, %16 : i32
      %18 = arith.index_cast %17 : i32 to index
      %c32_0 = arith.constant 32 : index
      %19 = arith.muli %arg11, %arg11 : i32
      %20 = arith.index_cast %19 : i32 to index
      %21 = arith.muli %arg14, %arg11 : i32
      %22 = arith.muli %21, %arg11 : i32
      %23 = arith.muli %4, %19 : i32
      %24 = arith.subi %c32_0, %c1 : index
      %25 = arith.muli %arg5, %arg6 : i32
      %26 = arith.muli %25, %arg7 : i32
      %27 = arith.muli %arg6, %arg7 : i32
      %28 = arith.divsi %2, %arg8 : i32
      %29 = arith.divsi %3, %arg14 : i32
      %30 = arith.muli %29, %22 : i32
      %31 = arith.addi %30, %23 : i32
      %32 = arith.index_cast %31 : i32 to index
      %33 = arith.muli %28, %26 : i32
      %34 = arith.muli %29, %27 : i32
      %35 = arith.addi %33, %34 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg15 = %c0 to %c32 step %c1_1 {
        %68 = arith.subi %20, %arg15 : index
        %69 = arith.addi %24, %68 : index
        %70 = arith.divui %69, %c32_0 : index
        scf.for %arg16 = %c0 to %70 step %c1 {
          %74 = arith.muli %arg16, %c32_0 : index
          %75 = arith.addi %74, %32 : index
          %76 = arith.addi %75, %arg15 : index
          %77 = memref.load %arg1[%76] : memref<?xf32>
          %78 = arith.addi %74, %arg15 : index
          %79 = arith.addi %78, %18 : index
          memref.store %77, %alloca[%79] : memref<1xf32, 5>
        }
        %71 = arith.subi %18, %arg15 : index
        %72 = arith.addi %24, %71 : index
        %73 = arith.divui %72, %c32_0 : index
        scf.for %arg16 = %c0 to %73 step %c1 {
          %74 = arith.muli %arg16, %c32_0 : index
          %75 = arith.addi %arg15, %74 : index
          %76 = arith.index_cast %75 : index to i32
          %77 = arith.divsi %76, %16 : i32
          %78 = arith.remsi %76, %16 : i32
          %79 = arith.addi %14, %77 : i32
          %80 = arith.addi %12, %78 : i32
          %81 = arith.cmpi sge, %79, %c0_i32 : i32
          %82 = arith.cmpi slt, %79, %arg6 : i32
          %83 = arith.cmpi sge, %80, %c0_i32 : i32
          %84 = arith.cmpi slt, %80, %arg7 : i32
          %85 = arith.andi %83, %84 : i1
          %86 = arith.andi %82, %85 : i1
          %87 = arith.andi %81, %86 : i1
          %88 = scf.if %87 -> (f32) {
            %90 = arith.muli %79, %arg7 : i32
            %91 = arith.addi %35, %90 : i32
            %92 = arith.addi %91, %80 : i32
            %93 = arith.index_cast %92 : i32 to index
            %94 = memref.load %arg0[%93] : memref<?xf32>
            scf.yield %94 : f32
          } else {
            scf.yield %cst : f32
          }
          %89 = arith.addi %74, %arg15 : index
          memref.store %88, %alloca[%89] : memref<1xf32, 5>
        }
      }
      %36 = arith.index_cast %16 : i32 to index
      %37 = arith.index_cast %3 : i32 to index
      %38 = llvm.mlir.undef : i32
      %39 = arith.index_cast %arg10 : i32 to index
      %40 = arith.index_cast %arg11 : i32 to index
      %41 = arith.index_cast %arg12 : i32 to index
      %42 = arith.index_cast %arg9 : i32 to index
      %43 = llvm.mlir.zero : !llvm.ptr
      %44 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %45 = llvm.icmp "ne" %44, %43 : !llvm.ptr
      %46 = arith.muli %arg8, %arg9 : i32
      %47 = arith.muli %46, %arg10 : i32
      %48 = arith.muli %arg9, %arg10 : i32
      %49 = arith.muli %3, %48 : i32
      %50 = arith.muli %5, %c-32 : index
      %51 = arith.muli %8, %c-32 : index
      %52 = arith.addi %51, %42 : index
      %53 = arith.muli %5, %c32 : index
      %54 = arith.muli %8, %c32 : index
      %55 = arith.addi %40, %c-3 : index
      %56 = arith.cmpi eq, %55, %c0 : index
      %57 = arith.addi %18, %c1 : index
      %58 = arith.addi %18, %c2 : index
      %59 = arith.addi %18, %c3 : index
      %60 = arith.addi %18, %c4 : index
      %61 = arith.addi %18, %c5 : index
      %62 = arith.addi %18, %c6 : index
      %63 = arith.addi %18, %c7 : index
      %64 = arith.addi %18, %c8 : index
      %65 = arith.muli %28, %47 : i32
      %66 = arith.addi %65, %49 : i32
      %67 = arith.index_cast %66 : i32 to index
      %c1_2 = arith.constant 1 : index
      scf.for %arg15 = %c0 to %c32 step %c1_2 {
        %68 = arith.subi %c1024, %arg15 : index
        %69 = arith.addi %24, %68 : index
        %70 = arith.divui %69, %c32_0 : index
        %71:3 = scf.for %arg16 = %c0 to %70 step %c1 iter_args(%arg17 = %38, %arg18 = %38, %arg19 = %38) -> (i32, i32, i32) {
          %72 = arith.muli %arg16, %c32_0 : index
          %73 = arith.addi %arg15, %72 : index
          %74 = arith.index_cast %73 : index to i32
          %75 = arith.divsi %74, %c32_i32 : i32
          %76 = arith.remsi %74, %c32_i32 : i32
          %77 = arith.subi %50, %72 : index
          %78 = arith.subi %77, %arg15 : index
          %79 = arith.addi %78, %39 : index
          %80 = arith.addi %72, %arg15 : index
          %81 = arith.cmpi slt, %80, %c0 : index
          %82 = arith.subi %c-1, %80 : index
          %83 = arith.select %81, %82, %80 : index
          %84 = arith.divsi %83, %c32 : index
          %85 = arith.subi %c-1, %84 : index
          %86 = arith.select %81, %85, %84 : index
          %87 = arith.muli %86, %c32 : index
          %88 = arith.addi %79, %87 : index
          %89 = arith.addi %88, %c-1 : index
          %90 = arith.cmpi sge, %89, %c0 : index
          %91 = arith.subi %52, %86 : index
          %92 = arith.addi %91, %c-1 : index
          %93 = arith.cmpi sge, %92, %c0 : index
          %94 = arith.andi %90, %93 : i1
          %95:3 = scf.if %94 -> (i32, i32, i32) {
            %96:4 = scf.if %56 -> (i32, i32, i32, f32) {
              %106 = arith.remsi %80, %c32 : index
              %107 = arith.cmpi slt, %106, %c0 : index
              %108 = arith.addi %106, %c32 : index
              %109 = arith.select %107, %108, %106 : index
              %110 = arith.muli %109, %41 : index
              %111 = arith.muli %86, %41 : index
              %112 = arith.muli %111, %36 : index
              %113 = arith.addi %110, %112 : index
              %114 = memref.load %alloca[%113] : memref<1xf32, 5>
              %115 = memref.load %alloca[%18] : memref<1xf32, 5>
              %116 = arith.mulf %114, %115 : f32
              %117 = arith.addf %116, %cst : f32
              %118 = arith.addi %112, %110 : index
              %119 = arith.addi %118, %c1 : index
              %120 = memref.load %alloca[%119] : memref<1xf32, 5>
              %121 = memref.load %alloca[%57] : memref<1xf32, 5>
              %122 = arith.mulf %120, %121 : f32
              %123 = arith.addf %117, %122 : f32
              %124 = arith.addi %118, %c2 : index
              %125 = memref.load %alloca[%124] : memref<1xf32, 5>
              %126 = memref.load %alloca[%58] : memref<1xf32, 5>
              %127 = arith.mulf %125, %126 : f32
              %128 = arith.addf %123, %127 : f32
              %129 = arith.addi %111, %c1 : index
              %130 = arith.muli %129, %36 : index
              %131 = arith.addi %110, %130 : index
              %132 = memref.load %alloca[%131] : memref<1xf32, 5>
              %133 = memref.load %alloca[%59] : memref<1xf32, 5>
              %134 = arith.mulf %132, %133 : f32
              %135 = arith.addf %128, %134 : f32
              %136 = arith.addi %131, %c1 : index
              %137 = memref.load %alloca[%136] : memref<1xf32, 5>
              %138 = memref.load %alloca[%60] : memref<1xf32, 5>
              %139 = arith.mulf %137, %138 : f32
              %140 = arith.addf %135, %139 : f32
              %141 = arith.addi %131, %c2 : index
              %142 = memref.load %alloca[%141] : memref<1xf32, 5>
              %143 = memref.load %alloca[%61] : memref<1xf32, 5>
              %144 = arith.mulf %142, %143 : f32
              %145 = arith.addf %140, %144 : f32
              %146 = arith.addi %111, %c2 : index
              %147 = arith.muli %146, %36 : index
              %148 = arith.addi %110, %147 : index
              %149 = memref.load %alloca[%148] : memref<1xf32, 5>
              %150 = memref.load %alloca[%62] : memref<1xf32, 5>
              %151 = arith.mulf %149, %150 : f32
              %152 = arith.addf %145, %151 : f32
              %153 = arith.addi %148, %c1 : index
              %154 = memref.load %alloca[%153] : memref<1xf32, 5>
              %155 = memref.load %alloca[%63] : memref<1xf32, 5>
              %156 = arith.mulf %154, %155 : f32
              %157 = arith.addf %152, %156 : f32
              %158 = arith.addi %148, %c2 : index
              %159 = memref.load %alloca[%158] : memref<1xf32, 5>
              %160 = memref.load %alloca[%64] : memref<1xf32, 5>
              %161 = arith.mulf %159, %160 : f32
              %162 = arith.addf %157, %161 : f32
              scf.yield %arg17, %arg18, %arg19, %162 : i32, i32, i32, f32
            } else {
              %106 = arith.muli %75, %arg12 : i32
              %107 = arith.muli %76, %arg12 : i32
              %108 = arith.remsi %80, %c32 : index
              %109 = arith.cmpi slt, %108, %c0 : index
              %110 = arith.addi %108, %c32 : index
              %111 = arith.select %109, %110, %108 : index
              %112 = arith.muli %111, %41 : index
              %113 = arith.muli %86, %41 : index
              %114:4 = scf.for %arg20 = %c0 to %40 step %c1 iter_args(%arg21 = %arg17, %arg22 = %arg18, %arg23 = %cst, %arg24 = %arg19) -> (i32, i32, f32, i32) {
                %115 = arith.index_cast %arg20 : index to i32
                %116 = arith.addi %106, %115 : i32
                %117 = arith.addi %arg20, %113 : index
                %118 = arith.muli %117, %36 : index
                %119 = arith.muli %arg20, %40 : index
                %120:3 = scf.for %arg25 = %c0 to %40 step %c1 iter_args(%arg26 = %arg23, %arg27 = %arg21, %arg28 = %arg22) -> (f32, i32, i32) {
                  %121 = arith.index_cast %arg25 : index to i32
                  %122 = arith.addi %107, %121 : i32
                  %123 = arith.addi %arg25, %112 : index
                  %124 = arith.addi %123, %118 : index
                  %125 = memref.load %alloca[%124] : memref<1xf32, 5>
                  %126 = arith.addi %arg25, %119 : index
                  %127 = arith.addi %126, %18 : index
                  %128 = memref.load %alloca[%127] : memref<1xf32, 5>
                  %129 = arith.mulf %125, %128 : f32
                  %130 = arith.addf %arg26, %129 : f32
                  scf.yield %130, %122, %116 : f32, i32, i32
                }
                scf.yield %120#1, %120#2, %120#0, %arg11 : i32, i32, f32, i32
              }
              scf.yield %114#0, %114#1, %114#3, %114#2 : i32, i32, i32, f32
            }
            %97 = scf.if %45 -> (f32) {
              %106 = memref.load %arg2[%37] : memref<?xf32>
              %107 = arith.addf %96#3, %106 : f32
              scf.yield %107 : f32
            } else {
              scf.yield %96#3 : f32
            }
            %98 = arith.addi %72, %67 : index
            %99 = arith.addi %98, %arg15 : index
            %100 = arith.addi %99, %53 : index
            %101 = arith.muli %86, %c-32 : index
            %102 = arith.addi %100, %101 : index
            %103 = arith.addi %86, %54 : index
            %104 = arith.muli %103, %39 : index
            %105 = arith.addi %102, %104 : index
            memref.store %97, %arg3[%105] : memref<?xf32>
            scf.yield %96#0, %96#1, %96#2 : i32, i32, i32
          } else {
            scf.yield %arg17, %arg18, %arg19 : i32, i32, i32
          }
          scf.yield %95#0, %95#1, %95#2 : i32, i32, i32
        }
      }
      gpu.return
    }
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] GPUBlockIdToNPULowering: process op: 

%1 = gpu.block_id  z
[ict-error] GPUBlockIdToNPULowering: block id dimension is not x

