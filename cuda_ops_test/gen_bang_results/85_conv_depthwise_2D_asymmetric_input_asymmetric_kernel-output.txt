warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z47__device_stub__combined_depthwise_conv2d_kernelPKfS0_S0_Pfiiiiiiiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z32combined_depthwise_conv2d_kernelPKfS0_S0_Pfiiiiiiiiiiiiiiiii(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9, %arg10, %arg11, %arg12, %arg13, %arg14, %arg15, %arg16, %arg17, %arg18, %arg19, %arg20) : (memref<?xf32>, memref<?xf32>, memref<?xf32>, memref<?xf32>, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) -> ()
    return
  }
  func.func private @_Z32combined_depthwise_conv2d_kernelPKfS0_S0_Pfiiiiiiiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1 = arith.constant 1 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4_i32 = arith.constant 4 : i32
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c16_i32 = arith.constant 16 : i32
    %c64_i32 = arith.constant 64 : i32
    %0 = arith.index_cast %arg12 : i32 to index
    %1 = arith.index_cast %arg14 : i32 to index
    %2 = arith.index_cast %arg18 : i32 to index
    %3 = arith.index_cast %arg17 : i32 to index
    %4 = arith.index_cast %arg11 : i32 to index
    %5 = arith.index_cast %arg12 : i32 to index
    %alloca = memref.alloca() : memref<4xf32>
    %alloca_0 = memref.alloca() : memref<1xf32, 5>
    %6 = gpu.block_id  z
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.divui %7, %arg8 : i32
    %9 = gpu.block_id  z
    %10 = arith.index_cast %9 : index to i32
    %11 = arith.remui %10, %arg8 : i32
    %12 = arith.index_cast %11 : i32 to index
    %13 = arith.divsi %11, %arg20 : i32
    %14 = arith.muli %13, %arg20 : i32
    %15 = arith.remsi %11, %arg20 : i32
    %16 = arith.addi %14, %15 : i32
    %17 = arith.muli %16, %arg11 : i32
    %18 = arith.index_cast %17 : i32 to index
    %19 = arith.muli %arg14, %c64_i32 : i32
    %20 = arith.addi %arg12, %c-1_i32 : i32
    %21 = arith.muli %20, %arg18 : i32
    %22 = arith.addi %19, %21 : i32
    %23 = arith.index_cast %22 : i32 to index
    %24 = arith.muli %arg13, %c16_i32 : i32
    %25 = arith.addi %arg11, %c-1_i32 : i32
    %26 = arith.muli %25, %arg17 : i32
    %27 = arith.addi %24, %26 : i32
    %28 = gpu.block_id  x
    %29 = arith.index_cast %28 : index to i32
    %30 = arith.muli %29, %c64_i32 : i32
    %31 = arith.muli %30, %arg14 : i32
    %32 = arith.subi %31, %arg16 : i32
    %33 = gpu.block_id  y
    %34 = arith.index_cast %33 : index to i32
    %35 = arith.muli %34, %c16_i32 : i32
    %36 = arith.muli %35, %arg13 : i32
    %37 = arith.subi %36, %arg15 : i32
    %38 = arith.muli %22, %27 : i32
    %39 = gpu.thread_id  x
    %40 = arith.index_cast %39 : index to i32
    %41 = arith.muli %40, %c4_i32 : i32
    %42 = arith.muli %41, %arg14 : i32
    %43 = arith.index_cast %42 : i32 to index
    %44 = gpu.thread_id  y
    %45 = arith.index_cast %44 : index to i32
    %46 = arith.muli %45, %arg13 : i32
    %47 = arith.index_cast %46 : i32 to index
    %48 = gpu.block_dim  x
    %49 = arith.index_cast %48 : index to i32
    %50 = arith.muli %45, %49 : i32
    %51 = arith.addi %50, %40 : i32
    %52 = gpu.block_dim  x
    %53 = arith.index_cast %52 : index to i32
    %54 = gpu.block_dim  y
    %55 = arith.index_cast %54 : index to i32
    %56 = arith.muli %53, %55 : i32
    %57 = arith.index_cast %38 : i32 to index
    %58 = arith.index_cast %51 : i32 to index
    %59 = arith.index_cast %56 : i32 to index
    %60 = arith.index_cast %56 : i32 to index
    %61 = arith.index_cast %51 : i32 to index
    %62 = arith.muli %8, %arg5 : i32
    %63 = arith.addi %62, %13 : i32
    %64 = arith.muli %63, %arg6 : i32
    %65 = arith.subi %57, %58 : index
    %66 = arith.subi %59, %c1 : index
    %67 = arith.addi %66, %65 : index
    %68 = arith.divui %67, %59 : index
    affine.for %arg21 = 0 to %68 {
      %74 = arith.muli %arg21, %59 : index
      %75 = arith.divui %74, %59 : index
      %76 = arith.muli %75, %60 : index
      %77 = arith.addi %61, %76 : index
      %78 = arith.index_cast %77 : index to i32
      %79 = arith.divsi %78, %22 : i32
      %80 = arith.remsi %78, %22 : i32
      %81 = arith.addi %37, %79 : i32
      %82 = arith.addi %32, %80 : i32
      %83 = arith.cmpi sge, %81, %c0_i32 : i32
      %84 = arith.cmpi slt, %81, %arg6 : i32
      %85 = arith.cmpi sge, %82, %c0_i32 : i32
      %86 = arith.cmpi slt, %82, %arg7 : i32
      %87 = arith.andi %85, %86 : i1
      %88 = arith.andi %84, %87 : i1
      %89 = arith.andi %83, %88 : i1
      %90 = scf.if %89 -> (f32) {
        %94 = arith.addi %64, %81 : i32
        %95 = arith.muli %94, %arg7 : i32
        %96 = arith.addi %95, %82 : i32
        %97 = arith.index_cast %96 : i32 to index
        %98 = memref.load %arg0[%97] : memref<?xf32>
        scf.yield %98 : f32
      } else {
        scf.yield %cst : f32
      }
      %91 = arith.muli %79, %22 : i32
      %92 = arith.addi %91, %80 : i32
      %93 = arith.index_cast %92 : i32 to index
      memref.store %90, %alloca_0[%93] : memref<1xf32, 5>
    }
    nvvm.barrier0
    %69 = gpu.block_id  y
    %70 = arith.index_cast %69 : index to i32
    %71 = arith.muli %70, %c16_i32 : i32
    %72 = arith.addi %71, %45 : i32
    %73 = arith.cmpi slt, %72, %arg9 : i32
    scf.if %73 {
      %74 = gpu.block_id  x
      %75 = arith.index_cast %74 : index to i32
      %76 = arith.muli %75, %c64_i32 : i32
      %77 = arith.muli %40, %c4_i32 : i32
      %78 = arith.addi %76, %77 : i32
      affine.store %cst, %alloca[0] : memref<4xf32>
      affine.store %cst, %alloca[1] : memref<4xf32>
      affine.store %cst, %alloca[2] : memref<4xf32>
      affine.store %cst, %alloca[3] : memref<4xf32>
      affine.for %arg21 = 0 to %4 {
        affine.for %arg22 = 0 to %5 {
          %87 = affine.load %arg1[%arg22 + (%arg21 + symbol(%18)) * symbol(%0)] : memref<?xf32>
          affine.for %arg23 = 0 to 4 {
            %88 = affine.load %alloca_0[%arg23 * symbol(%1) + %arg22 * symbol(%2) + symbol(%43) + (%arg21 * symbol(%3) + symbol(%47)) * symbol(%23)] : memref<1xf32, 5>
            %89 = arith.mulf %88, %87 : f32
            %90 = affine.load %alloca[%arg23] : memref<4xf32>
            %91 = arith.addf %90, %89 : f32
            affine.store %91, %alloca[%arg23] : memref<4xf32>
          }
        }
      }
      %79 = llvm.mlir.zero : !llvm.ptr
      %80 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %81 = llvm.icmp "ne" %80, %79 : !llvm.ptr
      %82 = arith.muli %8, %arg8 : i32
      %83 = arith.addi %82, %11 : i32
      %84 = arith.muli %83, %arg9 : i32
      %85 = arith.addi %84, %72 : i32
      %86 = arith.muli %85, %arg10 : i32
      affine.for %arg21 = 0 to 4 {
        %87 = arith.index_cast %arg21 : index to i32
        %88 = arith.addi %78, %87 : i32
        %89 = arith.cmpi slt, %88, %arg10 : i32
        scf.if %89 {
          %90 = affine.load %alloca[%arg21] : memref<4xf32>
          %91 = scf.if %81 -> (f32) {
            %94 = affine.load %arg2[symbol(%12)] : memref<?xf32>
            %95 = arith.addf %90, %94 : f32
            scf.yield %95 : f32
          } else {
            scf.yield %90 : f32
          }
          %92 = arith.addi %86, %88 : i32
          %93 = arith.index_cast %92 : i32 to index
          memref.store %91, %arg3[%93] : memref<?xf32>
        }
      }
    }
    return
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z32combined_depthwise_conv2d_kernelPKfS0_S0_Pfiiiiiiiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c64_i32 = arith.constant 64 : i32
    %c16_i32 = arith.constant 16 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i32 = arith.constant 0 : i32
    %c4_i32 = arith.constant 4 : i32
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %0 = arith.index_cast %arg10 : i32 to index
    %1 = arith.index_cast %arg12 : i32 to index
    %2 = arith.index_cast %arg14 : i32 to index
    %3 = arith.index_cast %arg18 : i32 to index
    %4 = arith.index_cast %arg17 : i32 to index
    %5 = arith.index_cast %arg11 : i32 to index
    %alloca = memref.alloca() : memref<4xf32>
    %alloca_0 = memref.alloca() : memref<1xf32, 5>
    %6 = gpu.block_id  z
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.divui %7, %arg8 : i32
    %9 = arith.muli %8, %arg8 : i32
    %10 = arith.remui %7, %arg8 : i32
    %11 = arith.addi %9, %10 : i32
    %12 = arith.muli %11, %arg9 : i32
    %13 = arith.index_cast %10 : i32 to index
    %14 = arith.divsi %10, %arg20 : i32
    %15 = arith.muli %14, %arg20 : i32
    %16 = arith.remsi %10, %arg20 : i32
    %17 = arith.addi %15, %16 : i32
    %18 = arith.muli %17, %arg11 : i32
    %19 = arith.index_cast %18 : i32 to index
    %20 = arith.muli %arg14, %c64_i32 : i32
    %21 = arith.addi %arg12, %c-1_i32 : i32
    %22 = arith.muli %21, %arg18 : i32
    %23 = arith.addi %20, %22 : i32
    %24 = arith.index_cast %23 : i32 to index
    %25 = arith.muli %arg13, %c16_i32 : i32
    %26 = arith.addi %arg11, %c-1_i32 : i32
    %27 = arith.muli %26, %arg17 : i32
    %28 = arith.addi %25, %27 : i32
    %29 = gpu.block_id  x
    %30 = arith.index_cast %29 : index to i32
    %31 = arith.muli %30, %c64_i32 : i32
    %32 = arith.muli %31, %arg14 : i32
    %33 = arith.subi %32, %arg16 : i32
    %34 = gpu.block_id  y
    %35 = arith.index_cast %34 : index to i32
    %36 = arith.muli %35, %c16_i32 : i32
    %37 = arith.muli %36, %arg13 : i32
    %38 = arith.subi %37, %arg15 : i32
    %39 = arith.muli %23, %28 : i32
    %40 = gpu.thread_id  x
    %41 = arith.index_cast %40 : index to i32
    %42 = arith.muli %41, %c4_i32 : i32
    %43 = arith.muli %42, %arg14 : i32
    %44 = arith.index_cast %43 : i32 to index
    %45 = gpu.thread_id  y
    %46 = arith.index_cast %45 : index to i32
    %47 = arith.muli %46, %arg13 : i32
    %48 = arith.index_cast %47 : i32 to index
    %49 = gpu.block_dim  x
    %50 = arith.index_cast %49 : index to i32
    %51 = arith.muli %46, %50 : i32
    %52 = arith.addi %51, %41 : i32
    %53 = gpu.block_dim  y
    %54 = arith.index_cast %53 : index to i32
    %55 = arith.muli %50, %54 : i32
    %56 = arith.index_cast %39 : i32 to index
    %57 = arith.index_cast %52 : i32 to index
    %58 = arith.index_cast %55 : i32 to index
    %59 = arith.muli %8, %arg5 : i32
    %60 = arith.addi %59, %14 : i32
    %61 = arith.muli %60, %arg6 : i32
    %62 = arith.subi %56, %57 : index
    %63 = arith.subi %58, %c1 : index
    %64 = arith.addi %63, %62 : index
    %65 = arith.divui %64, %58 : index
    affine.for %arg21 = 0 to %65 {
      %71 = arith.muli %arg21, %58 : index
      %72 = arith.addi %57, %71 : index
      %73 = arith.index_cast %72 : index to i32
      %74 = arith.divsi %73, %23 : i32
      %75 = arith.remsi %73, %23 : i32
      %76 = arith.addi %38, %74 : i32
      %77 = arith.addi %33, %75 : i32
      %78 = arith.cmpi sge, %76, %c0_i32 : i32
      %79 = arith.cmpi slt, %76, %arg6 : i32
      %80 = arith.cmpi sge, %77, %c0_i32 : i32
      %81 = arith.cmpi slt, %77, %arg7 : i32
      %82 = arith.andi %80, %81 : i1
      %83 = arith.andi %79, %82 : i1
      %84 = arith.andi %78, %83 : i1
      %85 = scf.if %84 -> (f32) {
        %89 = arith.addi %61, %76 : i32
        %90 = arith.muli %89, %arg7 : i32
        %91 = arith.addi %90, %77 : i32
        %92 = arith.index_cast %91 : i32 to index
        %93 = memref.load %arg0[%92] : memref<?xf32>
        scf.yield %93 : f32
      } else {
        scf.yield %cst : f32
      }
      %86 = arith.muli %74, %23 : i32
      %87 = arith.addi %86, %75 : i32
      %88 = arith.index_cast %87 : i32 to index
      memref.store %85, %alloca_0[%88] : memref<1xf32, 5>
    }
    nvvm.barrier0
    %66 = arith.addi %36, %46 : i32
    %67 = arith.addi %12, %66 : i32
    %68 = arith.muli %67, %arg10 : i32
    %69 = arith.index_cast %68 : i32 to index
    %70 = arith.cmpi slt, %66, %arg9 : i32
    scf.if %70 {
      affine.store %cst, %alloca[0] : memref<4xf32>
      affine.store %cst, %alloca[1] : memref<4xf32>
      affine.store %cst, %alloca[2] : memref<4xf32>
      affine.store %cst, %alloca[3] : memref<4xf32>
      affine.for %arg21 = 0 to %5 {
        affine.for %arg22 = 0 to %1 {
          %74 = affine.load %arg1[%arg22 + (%arg21 + symbol(%19)) * symbol(%1)] : memref<?xf32>
          affine.for %arg23 = 0 to 4 {
            %75 = affine.load %alloca_0[%arg23 * symbol(%2) + %arg22 * symbol(%3) + symbol(%44) + (%arg21 * symbol(%4) + symbol(%48)) * symbol(%24)] : memref<1xf32, 5>
            %76 = arith.mulf %75, %74 : f32
            %77 = affine.load %alloca[%arg23] : memref<4xf32>
            %78 = arith.addf %77, %76 : f32
            affine.store %78, %alloca[%arg23] : memref<4xf32>
          }
        }
      }
      %71 = llvm.mlir.zero : !llvm.ptr
      %72 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %73 = llvm.icmp "ne" %72, %71 : !llvm.ptr
      affine.for %arg21 = 0 to 4 {
        affine.if affine_set<(d0)[s0, s1, s2] : (-d0 - s0 * 64 - s1 * 4 + s2 - 1 >= 0)>(%arg21)[%29, %40, %0] {
          %74 = affine.load %alloca[%arg21] : memref<4xf32>
          %75 = scf.if %73 -> (f32) {
            %76 = affine.load %arg2[symbol(%13)] : memref<?xf32>
            %77 = arith.addf %74, %76 : f32
            scf.yield %77 : f32
          } else {
            scf.yield %74 : f32
          }
          affine.store %75, %arg3[%arg21 + symbol(%69) + symbol(%29) * 64 + symbol(%40) * 4] : memref<?xf32>
        }
      }
    }
    return
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z32combined_depthwise_conv2d_kernelPKfS0_S0_Pfiiiiiiiiiiiiiiiii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>, %arg3: memref<?xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32, %arg17: i32, %arg18: i32, %arg19: i32, %arg20: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c64 = arith.constant 64 : index
    %c-4 = arith.constant -4 : index
    %c-64 = arith.constant -64 : index
    %c-1 = arith.constant -1 : index
    %c4 = arith.constant 4 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c64_i32 = arith.constant 64 : i32
    %c16_i32 = arith.constant 16 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c0_i32 = arith.constant 0 : i32
    %c4_i32 = arith.constant 4 : i32
    %c-1_i32 = arith.constant -1 : i32
    %c1 = arith.constant 1 : index
    %0 = arith.index_cast %arg10 : i32 to index
    %1 = arith.index_cast %arg12 : i32 to index
    %2 = arith.index_cast %arg14 : i32 to index
    %3 = arith.index_cast %arg18 : i32 to index
    %4 = arith.index_cast %arg17 : i32 to index
    %5 = arith.index_cast %arg11 : i32 to index
    %alloca = memref.alloca() : memref<4xf32>
    %alloca_0 = memref.alloca() : memref<1xf32, 5>
    %6 = gpu.block_id  z
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.divui %7, %arg8 : i32
    %9 = arith.muli %8, %arg8 : i32
    %10 = arith.remui %7, %arg8 : i32
    %11 = arith.addi %9, %10 : i32
    %12 = arith.muli %11, %arg9 : i32
    %13 = arith.index_cast %10 : i32 to index
    %14 = arith.divsi %10, %arg20 : i32
    %15 = arith.muli %14, %arg20 : i32
    %16 = arith.remsi %10, %arg20 : i32
    %17 = arith.addi %15, %16 : i32
    %18 = arith.muli %17, %arg11 : i32
    %19 = arith.index_cast %18 : i32 to index
    %20 = arith.muli %arg14, %c64_i32 : i32
    %21 = arith.addi %arg12, %c-1_i32 : i32
    %22 = arith.muli %21, %arg18 : i32
    %23 = arith.addi %20, %22 : i32
    %24 = arith.index_cast %23 : i32 to index
    %25 = arith.muli %arg13, %c16_i32 : i32
    %26 = arith.addi %arg11, %c-1_i32 : i32
    %27 = arith.muli %26, %arg17 : i32
    %28 = arith.addi %25, %27 : i32
    %29 = gpu.block_id  x
    %30 = arith.index_cast %29 : index to i32
    %31 = arith.muli %30, %c64_i32 : i32
    %32 = arith.muli %31, %arg14 : i32
    %33 = arith.subi %32, %arg16 : i32
    %34 = gpu.block_id  y
    %35 = arith.index_cast %34 : index to i32
    %36 = arith.muli %35, %c16_i32 : i32
    %37 = arith.muli %36, %arg13 : i32
    %38 = arith.subi %37, %arg15 : i32
    %39 = arith.muli %23, %28 : i32
    %40 = gpu.thread_id  x
    %41 = arith.index_cast %40 : index to i32
    %42 = arith.muli %41, %c4_i32 : i32
    %43 = arith.muli %42, %arg14 : i32
    %44 = arith.index_cast %43 : i32 to index
    %45 = gpu.thread_id  y
    %46 = arith.index_cast %45 : index to i32
    %47 = arith.muli %46, %arg13 : i32
    %48 = arith.index_cast %47 : i32 to index
    %49 = gpu.block_dim  x
    %50 = arith.index_cast %49 : index to i32
    %51 = arith.muli %46, %50 : i32
    %52 = arith.addi %51, %41 : i32
    %53 = gpu.block_dim  y
    %54 = arith.index_cast %53 : index to i32
    %55 = arith.muli %50, %54 : i32
    %56 = arith.index_cast %39 : i32 to index
    %57 = arith.index_cast %52 : i32 to index
    %58 = arith.index_cast %55 : i32 to index
    %59 = arith.muli %8, %arg5 : i32
    %60 = arith.addi %59, %14 : i32
    %61 = arith.muli %60, %arg6 : i32
    %62 = arith.subi %56, %57 : index
    %63 = arith.subi %58, %c1 : index
    %64 = arith.addi %63, %62 : index
    %65 = arith.divui %64, %58 : index
    scf.for %arg21 = %c0 to %65 step %c1 {
      %71 = arith.muli %arg21, %58 : index
      %72 = arith.addi %57, %71 : index
      %73 = arith.index_cast %72 : index to i32
      %74 = arith.divsi %73, %23 : i32
      %75 = arith.remsi %73, %23 : i32
      %76 = arith.addi %38, %74 : i32
      %77 = arith.addi %33, %75 : i32
      %78 = arith.cmpi sge, %76, %c0_i32 : i32
      %79 = arith.cmpi slt, %76, %arg6 : i32
      %80 = arith.cmpi sge, %77, %c0_i32 : i32
      %81 = arith.cmpi slt, %77, %arg7 : i32
      %82 = arith.andi %80, %81 : i1
      %83 = arith.andi %79, %82 : i1
      %84 = arith.andi %78, %83 : i1
      %85 = scf.if %84 -> (f32) {
        %89 = arith.addi %61, %76 : i32
        %90 = arith.muli %89, %arg7 : i32
        %91 = arith.addi %90, %77 : i32
        %92 = arith.index_cast %91 : i32 to index
        %93 = memref.load %arg0[%92] : memref<?xf32>
        scf.yield %93 : f32
      } else {
        scf.yield %cst : f32
      }
      %86 = arith.muli %74, %23 : i32
      %87 = arith.addi %86, %75 : i32
      %88 = arith.index_cast %87 : i32 to index
      memref.store %85, %alloca_0[%88] : memref<1xf32, 5>
    }
    nvvm.barrier0
    %66 = arith.addi %36, %46 : i32
    %67 = arith.addi %12, %66 : i32
    %68 = arith.muli %67, %arg10 : i32
    %69 = arith.index_cast %68 : i32 to index
    %70 = arith.cmpi slt, %66, %arg9 : i32
    scf.if %70 {
      memref.store %cst, %alloca[%c0] : memref<4xf32>
      memref.store %cst, %alloca[%c1] : memref<4xf32>
      memref.store %cst, %alloca[%c2] : memref<4xf32>
      memref.store %cst, %alloca[%c3] : memref<4xf32>
      scf.for %arg21 = %c0 to %5 step %c1 {
        scf.for %arg22 = %c0 to %1 step %c1 {
          %74 = arith.addi %arg21, %19 : index
          %75 = arith.muli %74, %1 : index
          %76 = arith.addi %arg22, %75 : index
          %77 = memref.load %arg1[%76] : memref<?xf32>
          scf.for %arg23 = %c0 to %c4 step %c1 {
            %78 = arith.muli %arg23, %2 : index
            %79 = arith.muli %arg22, %3 : index
            %80 = arith.addi %78, %79 : index
            %81 = arith.addi %80, %44 : index
            %82 = arith.muli %arg21, %4 : index
            %83 = arith.addi %82, %48 : index
            %84 = arith.muli %83, %24 : index
            %85 = arith.addi %81, %84 : index
            %86 = memref.load %alloca_0[%85] : memref<1xf32, 5>
            %87 = arith.mulf %86, %77 : f32
            %88 = memref.load %alloca[%arg23] : memref<4xf32>
            %89 = arith.addf %88, %87 : f32
            memref.store %89, %alloca[%arg23] : memref<4xf32>
          }
        }
      }
      %71 = llvm.mlir.zero : !llvm.ptr
      %72 = "polygeist.memref2pointer"(%arg2) : (memref<?xf32>) -> !llvm.ptr
      %73 = llvm.icmp "ne" %72, %71 : !llvm.ptr
      scf.for %arg21 = %c0 to %c4 step %c1 {
        %74 = arith.muli %29, %c-64 : index
        %75 = arith.subi %74, %arg21 : index
        %76 = arith.muli %40, %c-4 : index
        %77 = arith.addi %75, %76 : index
        %78 = arith.addi %77, %0 : index
        %79 = arith.addi %78, %c-1 : index
        %80 = arith.cmpi sge, %79, %c0 : index
        scf.if %80 {
          %81 = memref.load %alloca[%arg21] : memref<4xf32>
          %82 = scf.if %73 -> (f32) {
            %88 = memref.load %arg2[%13] : memref<?xf32>
            %89 = arith.addf %81, %88 : f32
            scf.yield %89 : f32
          } else {
            scf.yield %81 : f32
          }
          %83 = arith.addi %arg21, %69 : index
          %84 = arith.muli %29, %c64 : index
          %85 = arith.addi %83, %84 : index
          %86 = arith.muli %40, %c4 : index
          %87 = arith.addi %85, %86 : index
          memref.store %82, %arg3[%87] : memref<?xf32>
        }
      }
    }
    return
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-error] WrapAndReplaceBarrierPass::runOnOperation(): gpuThreadIdOp.getDimension() != gpu::Dimension::x

