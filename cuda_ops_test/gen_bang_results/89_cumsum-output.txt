warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
warning: we failed to emit call to builtin function __nvvm_ldg_f
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z36__device_stub__aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z21aligned_cumsum_kernelPKfPfii(%arg0, %arg1, %arg2, %arg3) : (memref<?xf32>, memref<?xf32>, i32, i32) -> ()
    return
  }
  func.func private @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1_i32 = arith.constant 1 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32 = arith.constant 0 : i32
    %c-1_i32 = arith.constant -1 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<1xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = arith.divsi %2, %arg3 : i32
    %4 = arith.remsi %2, %arg3 : i32
    %5 = arith.muli %3, %arg2 : i32
    %6 = arith.muli %5, %arg3 : i32
    %7 = arith.index_cast %6 : i32 to index
    %8 = arith.index_cast %4 : i32 to index
    %9 = arith.addi %8, %7 : index
    %10 = arith.muli %3, %arg2 : i32
    %11 = arith.muli %10, %arg3 : i32
    %12 = arith.index_cast %11 : i32 to index
    %13 = arith.index_cast %4 : i32 to index
    %14 = arith.addi %13, %12 : index
    %15 = gpu.thread_id  x
    %16 = arith.index_cast %15 : index to i32
    %17 = arith.cmpi eq, %16, %c0_i32 : i32
    %18 = gpu.block_dim  x
    %19 = arith.index_cast %18 : index to i32
    %20 = arith.addi %arg2, %19 : i32
    %21 = arith.addi %20, %c-1_i32 : i32
    %22 = arith.divsi %21, %19 : i32
    %23 = arith.muli %16, %22 : i32
    %24 = arith.addi %23, %22 : i32
    %25 = call @_ZL3minii(%24, %arg2) : (i32, i32) -> i32
    %26 = arith.index_cast %25 : i32 to index
    %27 = arith.index_cast %23 : i32 to index
    %28 = arith.index_cast %23 : i32 to index
    %29 = affine.for %arg4 = %27 to %26 iter_args(%arg5 = %cst) -> (f32) {
      %36 = arith.subi %arg4, %27 : index
      %37 = arith.addi %28, %36 : index
      %38 = arith.index_cast %37 : index to i32
      %39 = arith.muli %38, %arg3 : i32
      %40 = arith.index_cast %39 : i32 to index
      %41 = arith.addi %40, %9 : index
      %42 = "polygeist.subindex"(%arg0, %41) : (memref<?xf32>, index) -> memref<?xf32>
      %43 = func.call @_Z5__ldgPKf(%42) : (memref<?xf32>) -> f32
      %44 = arith.addf %arg5, %43 : f32
      affine.yield %44 : f32
    }
    affine.store %29, %alloca[symbol(%15)] : memref<1xf32, 5>
    nvvm.barrier0
    %30 = scf.while (%arg4 = %c1_i32) : (i32) -> i32 {
      %36 = arith.cmpi slt, %arg4, %19 : i32
      scf.condition(%36) %arg4 : i32
    } do {
    ^bb0(%arg4: i32):
      %36 = arith.cmpi sge, %16, %arg4 : i32
      %37 = scf.if %36 -> (f32) {
        %41 = arith.subi %16, %arg4 : i32
        %42 = arith.index_cast %41 : i32 to index
        %43 = memref.load %alloca[%42] : memref<1xf32, 5>
        scf.yield %43 : f32
      } else {
        scf.yield %cst : f32
      }
      nvvm.barrier0
      %38 = affine.load %alloca[symbol(%15)] : memref<1xf32, 5>
      %39 = arith.addf %38, %37 : f32
      affine.store %39, %alloca[symbol(%15)] : memref<1xf32, 5>
      nvvm.barrier0
      %40 = arith.muli %arg4, %c2_i32 : i32
      scf.yield %40 : i32
    }
    %31 = scf.if %17 -> (f32) {
      scf.yield %cst : f32
    } else {
      %36 = affine.load %alloca[symbol(%15) - 1] : memref<1xf32, 5>
      scf.yield %36 : f32
    }
    %32 = arith.index_cast %25 : i32 to index
    %33 = arith.index_cast %23 : i32 to index
    %34 = arith.index_cast %23 : i32 to index
    %35 = affine.for %arg4 = %33 to %32 iter_args(%arg5 = %cst) -> (f32) {
      %36 = arith.subi %arg4, %33 : index
      %37 = arith.addi %34, %36 : index
      %38 = arith.index_cast %37 : index to i32
      %39 = arith.muli %38, %arg3 : i32
      %40 = arith.index_cast %39 : i32 to index
      %41 = arith.addi %40, %9 : index
      %42 = "polygeist.subindex"(%arg0, %41) : (memref<?xf32>, index) -> memref<?xf32>
      %43 = func.call @_Z5__ldgPKf(%42) : (memref<?xf32>) -> f32
      %44 = arith.addf %arg5, %43 : f32
      %45 = arith.addf %44, %31 : f32
      affine.store %45, %arg1[(%arg4 + symbol(%34) - symbol(%33)) * symbol(%0) + symbol(%14)] : memref<?xf32>
      affine.yield %44 : f32
    }
    return
  }
  func.func private @_ZL3minii(%arg0: i32, %arg1: i32) -> i32 attributes {llvm.linkage = #llvm.linkage<internal>, polygeist.device_only_func = "1"} {
    %0 = call @__nv_min(%arg0, %arg1) : (i32, i32) -> i32
    return %0 : i32
  }
  func.func private @_Z5__ldgPKf(%arg0: memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<linkonce_odr>, polygeist.device_only_func = "1"} {
    %0 = call @__nvvm_ldg_f(%arg0) : (memref<?xf32>) -> f32
    return %0 : f32
  }
  func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c1_i32 = arith.constant 1 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32 = arith.constant 0 : i32
    %c-1_i32 = arith.constant -1 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<1xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = arith.divsi %2, %arg3 : i32
    %4 = arith.remsi %2, %arg3 : i32
    %5 = arith.muli %3, %arg2 : i32
    %6 = arith.muli %5, %arg3 : i32
    %7 = arith.index_cast %6 : i32 to index
    %8 = arith.index_cast %4 : i32 to index
    %9 = arith.addi %8, %7 : index
    %10 = gpu.thread_id  x
    %11 = arith.index_cast %10 : index to i32
    %12 = arith.cmpi eq, %11, %c0_i32 : i32
    %13 = gpu.block_dim  x
    %14 = arith.index_cast %13 : index to i32
    %15 = arith.addi %arg2, %14 : i32
    %16 = arith.addi %15, %c-1_i32 : i32
    %17 = arith.divsi %16, %14 : i32
    %18 = arith.muli %11, %17 : i32
    %19 = arith.addi %18, %17 : i32
    %20 = call @__nv_min(%19, %arg2) : (i32, i32) -> i32
    %21 = arith.index_cast %20 : i32 to index
    %22 = arith.index_cast %18 : i32 to index
    %23 = affine.for %arg4 = %22 to %21 iter_args(%arg5 = %cst) -> (f32) {
      %27 = arith.index_cast %arg4 : index to i32
      %28 = arith.muli %27, %arg3 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.addi %29, %9 : index
      %31 = "polygeist.subindex"(%arg0, %30) : (memref<?xf32>, index) -> memref<?xf32>
      %32 = func.call @__nvvm_ldg_f(%31) : (memref<?xf32>) -> f32
      %33 = arith.addf %arg5, %32 : f32
      affine.yield %33 : f32
    }
    affine.store %23, %alloca[symbol(%10)] : memref<1xf32, 5>
    nvvm.barrier0
    %24 = scf.while (%arg4 = %c1_i32) : (i32) -> i32 {
      %27 = arith.cmpi slt, %arg4, %14 : i32
      scf.condition(%27) %arg4 : i32
    } do {
    ^bb0(%arg4: i32):
      %27 = arith.cmpi sge, %11, %arg4 : i32
      %28 = scf.if %27 -> (f32) {
        %32 = arith.subi %11, %arg4 : i32
        %33 = arith.index_cast %32 : i32 to index
        %34 = memref.load %alloca[%33] : memref<1xf32, 5>
        scf.yield %34 : f32
      } else {
        scf.yield %cst : f32
      }
      nvvm.barrier0
      %29 = affine.load %alloca[symbol(%10)] : memref<1xf32, 5>
      %30 = arith.addf %29, %28 : f32
      affine.store %30, %alloca[symbol(%10)] : memref<1xf32, 5>
      nvvm.barrier0
      %31 = arith.muli %arg4, %c2_i32 : i32
      scf.yield %31 : i32
    }
    %25 = scf.if %12 -> (f32) {
      scf.yield %cst : f32
    } else {
      %27 = affine.load %alloca[symbol(%10) - 1] : memref<1xf32, 5>
      scf.yield %27 : f32
    }
    %26 = affine.for %arg4 = %22 to %21 iter_args(%arg5 = %cst) -> (f32) {
      %27 = arith.index_cast %arg4 : index to i32
      %28 = arith.muli %27, %arg3 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.addi %29, %9 : index
      %31 = "polygeist.subindex"(%arg0, %30) : (memref<?xf32>, index) -> memref<?xf32>
      %32 = func.call @__nvvm_ldg_f(%31) : (memref<?xf32>) -> f32
      %33 = arith.addf %arg5, %32 : f32
      %34 = arith.addf %33, %25 : f32
      affine.store %34, %arg1[%arg4 * symbol(%0) + symbol(%9)] : memref<?xf32>
      affine.yield %33 : f32
    }
    return
  }
  func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c-1 = arith.constant -1 : index
    %c1 = arith.constant 1 : index
    %c1_i32 = arith.constant 1 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32 = arith.constant 0 : i32
    %c-1_i32 = arith.constant -1 : i32
    %0 = arith.index_cast %arg3 : i32 to index
    %alloca = memref.alloca() : memref<1xf32, 5>
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = arith.divsi %2, %arg3 : i32
    %4 = arith.remsi %2, %arg3 : i32
    %5 = arith.muli %3, %arg2 : i32
    %6 = arith.muli %5, %arg3 : i32
    %7 = arith.index_cast %6 : i32 to index
    %8 = arith.index_cast %4 : i32 to index
    %9 = arith.addi %8, %7 : index
    %10 = gpu.thread_id  x
    %11 = arith.index_cast %10 : index to i32
    %12 = arith.cmpi eq, %11, %c0_i32 : i32
    %13 = gpu.block_dim  x
    %14 = arith.index_cast %13 : index to i32
    %15 = arith.addi %arg2, %14 : i32
    %16 = arith.addi %15, %c-1_i32 : i32
    %17 = arith.divsi %16, %14 : i32
    %18 = arith.muli %11, %17 : i32
    %19 = arith.addi %18, %17 : i32
    %20 = call @__nv_min(%19, %arg2) : (i32, i32) -> i32
    %21 = arith.index_cast %20 : i32 to index
    %22 = arith.index_cast %18 : i32 to index
    %23 = scf.for %arg4 = %22 to %21 step %c1 iter_args(%arg5 = %cst) -> (f32) {
      %27 = arith.index_cast %arg4 : index to i32
      %28 = arith.muli %27, %arg3 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.addi %29, %9 : index
      %31 = "polygeist.subindex"(%arg0, %30) : (memref<?xf32>, index) -> memref<?xf32>
      %32 = func.call @__nvvm_ldg_f(%31) : (memref<?xf32>) -> f32
      %33 = arith.addf %arg5, %32 : f32
      scf.yield %33 : f32
    }
    memref.store %23, %alloca[%10] : memref<1xf32, 5>
    nvvm.barrier0
    %24 = scf.while (%arg4 = %c1_i32) : (i32) -> i32 {
      %27 = arith.cmpi slt, %arg4, %14 : i32
      scf.condition(%27) %arg4 : i32
    } do {
    ^bb0(%arg4: i32):
      %27 = arith.cmpi sge, %11, %arg4 : i32
      %28 = scf.if %27 -> (f32) {
        %32 = arith.subi %11, %arg4 : i32
        %33 = arith.index_cast %32 : i32 to index
        %34 = memref.load %alloca[%33] : memref<1xf32, 5>
        scf.yield %34 : f32
      } else {
        scf.yield %cst : f32
      }
      nvvm.barrier0
      %29 = memref.load %alloca[%10] : memref<1xf32, 5>
      %30 = arith.addf %29, %28 : f32
      memref.store %30, %alloca[%10] : memref<1xf32, 5>
      nvvm.barrier0
      %31 = arith.muli %arg4, %c2_i32 : i32
      scf.yield %31 : i32
    }
    %25 = scf.if %12 -> (f32) {
      scf.yield %cst : f32
    } else {
      %27 = arith.addi %10, %c-1 : index
      %28 = memref.load %alloca[%27] : memref<1xf32, 5>
      scf.yield %28 : f32
    }
    %26 = scf.for %arg4 = %22 to %21 step %c1 iter_args(%arg5 = %cst) -> (f32) {
      %27 = arith.index_cast %arg4 : index to i32
      %28 = arith.muli %27, %arg3 : i32
      %29 = arith.index_cast %28 : i32 to index
      %30 = arith.addi %29, %9 : index
      %31 = "polygeist.subindex"(%arg0, %30) : (memref<?xf32>, index) -> memref<?xf32>
      %32 = func.call @__nvvm_ldg_f(%31) : (memref<?xf32>) -> f32
      %33 = arith.addf %arg5, %32 : f32
      %34 = arith.addf %33, %25 : f32
      %35 = arith.muli %arg4, %0 : index
      %36 = arith.addi %35, %9 : index
      memref.store %34, %arg1[%36] : memref<?xf32>
      scf.yield %33 : f32
    }
    return
  }
  func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-debug] WrapAndReplaceBarrierPass::runOnOperation(): Function name: __nv_min. func.getBlocks().size() == 0! this function is empty, skip it.

[ict-debug] WrapAndReplaceBarrierPass::runOnOperation(): Function name: __nvvm_ldg_f. func.getBlocks().size() == 0! this function is empty, skip it.

WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %c-1 = arith.constant -1 : index
      %c1_0 = arith.constant 1 : index
      %c1_i32 = arith.constant 1 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c2_i32 = arith.constant 2 : i32
      %c0_i32 = arith.constant 0 : i32
      %c-1_i32 = arith.constant -1 : i32
      %0 = arith.index_cast %arg3 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = arith.divsi %2, %arg3 : i32
      %4 = arith.remsi %2, %arg3 : i32
      %5 = arith.muli %3, %arg2 : i32
      %6 = arith.muli %5, %arg3 : i32
      %7 = arith.index_cast %6 : i32 to index
      %8 = arith.index_cast %4 : i32 to index
      %9 = arith.addi %8, %7 : index
      %10 = arith.index_cast %arg4 : index to i32
      %11 = arith.cmpi eq, %10, %c0_i32 : i32
      %12 = gpu.block_dim  x
      %13 = arith.index_cast %12 : index to i32
      %14 = arith.addi %arg2, %13 : i32
      %15 = arith.addi %14, %c-1_i32 : i32
      %16 = arith.divsi %15, %13 : i32
      %17 = arith.muli %10, %16 : i32
      %18 = arith.addi %17, %16 : i32
      %19 = func.call @__nv_min(%18, %arg2) : (i32, i32) -> i32
      %20 = arith.index_cast %19 : i32 to index
      %21 = arith.index_cast %17 : i32 to index
      %22 = scf.for %arg5 = %21 to %20 step %c1_0 iter_args(%arg6 = %cst) -> (f32) {
        %26 = arith.index_cast %arg5 : index to i32
        %27 = arith.muli %26, %arg3 : i32
        %28 = arith.index_cast %27 : i32 to index
        %29 = arith.addi %28, %9 : index
        %30 = "polygeist.subindex"(%arg0, %29) : (memref<?xf32>, index) -> memref<?xf32>
        %31 = func.call @__nvvm_ldg_f(%30) : (memref<?xf32>) -> f32
        %32 = arith.addf %arg6, %31 : f32
        scf.yield %32 : f32
      }
      memref.store %22, %alloca[%arg4] : memref<1xf32, 5>
      "polygeist.barrier"(%arg4) : (index) -> ()
      %23 = scf.while (%arg5 = %c1_i32) : (i32) -> i32 {
        %26 = arith.cmpi slt, %arg5, %13 : i32
        scf.condition(%26) %arg5 : i32
      } do {
      ^bb0(%arg5: i32):
        %26 = arith.cmpi sge, %10, %arg5 : i32
        %27 = scf.if %26 -> (f32) {
          %31 = arith.subi %10, %arg5 : i32
          %32 = arith.index_cast %31 : i32 to index
          %33 = memref.load %alloca[%32] : memref<1xf32, 5>
          scf.yield %33 : f32
        } else {
          scf.yield %cst : f32
        }
        "polygeist.barrier"(%arg4) : (index) -> ()
        %28 = memref.load %alloca[%arg4] : memref<1xf32, 5>
        %29 = arith.addf %28, %27 : f32
        memref.store %29, %alloca[%arg4] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        %30 = arith.muli %arg5, %c2_i32 : i32
        scf.yield %30 : i32
      }
      %24 = scf.if %11 -> (f32) {
        scf.yield %cst : f32
      } else {
        %26 = arith.addi %arg4, %c-1 : index
        %27 = memref.load %alloca[%26] : memref<1xf32, 5>
        scf.yield %27 : f32
      }
      %25 = scf.for %arg5 = %21 to %20 step %c1_0 iter_args(%arg6 = %cst) -> (f32) {
        %26 = arith.index_cast %arg5 : index to i32
        %27 = arith.muli %26, %arg3 : i32
        %28 = arith.index_cast %27 : i32 to index
        %29 = arith.addi %28, %9 : index
        %30 = "polygeist.subindex"(%arg0, %29) : (memref<?xf32>, index) -> memref<?xf32>
        %31 = func.call @__nvvm_ldg_f(%30) : (memref<?xf32>) -> f32
        %32 = arith.addf %arg6, %31 : f32
        %33 = arith.addf %32, %24 : f32
        %34 = arith.muli %arg5, %0 : index
        %35 = arith.addi %34, %9 : index
        memref.store %33, %arg1[%35] : memref<?xf32>
        scf.yield %32 : f32
      }
      scf.yield
    }
    return
  }
  func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %c-1 = arith.constant -1 : index
      %c1_0 = arith.constant 1 : index
      %c1_i32 = arith.constant 1 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c2_i32 = arith.constant 2 : i32
      %c0_i32 = arith.constant 0 : i32
      %c-1_i32 = arith.constant -1 : i32
      %0 = arith.index_cast %arg3 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = arith.divsi %2, %arg3 : i32
      %4 = arith.remsi %2, %arg3 : i32
      %5 = arith.muli %3, %arg2 : i32
      %6 = arith.muli %5, %arg3 : i32
      %7 = arith.index_cast %6 : i32 to index
      %8 = arith.index_cast %4 : i32 to index
      %9 = arith.addi %8, %7 : index
      %10 = arith.index_cast %arg4 : index to i32
      %11 = arith.cmpi eq, %10, %c0_i32 : i32
      %12 = gpu.block_dim  x
      %13 = arith.index_cast %12 : index to i32
      %14 = arith.addi %arg2, %13 : i32
      %15 = arith.addi %14, %c-1_i32 : i32
      %16 = arith.divsi %15, %13 : i32
      %17 = arith.muli %10, %16 : i32
      %18 = arith.addi %17, %16 : i32
      %19 = func.call @__nv_min(%18, %arg2) : (i32, i32) -> i32
      %20 = arith.index_cast %19 : i32 to index
      %21 = arith.index_cast %17 : i32 to index
      %22 = scf.for %arg5 = %21 to %20 step %c1_0 iter_args(%arg6 = %cst) -> (f32) {
        %26 = arith.index_cast %arg5 : index to i32
        %27 = arith.muli %26, %arg3 : i32
        %28 = arith.index_cast %27 : i32 to index
        %29 = arith.addi %28, %9 : index
        %30 = "polygeist.subindex"(%arg0, %29) : (memref<?xf32>, index) -> memref<?xf32>
        %31 = func.call @__nvvm_ldg_f(%30) : (memref<?xf32>) -> f32
        %32 = arith.addf %arg6, %31 : f32
        scf.yield %32 : f32
      }
      memref.store %22, %alloca[%arg4] : memref<1xf32, 5>
      "polygeist.barrier"(%arg4) : (index) -> ()
      %23 = scf.while (%arg5 = %c1_i32) : (i32) -> i32 {
        %26 = arith.cmpi slt, %arg5, %13 : i32
        scf.condition(%26) %arg5 : i32
      } do {
      ^bb0(%arg5: i32):
        %26 = arith.cmpi sge, %10, %arg5 : i32
        %27 = scf.if %26 -> (f32) {
          %31 = arith.subi %10, %arg5 : i32
          %32 = arith.index_cast %31 : i32 to index
          %33 = memref.load %alloca[%32] : memref<1xf32, 5>
          scf.yield %33 : f32
        } else {
          scf.yield %cst : f32
        }
        "polygeist.barrier"(%arg4) : (index) -> ()
        %28 = memref.load %alloca[%arg4] : memref<1xf32, 5>
        %29 = arith.addf %28, %27 : f32
        memref.store %29, %alloca[%arg4] : memref<1xf32, 5>
        "polygeist.barrier"(%arg4) : (index) -> ()
        %30 = arith.muli %arg5, %c2_i32 : i32
        scf.yield %30 : i32
      }
      %24 = scf.if %11 -> (f32) {
        scf.yield %cst : f32
      } else {
        %26 = arith.addi %arg4, %c-1 : index
        %27 = memref.load %alloca[%26] : memref<1xf32, 5>
        scf.yield %27 : f32
      }
      %25 = scf.for %arg5 = %21 to %20 step %c1_0 iter_args(%arg6 = %cst) -> (f32) {
        %26 = arith.index_cast %arg5 : index to i32
        %27 = arith.muli %26, %arg3 : i32
        %28 = arith.index_cast %27 : i32 to index
        %29 = arith.addi %28, %9 : index
        %30 = "polygeist.subindex"(%arg0, %29) : (memref<?xf32>, index) -> memref<?xf32>
        %31 = func.call @__nvvm_ldg_f(%30) : (memref<?xf32>) -> f32
        %32 = arith.addf %arg6, %31 : f32
        %33 = arith.addf %32, %24 : f32
        %34 = arith.muli %arg5, %0 : index
        %35 = arith.addi %34, %9 : index
        memref.store %33, %arg1[%35] : memref<?xf32>
        scf.yield %32 : f32
      }
      scf.yield
    }
    return
  }
  func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c-1_i32 = arith.constant -1 : i32
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c1_i32 = arith.constant 1 : i32
    %c-1 = arith.constant -1 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %alloca = memref.alloca() : memref<1xf32, 5>
    %alloca_0 = memref.alloca() : memref<32xi32>
    %alloca_1 = memref.alloca() : memref<32xi32>
    %alloca_2 = memref.alloca() : memref<32xi32>
    %alloca_3 = memref.alloca() : memref<32xf32>
    %alloca_4 = memref.alloca() : memref<i1>
    %0 = gpu.block_id  x
    %1 = arith.index_cast %0 : index to i32
    %2 = arith.remsi %1, %arg3 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4 = gpu.block_dim  x
    %5 = arith.index_cast %4 : index to i32
    %6 = arith.addi %arg2, %5 : i32
    %7 = arith.addi %6, %c-1_i32 : i32
    %8 = arith.divsi %1, %arg3 : i32
    %9 = arith.muli %8, %arg2 : i32
    %10 = arith.muli %9, %arg3 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12 = arith.addi %3, %11 : index
    %13 = arith.divsi %7, %5 : i32
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %31 = arith.index_cast %arg4 : index to i32
      %32 = arith.muli %31, %13 : i32
      %33 = arith.addi %32, %13 : i32
      %34 = func.call @__nv_min(%33, %arg2) : (i32, i32) -> i32
      memref.store %34, %alloca_0[%arg4] : memref<32xi32>
      %35 = arith.index_cast %34 : i32 to index
      %36 = arith.index_cast %32 : i32 to index
      %37 = scf.for %arg5 = %36 to %35 step %c1 iter_args(%arg6 = %cst) -> (f32) {
        %38 = arith.index_cast %arg5 : index to i32
        %39 = arith.muli %38, %arg3 : i32
        %40 = arith.index_cast %39 : i32 to index
        %41 = arith.addi %40, %12 : index
        %42 = "polygeist.subindex"(%arg0, %41) : (memref<?xf32>, index) -> memref<?xf32>
        %43 = func.call @__nvvm_ldg_f(%42) : (memref<?xf32>) -> f32
        %44 = arith.addf %arg6, %43 : f32
        scf.yield %44 : f32
      }
      memref.store %37, %alloca[%arg4] : memref<1xf32, 5>
      scf.yield
    }
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32>
      scf.yield
    }
    %14 = gpu.block_dim  x
    %15 = arith.index_cast %14 : index to i32
    scf.while : () -> () {
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %32 = memref.load %alloca_1[%arg4] : memref<32xi32>
        %33 = arith.cmpi slt, %32, %15 : i32
        %34 = arith.cmpi eq, %arg4, %c0 : index
        scf.if %34 {
          memref.store %33, %alloca_4[] : memref<i1>
        }
        memref.store %32, %alloca_2[%arg4] : memref<32xi32>
        scf.yield
      }
      %31 = memref.load %alloca_4[] : memref<i1>
      scf.condition(%31)
    } do {
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %31 = arith.index_cast %arg4 : index to i32
        %32 = memref.load %alloca_2[%arg4] : memref<32xi32>
        %33 = arith.cmpi sge, %31, %32 : i32
        %34 = scf.if %33 -> (f32) {
          %35 = arith.subi %31, %32 : i32
          %36 = arith.index_cast %35 : i32 to index
          %37 = memref.load %alloca[%36] : memref<1xf32, 5>
          scf.yield %37 : f32
        } else {
          scf.yield %cst : f32
        }
        memref.store %34, %alloca_3[%arg4] : memref<32xf32>
        scf.yield
      }
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %31 = memref.load %alloca_3[%arg4] : memref<32xf32>
        %32 = memref.load %alloca_2[%arg4] : memref<32xi32>
        %33 = memref.load %alloca[%arg4] : memref<1xf32, 5>
        %34 = arith.addf %33, %31 : f32
        memref.store %34, %alloca[%arg4] : memref<1xf32, 5>
        %35 = arith.muli %32, %c2_i32 : i32
        memref.store %35, %alloca_1[%arg4] : memref<32xi32>
        scf.yield
      }
      scf.yield
    }
    %16 = arith.index_cast %arg3 : i32 to index
    %17 = gpu.block_id  x
    %18 = arith.index_cast %17 : index to i32
    %19 = arith.remsi %18, %arg3 : i32
    %20 = arith.index_cast %19 : i32 to index
    %21 = gpu.block_dim  x
    %22 = arith.index_cast %21 : index to i32
    %23 = arith.addi %arg2, %22 : i32
    %24 = arith.addi %23, %c-1_i32 : i32
    %25 = arith.divsi %18, %arg3 : i32
    %26 = arith.muli %25, %arg2 : i32
    %27 = arith.muli %26, %arg3 : i32
    %28 = arith.index_cast %27 : i32 to index
    %29 = arith.addi %20, %28 : index
    %30 = arith.divsi %24, %22 : i32
    scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
      %31 = arith.index_cast %arg4 : index to i32
      %32 = arith.cmpi eq, %31, %c0_i32 : i32
      %33 = memref.load %alloca_0[%arg4] : memref<32xi32>
      %34 = arith.index_cast %33 : i32 to index
      %35 = arith.muli %31, %30 : i32
      %36 = arith.index_cast %35 : i32 to index
      %37 = scf.if %32 -> (f32) {
        scf.yield %cst : f32
      } else {
        %39 = arith.addi %arg4, %c-1 : index
        %40 = memref.load %alloca[%39] : memref<1xf32, 5>
        scf.yield %40 : f32
      }
      %38 = scf.for %arg5 = %36 to %34 step %c1 iter_args(%arg6 = %cst) -> (f32) {
        %39 = arith.index_cast %arg5 : index to i32
        %40 = arith.muli %39, %arg3 : i32
        %41 = arith.index_cast %40 : i32 to index
        %42 = arith.addi %41, %29 : index
        %43 = "polygeist.subindex"(%arg0, %42) : (memref<?xf32>, index) -> memref<?xf32>
        %44 = func.call @__nvvm_ldg_f(%43) : (memref<?xf32>) -> f32
        %45 = arith.addf %arg6, %44 : f32
        %46 = arith.addf %45, %37 : f32
        %47 = arith.muli %arg5, %16 : index
        %48 = arith.addi %47, %29 : index
        memref.store %46, %arg1[%48] : memref<?xf32>
        scf.yield %45 : f32
      }
      scf.yield
    }
    return
  }
  func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] WrapAndReplaceBarrierPass::runOnOperation(): Function name: __nv_min. func.getBlocks().size() == 0! this function is empty, skip it.

[ict-debug] WrapAndReplaceBarrierPass::runOnOperation(): Function name: __nvvm_ldg_f. func.getBlocks().size() == 0! this function is empty, skip it.

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<1xf32, 5>
      %alloca_0 = memref.alloca() : memref<32xi32>
      %alloca_1 = memref.alloca() : memref<32xi32>
      %alloca_2 = memref.alloca() : memref<32xi32>
      %alloca_3 = memref.alloca() : memref<32xf32>
      %alloca_4 = memref.alloca() : memref<i1>
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.remsi %1, %arg3 : i32
      %3 = arith.index_cast %2 : i32 to index
      %4 = gpu.block_dim  x
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.addi %arg2, %5 : i32
      %7 = arith.addi %6, %c-1_i32 : i32
      %8 = arith.divsi %1, %arg3 : i32
      %9 = arith.muli %8, %arg2 : i32
      %10 = arith.muli %9, %arg3 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.addi %3, %11 : index
      %13 = arith.divsi %7, %5 : i32
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %15 = arith.index_cast %arg4 : index to i32
        %16 = arith.muli %15, %13 : i32
        %17 = arith.addi %16, %13 : i32
        %18 = func.call @__nv_min(%17, %arg2) : (i32, i32) -> i32
        memref.store %18, %alloca_0[%arg4] : memref<32xi32>
        %19 = arith.index_cast %18 : i32 to index
        %20 = arith.index_cast %16 : i32 to index
        %21 = scf.for %arg5 = %20 to %19 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %22 = arith.index_cast %arg5 : index to i32
          %23 = arith.muli %22, %arg3 : i32
          %24 = arith.index_cast %23 : i32 to index
          %25 = arith.addi %24, %12 : index
          %26 = "polygeist.subindex"(%arg0, %25) : (memref<?xf32>, index) -> memref<?xf32>
          %27 = func.call @__nvvm_ldg_f(%26) : (memref<?xf32>) -> f32
          %28 = arith.addf %arg6, %27 : f32
          scf.yield %28 : f32
        }
        memref.store %21, %alloca[%arg4] : memref<1xf32, 5>
        scf.yield
      }
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32>
        scf.yield
      }
      scf.while : () -> () {
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          %16 = memref.load %alloca_1[%arg4] : memref<32xi32>
          %17 = arith.cmpi slt, %16, %5 : i32
          %18 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %18 {
            memref.store %17, %alloca_4[] : memref<i1>
          }
          memref.store %16, %alloca_2[%arg4] : memref<32xi32>
          scf.yield
        }
        %15 = memref.load %alloca_4[] : memref<i1>
        scf.condition(%15)
      } do {
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          %15 = arith.index_cast %arg4 : index to i32
          %16 = memref.load %alloca_2[%arg4] : memref<32xi32>
          %17 = arith.cmpi sge, %15, %16 : i32
          %18 = scf.if %17 -> (f32) {
            %19 = arith.subi %15, %16 : i32
            %20 = arith.index_cast %19 : i32 to index
            %21 = memref.load %alloca[%20] : memref<1xf32, 5>
            scf.yield %21 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %18, %alloca_3[%arg4] : memref<32xf32>
          scf.yield
        }
        scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
          %15 = memref.load %alloca_3[%arg4] : memref<32xf32>
          %16 = memref.load %alloca_2[%arg4] : memref<32xi32>
          %17 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %18 = arith.addf %17, %15 : f32
          memref.store %18, %alloca[%arg4] : memref<1xf32, 5>
          %19 = arith.muli %16, %c2_i32 : i32
          memref.store %19, %alloca_1[%arg4] : memref<32xi32>
          scf.yield
        }
        scf.yield
      }
      %14 = arith.index_cast %arg3 : i32 to index
      scf.parallel (%arg4) = (%c0) to (%c32) step (%c1) {
        %15 = arith.index_cast %arg4 : index to i32
        %16 = arith.cmpi eq, %15, %c0_i32 : i32
        %17 = memref.load %alloca_0[%arg4] : memref<32xi32>
        %18 = arith.index_cast %17 : i32 to index
        %19 = arith.muli %15, %13 : i32
        %20 = arith.index_cast %19 : i32 to index
        %21 = scf.if %16 -> (f32) {
          scf.yield %cst : f32
        } else {
          %23 = arith.addi %arg4, %c-1 : index
          %24 = memref.load %alloca[%23] : memref<1xf32, 5>
          scf.yield %24 : f32
        }
        %22 = scf.for %arg5 = %20 to %18 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %23 = arith.index_cast %arg5 : index to i32
          %24 = arith.muli %23, %arg3 : i32
          %25 = arith.index_cast %24 : i32 to index
          %26 = arith.addi %25, %12 : index
          %27 = "polygeist.subindex"(%arg0, %26) : (memref<?xf32>, index) -> memref<?xf32>
          %28 = func.call @__nvvm_ldg_f(%27) : (memref<?xf32>) -> f32
          %29 = arith.addf %arg6, %28 : f32
          %30 = arith.addf %29, %21 : f32
          %31 = arith.muli %arg5, %14 : index
          %32 = arith.addi %31, %12 : index
          memref.store %30, %arg1[%32] : memref<?xf32>
          scf.yield %29 : f32
        }
        scf.yield
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %alloca = memref.alloca() : memref<1xf32, 5>
      %alloca_0 = memref.alloca() : memref<32xi32>
      %alloca_1 = memref.alloca() : memref<32xi32>
      %alloca_2 = memref.alloca() : memref<32xi32>
      %alloca_3 = memref.alloca() : memref<32xf32>
      %alloca_4 = memref.alloca() : memref<i1>
      %0 = gpu.block_id  x
      %1 = arith.index_cast %0 : index to i32
      %2 = arith.remsi %1, %arg3 : i32
      %3 = arith.index_cast %2 : i32 to index
      %c32_5 = arith.constant 32 : index
      %4 = arith.index_cast %c32_5 : index to i32
      %5 = arith.addi %arg2, %4 : i32
      %6 = arith.addi %5, %c-1_i32 : i32
      %7 = arith.divsi %1, %arg3 : i32
      %8 = arith.muli %7, %arg2 : i32
      %9 = arith.muli %8, %arg3 : i32
      %10 = arith.index_cast %9 : i32 to index
      %11 = arith.addi %3, %10 : index
      %12 = arith.divsi %6, %4 : i32
      %c1_6 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_6 {
        %14 = arith.index_cast %arg4 : index to i32
        %15 = arith.muli %14, %12 : i32
        %16 = arith.addi %15, %12 : i32
        %17 = func.call @__nv_min(%16, %arg2) : (i32, i32) -> i32
        memref.store %17, %alloca_0[%arg4] : memref<32xi32>
        %18 = arith.index_cast %17 : i32 to index
        %19 = arith.index_cast %15 : i32 to index
        %20 = scf.for %arg5 = %19 to %18 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %21 = arith.index_cast %arg5 : index to i32
          %22 = arith.muli %21, %arg3 : i32
          %23 = arith.index_cast %22 : i32 to index
          %24 = arith.addi %23, %11 : index
          %25 = "polygeist.subindex"(%arg0, %24) : (memref<?xf32>, index) -> memref<?xf32>
          %26 = func.call @__nvvm_ldg_f(%25) : (memref<?xf32>) -> f32
          %27 = arith.addf %arg6, %26 : f32
          scf.yield %27 : f32
        }
        memref.store %20, %alloca[%arg4] : memref<1xf32, 5>
      }
      %c1_7 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_7 {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32>
      }
      scf.while : () -> () {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %15 = memref.load %alloca_1[%arg4] : memref<32xi32>
          %16 = arith.cmpi slt, %15, %4 : i32
          %17 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %17 {
            memref.store %16, %alloca_4[] : memref<i1>
          }
          memref.store %15, %alloca_2[%arg4] : memref<32xi32>
        }
        %14 = memref.load %alloca_4[] : memref<i1>
        scf.condition(%14)
      } do {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %14 = arith.index_cast %arg4 : index to i32
          %15 = memref.load %alloca_2[%arg4] : memref<32xi32>
          %16 = arith.cmpi sge, %14, %15 : i32
          %17 = scf.if %16 -> (f32) {
            %18 = arith.subi %14, %15 : i32
            %19 = arith.index_cast %18 : i32 to index
            %20 = memref.load %alloca[%19] : memref<1xf32, 5>
            scf.yield %20 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %17, %alloca_3[%arg4] : memref<32xf32>
        }
        %c1_10 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_10 {
          %14 = memref.load %alloca_3[%arg4] : memref<32xf32>
          %15 = memref.load %alloca_2[%arg4] : memref<32xi32>
          %16 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %17 = arith.addf %16, %14 : f32
          memref.store %17, %alloca[%arg4] : memref<1xf32, 5>
          %18 = arith.muli %15, %c2_i32 : i32
          memref.store %18, %alloca_1[%arg4] : memref<32xi32>
        }
        scf.yield
      }
      %13 = arith.index_cast %arg3 : i32 to index
      %c1_8 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_8 {
        %14 = arith.index_cast %arg4 : index to i32
        %15 = arith.cmpi eq, %14, %c0_i32 : i32
        %16 = memref.load %alloca_0[%arg4] : memref<32xi32>
        %17 = arith.index_cast %16 : i32 to index
        %18 = arith.muli %14, %12 : i32
        %19 = arith.index_cast %18 : i32 to index
        %20 = scf.if %15 -> (f32) {
          scf.yield %cst : f32
        } else {
          %22 = arith.addi %arg4, %c-1 : index
          %23 = memref.load %alloca[%22] : memref<1xf32, 5>
          scf.yield %23 : f32
        }
        %21 = scf.for %arg5 = %19 to %17 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %22 = arith.index_cast %arg5 : index to i32
          %23 = arith.muli %22, %arg3 : i32
          %24 = arith.index_cast %23 : i32 to index
          %25 = arith.addi %24, %11 : index
          %26 = "polygeist.subindex"(%arg0, %25) : (memref<?xf32>, index) -> memref<?xf32>
          %27 = func.call @__nvvm_ldg_f(%26) : (memref<?xf32>) -> f32
          %28 = arith.addf %arg6, %27 : f32
          %29 = arith.addf %28, %20 : f32
          %30 = arith.muli %arg5, %13 : index
          %31 = arith.addi %30, %11 : index
          memref.store %29, %arg1[%31] : memref<?xf32>
          scf.yield %28 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca = memref.alloca() : memref<1xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca = memref.alloca() : memref<1xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %alloca_0 = memref.alloca() : memref<32xi32, 5>
      %alloca_1 = memref.alloca() : memref<32xi32, 5>
      %alloca_2 = memref.alloca() : memref<32xi32, 5>
      %alloca_3 = memref.alloca() : memref<32xf32, 5>
      %alloca_4 = memref.alloca() : memref<i1, 5>
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = arith.remsi %2, %arg3 : i32
      %4 = arith.index_cast %3 : i32 to index
      %c32_5 = arith.constant 32 : index
      %5 = arith.index_cast %c32_5 : index to i32
      %6 = arith.addi %arg2, %5 : i32
      %7 = arith.addi %6, %c-1_i32 : i32
      %8 = arith.divsi %2, %arg3 : i32
      %9 = arith.muli %8, %arg2 : i32
      %10 = arith.muli %9, %arg3 : i32
      %11 = arith.index_cast %10 : i32 to index
      %12 = arith.addi %4, %11 : index
      %13 = arith.divsi %7, %5 : i32
      %c1_6 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_6 {
        %15 = arith.index_cast %arg4 : index to i32
        %16 = arith.muli %15, %13 : i32
        %17 = arith.addi %16, %13 : i32
        %18 = func.call @__nv_min(%17, %arg2) : (i32, i32) -> i32
        memref.store %18, %alloca_0[%arg4] : memref<32xi32, 5>
        %19 = arith.index_cast %18 : i32 to index
        %20 = arith.index_cast %16 : i32 to index
        %21 = scf.for %arg5 = %20 to %19 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %22 = arith.index_cast %arg5 : index to i32
          %23 = arith.muli %22, %arg3 : i32
          %24 = arith.index_cast %23 : i32 to index
          %25 = arith.addi %24, %12 : index
          %26 = "polygeist.subindex"(%arg0, %25) : (memref<?xf32>, index) -> memref<?xf32>
          %27 = func.call @__nvvm_ldg_f(%26) : (memref<?xf32>) -> f32
          %28 = arith.addf %arg6, %27 : f32
          scf.yield %28 : f32
        }
        memref.store %21, %alloca[%arg4] : memref<1xf32, 5>
      }
      %c1_7 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_7 {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %16 = memref.load %alloca_1[%arg4] : memref<32xi32, 5>
          %17 = arith.cmpi slt, %16, %5 : i32
          %18 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %18 {
            memref.store %17, %alloca_4[] : memref<i1, 5>
          }
          memref.store %16, %alloca_2[%arg4] : memref<32xi32, 5>
        }
        %15 = memref.load %alloca_4[] : memref<i1, 5>
        scf.condition(%15)
      } do {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %15 = arith.index_cast %arg4 : index to i32
          %16 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %17 = arith.cmpi sge, %15, %16 : i32
          %18 = scf.if %17 -> (f32) {
            %19 = arith.subi %15, %16 : i32
            %20 = arith.index_cast %19 : i32 to index
            %21 = memref.load %alloca[%20] : memref<1xf32, 5>
            scf.yield %21 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %18, %alloca_3[%arg4] : memref<32xf32, 5>
        }
        %c1_10 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_10 {
          %15 = memref.load %alloca_3[%arg4] : memref<32xf32, 5>
          %16 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %17 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %18 = arith.addf %17, %15 : f32
          memref.store %18, %alloca[%arg4] : memref<1xf32, 5>
          %19 = arith.muli %16, %c2_i32 : i32
          memref.store %19, %alloca_1[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %14 = arith.index_cast %arg3 : i32 to index
      %c1_8 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_8 {
        %15 = arith.index_cast %arg4 : index to i32
        %16 = arith.cmpi eq, %15, %c0_i32 : i32
        %17 = memref.load %alloca_0[%arg4] : memref<32xi32, 5>
        %18 = arith.index_cast %17 : i32 to index
        %19 = arith.muli %15, %13 : i32
        %20 = arith.index_cast %19 : i32 to index
        %21 = scf.if %16 -> (f32) {
          scf.yield %cst : f32
        } else {
          %23 = arith.addi %arg4, %c-1 : index
          %24 = memref.load %alloca[%23] : memref<1xf32, 5>
          scf.yield %24 : f32
        }
        %22 = scf.for %arg5 = %20 to %18 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %23 = arith.index_cast %arg5 : index to i32
          %24 = arith.muli %23, %arg3 : i32
          %25 = arith.index_cast %24 : i32 to index
          %26 = arith.addi %25, %12 : index
          %27 = "polygeist.subindex"(%arg0, %26) : (memref<?xf32>, index) -> memref<?xf32>
          %28 = func.call @__nvvm_ldg_f(%27) : (memref<?xf32>) -> f32
          %29 = arith.addf %arg6, %28 : f32
          %30 = arith.addf %29, %21 : f32
          %31 = arith.muli %arg5, %14 : index
          %32 = arith.addi %31, %12 : index
          memref.store %30, %arg1[%32] : memref<?xf32>
          scf.yield %29 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_0 = memref.alloca() : memref<32xi32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_0 = memref.alloca() : memref<32xi32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<32xi32, 5>
      %alloca_1 = memref.alloca() : memref<32xi32, 5>
      %alloca_2 = memref.alloca() : memref<32xi32, 5>
      %alloca_3 = memref.alloca() : memref<32xf32, 5>
      %alloca_4 = memref.alloca() : memref<i1, 5>
      %2 = gpu.block_id  x
      %3 = arith.index_cast %2 : index to i32
      %4 = arith.remsi %3, %arg3 : i32
      %5 = arith.index_cast %4 : i32 to index
      %c32_5 = arith.constant 32 : index
      %6 = arith.index_cast %c32_5 : index to i32
      %7 = arith.addi %arg2, %6 : i32
      %8 = arith.addi %7, %c-1_i32 : i32
      %9 = arith.divsi %3, %arg3 : i32
      %10 = arith.muli %9, %arg2 : i32
      %11 = arith.muli %10, %arg3 : i32
      %12 = arith.index_cast %11 : i32 to index
      %13 = arith.addi %5, %12 : index
      %14 = arith.divsi %8, %6 : i32
      %c1_6 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_6 {
        %16 = arith.index_cast %arg4 : index to i32
        %17 = arith.muli %16, %14 : i32
        %18 = arith.addi %17, %14 : i32
        %19 = func.call @__nv_min(%18, %arg2) : (i32, i32) -> i32
        memref.store %19, %alloca_0[%arg4] : memref<32xi32, 5>
        %20 = arith.index_cast %19 : i32 to index
        %21 = arith.index_cast %17 : i32 to index
        %22 = scf.for %arg5 = %21 to %20 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %23 = arith.index_cast %arg5 : index to i32
          %24 = arith.muli %23, %arg3 : i32
          %25 = arith.index_cast %24 : i32 to index
          %26 = arith.addi %25, %13 : index
          %27 = "polygeist.subindex"(%arg0, %26) : (memref<?xf32>, index) -> memref<?xf32>
          %28 = func.call @__nvvm_ldg_f(%27) : (memref<?xf32>) -> f32
          %29 = arith.addf %arg6, %28 : f32
          scf.yield %29 : f32
        }
        memref.store %22, %alloca[%arg4] : memref<1xf32, 5>
      }
      %c1_7 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_7 {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %17 = memref.load %alloca_1[%arg4] : memref<32xi32, 5>
          %18 = arith.cmpi slt, %17, %6 : i32
          %19 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %19 {
            memref.store %18, %alloca_4[] : memref<i1, 5>
          }
          memref.store %17, %alloca_2[%arg4] : memref<32xi32, 5>
        }
        %16 = memref.load %alloca_4[] : memref<i1, 5>
        scf.condition(%16)
      } do {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %16 = arith.index_cast %arg4 : index to i32
          %17 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %18 = arith.cmpi sge, %16, %17 : i32
          %19 = scf.if %18 -> (f32) {
            %20 = arith.subi %16, %17 : i32
            %21 = arith.index_cast %20 : i32 to index
            %22 = memref.load %alloca[%21] : memref<1xf32, 5>
            scf.yield %22 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %19, %alloca_3[%arg4] : memref<32xf32, 5>
        }
        %c1_10 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_10 {
          %16 = memref.load %alloca_3[%arg4] : memref<32xf32, 5>
          %17 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %18 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %19 = arith.addf %18, %16 : f32
          memref.store %19, %alloca[%arg4] : memref<1xf32, 5>
          %20 = arith.muli %17, %c2_i32 : i32
          memref.store %20, %alloca_1[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %15 = arith.index_cast %arg3 : i32 to index
      %c1_8 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_8 {
        %16 = arith.index_cast %arg4 : index to i32
        %17 = arith.cmpi eq, %16, %c0_i32 : i32
        %18 = memref.load %alloca_0[%arg4] : memref<32xi32, 5>
        %19 = arith.index_cast %18 : i32 to index
        %20 = arith.muli %16, %14 : i32
        %21 = arith.index_cast %20 : i32 to index
        %22 = scf.if %17 -> (f32) {
          scf.yield %cst : f32
        } else {
          %24 = arith.addi %arg4, %c-1 : index
          %25 = memref.load %alloca[%24] : memref<1xf32, 5>
          scf.yield %25 : f32
        }
        %23 = scf.for %arg5 = %21 to %19 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %24 = arith.index_cast %arg5 : index to i32
          %25 = arith.muli %24, %arg3 : i32
          %26 = arith.index_cast %25 : i32 to index
          %27 = arith.addi %26, %13 : index
          %28 = "polygeist.subindex"(%arg0, %27) : (memref<?xf32>, index) -> memref<?xf32>
          %29 = func.call @__nvvm_ldg_f(%28) : (memref<?xf32>) -> f32
          %30 = arith.addf %arg6, %29 : f32
          %31 = arith.addf %30, %22 : f32
          %32 = arith.muli %arg5, %15 : index
          %33 = arith.addi %32, %13 : index
          memref.store %31, %arg1[%33] : memref<?xf32>
          scf.yield %30 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_1 = memref.alloca() : memref<32xi32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_1 = memref.alloca() : memref<32xi32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<32xi32, 5>
      %2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_1 = memref.alloca() : memref<32xi32, 5>
      %alloca_2 = memref.alloca() : memref<32xi32, 5>
      %alloca_3 = memref.alloca() : memref<32xf32, 5>
      %alloca_4 = memref.alloca() : memref<i1, 5>
      %3 = gpu.block_id  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.remsi %4, %arg3 : i32
      %6 = arith.index_cast %5 : i32 to index
      %c32_5 = arith.constant 32 : index
      %7 = arith.index_cast %c32_5 : index to i32
      %8 = arith.addi %arg2, %7 : i32
      %9 = arith.addi %8, %c-1_i32 : i32
      %10 = arith.divsi %4, %arg3 : i32
      %11 = arith.muli %10, %arg2 : i32
      %12 = arith.muli %11, %arg3 : i32
      %13 = arith.index_cast %12 : i32 to index
      %14 = arith.addi %6, %13 : index
      %15 = arith.divsi %9, %7 : i32
      %c1_6 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_6 {
        %17 = arith.index_cast %arg4 : index to i32
        %18 = arith.muli %17, %15 : i32
        %19 = arith.addi %18, %15 : i32
        %20 = func.call @__nv_min(%19, %arg2) : (i32, i32) -> i32
        memref.store %20, %alloca_0[%arg4] : memref<32xi32, 5>
        %21 = arith.index_cast %20 : i32 to index
        %22 = arith.index_cast %18 : i32 to index
        %23 = scf.for %arg5 = %22 to %21 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %24 = arith.index_cast %arg5 : index to i32
          %25 = arith.muli %24, %arg3 : i32
          %26 = arith.index_cast %25 : i32 to index
          %27 = arith.addi %26, %14 : index
          %28 = "polygeist.subindex"(%arg0, %27) : (memref<?xf32>, index) -> memref<?xf32>
          %29 = func.call @__nvvm_ldg_f(%28) : (memref<?xf32>) -> f32
          %30 = arith.addf %arg6, %29 : f32
          scf.yield %30 : f32
        }
        memref.store %23, %alloca[%arg4] : memref<1xf32, 5>
      }
      %c1_7 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_7 {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %18 = memref.load %alloca_1[%arg4] : memref<32xi32, 5>
          %19 = arith.cmpi slt, %18, %7 : i32
          %20 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %20 {
            memref.store %19, %alloca_4[] : memref<i1, 5>
          }
          memref.store %18, %alloca_2[%arg4] : memref<32xi32, 5>
        }
        %17 = memref.load %alloca_4[] : memref<i1, 5>
        scf.condition(%17)
      } do {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %17 = arith.index_cast %arg4 : index to i32
          %18 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %19 = arith.cmpi sge, %17, %18 : i32
          %20 = scf.if %19 -> (f32) {
            %21 = arith.subi %17, %18 : i32
            %22 = arith.index_cast %21 : i32 to index
            %23 = memref.load %alloca[%22] : memref<1xf32, 5>
            scf.yield %23 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %20, %alloca_3[%arg4] : memref<32xf32, 5>
        }
        %c1_10 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_10 {
          %17 = memref.load %alloca_3[%arg4] : memref<32xf32, 5>
          %18 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %19 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %20 = arith.addf %19, %17 : f32
          memref.store %20, %alloca[%arg4] : memref<1xf32, 5>
          %21 = arith.muli %18, %c2_i32 : i32
          memref.store %21, %alloca_1[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %16 = arith.index_cast %arg3 : i32 to index
      %c1_8 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_8 {
        %17 = arith.index_cast %arg4 : index to i32
        %18 = arith.cmpi eq, %17, %c0_i32 : i32
        %19 = memref.load %alloca_0[%arg4] : memref<32xi32, 5>
        %20 = arith.index_cast %19 : i32 to index
        %21 = arith.muli %17, %15 : i32
        %22 = arith.index_cast %21 : i32 to index
        %23 = scf.if %18 -> (f32) {
          scf.yield %cst : f32
        } else {
          %25 = arith.addi %arg4, %c-1 : index
          %26 = memref.load %alloca[%25] : memref<1xf32, 5>
          scf.yield %26 : f32
        }
        %24 = scf.for %arg5 = %22 to %20 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %25 = arith.index_cast %arg5 : index to i32
          %26 = arith.muli %25, %arg3 : i32
          %27 = arith.index_cast %26 : i32 to index
          %28 = arith.addi %27, %14 : index
          %29 = "polygeist.subindex"(%arg0, %28) : (memref<?xf32>, index) -> memref<?xf32>
          %30 = func.call @__nvvm_ldg_f(%29) : (memref<?xf32>) -> f32
          %31 = arith.addf %arg6, %30 : f32
          %32 = arith.addf %31, %23 : f32
          %33 = arith.muli %arg5, %16 : index
          %34 = arith.addi %33, %14 : index
          memref.store %32, %arg1[%34] : memref<?xf32>
          scf.yield %31 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_2 = memref.alloca() : memref<32xi32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%3 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_2 = memref.alloca() : memref<32xi32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<32xi32, 5>
      %2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_1 = memref.alloca() : memref<32xi32, 5>
      %3 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_2 = memref.alloca() : memref<32xi32, 5>
      %alloca_3 = memref.alloca() : memref<32xf32, 5>
      %alloca_4 = memref.alloca() : memref<i1, 5>
      %4 = gpu.block_id  x
      %5 = arith.index_cast %4 : index to i32
      %6 = arith.remsi %5, %arg3 : i32
      %7 = arith.index_cast %6 : i32 to index
      %c32_5 = arith.constant 32 : index
      %8 = arith.index_cast %c32_5 : index to i32
      %9 = arith.addi %arg2, %8 : i32
      %10 = arith.addi %9, %c-1_i32 : i32
      %11 = arith.divsi %5, %arg3 : i32
      %12 = arith.muli %11, %arg2 : i32
      %13 = arith.muli %12, %arg3 : i32
      %14 = arith.index_cast %13 : i32 to index
      %15 = arith.addi %7, %14 : index
      %16 = arith.divsi %10, %8 : i32
      %c1_6 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_6 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.muli %18, %16 : i32
        %20 = arith.addi %19, %16 : i32
        %21 = func.call @__nv_min(%20, %arg2) : (i32, i32) -> i32
        memref.store %21, %alloca_0[%arg4] : memref<32xi32, 5>
        %22 = arith.index_cast %21 : i32 to index
        %23 = arith.index_cast %19 : i32 to index
        %24 = scf.for %arg5 = %23 to %22 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %25 = arith.index_cast %arg5 : index to i32
          %26 = arith.muli %25, %arg3 : i32
          %27 = arith.index_cast %26 : i32 to index
          %28 = arith.addi %27, %15 : index
          %29 = "polygeist.subindex"(%arg0, %28) : (memref<?xf32>, index) -> memref<?xf32>
          %30 = func.call @__nvvm_ldg_f(%29) : (memref<?xf32>) -> f32
          %31 = arith.addf %arg6, %30 : f32
          scf.yield %31 : f32
        }
        memref.store %24, %alloca[%arg4] : memref<1xf32, 5>
      }
      %c1_7 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_7 {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %19 = memref.load %alloca_1[%arg4] : memref<32xi32, 5>
          %20 = arith.cmpi slt, %19, %8 : i32
          %21 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %21 {
            memref.store %20, %alloca_4[] : memref<i1, 5>
          }
          memref.store %19, %alloca_2[%arg4] : memref<32xi32, 5>
        }
        %18 = memref.load %alloca_4[] : memref<i1, 5>
        scf.condition(%18)
      } do {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %18 = arith.index_cast %arg4 : index to i32
          %19 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %20 = arith.cmpi sge, %18, %19 : i32
          %21 = scf.if %20 -> (f32) {
            %22 = arith.subi %18, %19 : i32
            %23 = arith.index_cast %22 : i32 to index
            %24 = memref.load %alloca[%23] : memref<1xf32, 5>
            scf.yield %24 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %21, %alloca_3[%arg4] : memref<32xf32, 5>
        }
        %c1_10 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_10 {
          %18 = memref.load %alloca_3[%arg4] : memref<32xf32, 5>
          %19 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %20 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %21 = arith.addf %20, %18 : f32
          memref.store %21, %alloca[%arg4] : memref<1xf32, 5>
          %22 = arith.muli %19, %c2_i32 : i32
          memref.store %22, %alloca_1[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %17 = arith.index_cast %arg3 : i32 to index
      %c1_8 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_8 {
        %18 = arith.index_cast %arg4 : index to i32
        %19 = arith.cmpi eq, %18, %c0_i32 : i32
        %20 = memref.load %alloca_0[%arg4] : memref<32xi32, 5>
        %21 = arith.index_cast %20 : i32 to index
        %22 = arith.muli %18, %16 : i32
        %23 = arith.index_cast %22 : i32 to index
        %24 = scf.if %19 -> (f32) {
          scf.yield %cst : f32
        } else {
          %26 = arith.addi %arg4, %c-1 : index
          %27 = memref.load %alloca[%26] : memref<1xf32, 5>
          scf.yield %27 : f32
        }
        %25 = scf.for %arg5 = %23 to %21 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %26 = arith.index_cast %arg5 : index to i32
          %27 = arith.muli %26, %arg3 : i32
          %28 = arith.index_cast %27 : i32 to index
          %29 = arith.addi %28, %15 : index
          %30 = "polygeist.subindex"(%arg0, %29) : (memref<?xf32>, index) -> memref<?xf32>
          %31 = func.call @__nvvm_ldg_f(%30) : (memref<?xf32>) -> f32
          %32 = arith.addf %arg6, %31 : f32
          %33 = arith.addf %32, %24 : f32
          %34 = arith.muli %arg5, %17 : index
          %35 = arith.addi %34, %15 : index
          memref.store %33, %arg1[%35] : memref<?xf32>
          scf.yield %32 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_3 = memref.alloca() : memref<32xf32, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_3 = memref.alloca() : memref<32xf32, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<32xi32, 5>
      %2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_1 = memref.alloca() : memref<32xi32, 5>
      %3 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_2 = memref.alloca() : memref<32xi32, 5>
      %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_3 = memref.alloca() : memref<32xf32, 5>
      %alloca_4 = memref.alloca() : memref<i1, 5>
      %5 = gpu.block_id  x
      %6 = arith.index_cast %5 : index to i32
      %7 = arith.remsi %6, %arg3 : i32
      %8 = arith.index_cast %7 : i32 to index
      %c32_5 = arith.constant 32 : index
      %9 = arith.index_cast %c32_5 : index to i32
      %10 = arith.addi %arg2, %9 : i32
      %11 = arith.addi %10, %c-1_i32 : i32
      %12 = arith.divsi %6, %arg3 : i32
      %13 = arith.muli %12, %arg2 : i32
      %14 = arith.muli %13, %arg3 : i32
      %15 = arith.index_cast %14 : i32 to index
      %16 = arith.addi %8, %15 : index
      %17 = arith.divsi %11, %9 : i32
      %c1_6 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_6 {
        %19 = arith.index_cast %arg4 : index to i32
        %20 = arith.muli %19, %17 : i32
        %21 = arith.addi %20, %17 : i32
        %22 = func.call @__nv_min(%21, %arg2) : (i32, i32) -> i32
        memref.store %22, %alloca_0[%arg4] : memref<32xi32, 5>
        %23 = arith.index_cast %22 : i32 to index
        %24 = arith.index_cast %20 : i32 to index
        %25 = scf.for %arg5 = %24 to %23 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %26 = arith.index_cast %arg5 : index to i32
          %27 = arith.muli %26, %arg3 : i32
          %28 = arith.index_cast %27 : i32 to index
          %29 = arith.addi %28, %16 : index
          %30 = "polygeist.subindex"(%arg0, %29) : (memref<?xf32>, index) -> memref<?xf32>
          %31 = func.call @__nvvm_ldg_f(%30) : (memref<?xf32>) -> f32
          %32 = arith.addf %arg6, %31 : f32
          scf.yield %32 : f32
        }
        memref.store %25, %alloca[%arg4] : memref<1xf32, 5>
      }
      %c1_7 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_7 {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %20 = memref.load %alloca_1[%arg4] : memref<32xi32, 5>
          %21 = arith.cmpi slt, %20, %9 : i32
          %22 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %22 {
            memref.store %21, %alloca_4[] : memref<i1, 5>
          }
          memref.store %20, %alloca_2[%arg4] : memref<32xi32, 5>
        }
        %19 = memref.load %alloca_4[] : memref<i1, 5>
        scf.condition(%19)
      } do {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %19 = arith.index_cast %arg4 : index to i32
          %20 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %21 = arith.cmpi sge, %19, %20 : i32
          %22 = scf.if %21 -> (f32) {
            %23 = arith.subi %19, %20 : i32
            %24 = arith.index_cast %23 : i32 to index
            %25 = memref.load %alloca[%24] : memref<1xf32, 5>
            scf.yield %25 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %22, %alloca_3[%arg4] : memref<32xf32, 5>
        }
        %c1_10 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_10 {
          %19 = memref.load %alloca_3[%arg4] : memref<32xf32, 5>
          %20 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %21 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %22 = arith.addf %21, %19 : f32
          memref.store %22, %alloca[%arg4] : memref<1xf32, 5>
          %23 = arith.muli %20, %c2_i32 : i32
          memref.store %23, %alloca_1[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %18 = arith.index_cast %arg3 : i32 to index
      %c1_8 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_8 {
        %19 = arith.index_cast %arg4 : index to i32
        %20 = arith.cmpi eq, %19, %c0_i32 : i32
        %21 = memref.load %alloca_0[%arg4] : memref<32xi32, 5>
        %22 = arith.index_cast %21 : i32 to index
        %23 = arith.muli %19, %17 : i32
        %24 = arith.index_cast %23 : i32 to index
        %25 = scf.if %20 -> (f32) {
          scf.yield %cst : f32
        } else {
          %27 = arith.addi %arg4, %c-1 : index
          %28 = memref.load %alloca[%27] : memref<1xf32, 5>
          scf.yield %28 : f32
        }
        %26 = scf.for %arg5 = %24 to %22 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %27 = arith.index_cast %arg5 : index to i32
          %28 = arith.muli %27, %arg3 : i32
          %29 = arith.index_cast %28 : i32 to index
          %30 = arith.addi %29, %16 : index
          %31 = "polygeist.subindex"(%arg0, %30) : (memref<?xf32>, index) -> memref<?xf32>
          %32 = func.call @__nvvm_ldg_f(%31) : (memref<?xf32>) -> f32
          %33 = arith.addf %arg6, %32 : f32
          %34 = arith.addf %33, %25 : f32
          %35 = arith.muli %arg5, %18 : index
          %36 = arith.addi %35, %16 : index
          memref.store %34, %arg1[%36] : memref<?xf32>
          scf.yield %33 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] MemRefAllocaToNPULowering: process op: 

%alloca_4 = memref.alloca() : memref<i1, 5>
[ict-debug] MemRefAllocaToNPULowering: memory space is 5

MemRefAllocaToNPULowering: newAllocaOp: 
%5 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
MemRefAllocaToNPULowering: old allocaOp: 
%alloca_4 = memref.alloca() : memref<i1, 5>
MemRefAllocaToNPULowering: module: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca = memref.alloca() : memref<1xf32, 5>
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_0 = memref.alloca() : memref<32xi32, 5>
      %2 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_1 = memref.alloca() : memref<32xi32, 5>
      %3 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_2 = memref.alloca() : memref<32xi32, 5>
      %4 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_3 = memref.alloca() : memref<32xf32, 5>
      %5 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %alloca_4 = memref.alloca() : memref<i1, 5>
      %6 = gpu.block_id  x
      %7 = arith.index_cast %6 : index to i32
      %8 = arith.remsi %7, %arg3 : i32
      %9 = arith.index_cast %8 : i32 to index
      %c32_5 = arith.constant 32 : index
      %10 = arith.index_cast %c32_5 : index to i32
      %11 = arith.addi %arg2, %10 : i32
      %12 = arith.addi %11, %c-1_i32 : i32
      %13 = arith.divsi %7, %arg3 : i32
      %14 = arith.muli %13, %arg2 : i32
      %15 = arith.muli %14, %arg3 : i32
      %16 = arith.index_cast %15 : i32 to index
      %17 = arith.addi %9, %16 : index
      %18 = arith.divsi %12, %10 : i32
      %c1_6 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_6 {
        %20 = arith.index_cast %arg4 : index to i32
        %21 = arith.muli %20, %18 : i32
        %22 = arith.addi %21, %18 : i32
        %23 = func.call @__nv_min(%22, %arg2) : (i32, i32) -> i32
        memref.store %23, %alloca_0[%arg4] : memref<32xi32, 5>
        %24 = arith.index_cast %23 : i32 to index
        %25 = arith.index_cast %21 : i32 to index
        %26 = scf.for %arg5 = %25 to %24 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %27 = arith.index_cast %arg5 : index to i32
          %28 = arith.muli %27, %arg3 : i32
          %29 = arith.index_cast %28 : i32 to index
          %30 = arith.addi %29, %17 : index
          %31 = "polygeist.subindex"(%arg0, %30) : (memref<?xf32>, index) -> memref<?xf32>
          %32 = func.call @__nvvm_ldg_f(%31) : (memref<?xf32>) -> f32
          %33 = arith.addf %arg6, %32 : f32
          scf.yield %33 : f32
        }
        memref.store %26, %alloca[%arg4] : memref<1xf32, 5>
      }
      %c1_7 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_7 {
        memref.store %c1_i32, %alloca_1[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %21 = memref.load %alloca_1[%arg4] : memref<32xi32, 5>
          %22 = arith.cmpi slt, %21, %10 : i32
          %23 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %23 {
            memref.store %22, %alloca_4[] : memref<i1, 5>
          }
          memref.store %21, %alloca_2[%arg4] : memref<32xi32, 5>
        }
        %20 = memref.load %alloca_4[] : memref<i1, 5>
        scf.condition(%20)
      } do {
        %c1_9 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_9 {
          %20 = arith.index_cast %arg4 : index to i32
          %21 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %22 = arith.cmpi sge, %20, %21 : i32
          %23 = scf.if %22 -> (f32) {
            %24 = arith.subi %20, %21 : i32
            %25 = arith.index_cast %24 : i32 to index
            %26 = memref.load %alloca[%25] : memref<1xf32, 5>
            scf.yield %26 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %23, %alloca_3[%arg4] : memref<32xf32, 5>
        }
        %c1_10 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_10 {
          %20 = memref.load %alloca_3[%arg4] : memref<32xf32, 5>
          %21 = memref.load %alloca_2[%arg4] : memref<32xi32, 5>
          %22 = memref.load %alloca[%arg4] : memref<1xf32, 5>
          %23 = arith.addf %22, %20 : f32
          memref.store %23, %alloca[%arg4] : memref<1xf32, 5>
          %24 = arith.muli %21, %c2_i32 : i32
          memref.store %24, %alloca_1[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %19 = arith.index_cast %arg3 : i32 to index
      %c1_8 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_8 {
        %20 = arith.index_cast %arg4 : index to i32
        %21 = arith.cmpi eq, %20, %c0_i32 : i32
        %22 = memref.load %alloca_0[%arg4] : memref<32xi32, 5>
        %23 = arith.index_cast %22 : i32 to index
        %24 = arith.muli %20, %18 : i32
        %25 = arith.index_cast %24 : i32 to index
        %26 = scf.if %21 -> (f32) {
          scf.yield %cst : f32
        } else {
          %28 = arith.addi %arg4, %c-1 : index
          %29 = memref.load %alloca[%28] : memref<1xf32, 5>
          scf.yield %29 : f32
        }
        %27 = scf.for %arg5 = %25 to %23 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %28 = arith.index_cast %arg5 : index to i32
          %29 = arith.muli %28, %arg3 : i32
          %30 = arith.index_cast %29 : i32 to index
          %31 = arith.addi %30, %17 : index
          %32 = "polygeist.subindex"(%arg0, %31) : (memref<?xf32>, index) -> memref<?xf32>
          %33 = func.call @__nvvm_ldg_f(%32) : (memref<?xf32>) -> f32
          %34 = arith.addf %arg6, %33 : f32
          %35 = arith.addf %34, %26 : f32
          %36 = arith.muli %arg5, %19 : index
          %37 = arith.addi %36, %17 : index
          memref.store %35, %arg1[%37] : memref<?xf32>
          scf.yield %34 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
MemRefAllocaToNPULowering: module: end
[ict-debug] GPUBlockIdToNPULowering: process op: 

%6 = gpu.block_id  x
[ict-debug] CastLikeOpToNPULowering: process op: 

%8 = arith.index_cast %7 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%11 = arith.index_cast %10 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%19 = arith.index_cast %18 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%25 = arith.index_cast %arg4 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%30 = arith.index_cast %29 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%32 = arith.index_cast %27 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%36 = arith.index_cast %arg5 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%39 = arith.index_cast %38 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%26 = arith.index_cast %arg4 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%32 = arith.index_cast %31 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%24 = arith.index_cast %arg3 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%27 = arith.index_cast %arg4 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%31 = arith.index_cast %30 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%34 = arith.index_cast %33 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%39 = arith.index_cast %arg5 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%42 = arith.index_cast %41 : i32 to index
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xf32> to !llvm.ptr
      %c-1_i32 = arith.constant -1 : i32
      %c0_i32 = arith.constant 0 : i32
      %c2_i32 = arith.constant 2 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c1_i32 = arith.constant 1 : i32
      %c-1 = arith.constant -1 : index
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %2 = builtin.unrealized_conversion_cast %1 : !llvm.ptr<6> to memref<1xf32, 5>
      %3 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %4 = builtin.unrealized_conversion_cast %3 : !llvm.ptr<6> to memref<32xi32, 5>
      %5 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %6 = builtin.unrealized_conversion_cast %5 : !llvm.ptr<6> to memref<32xi32, 5>
      %7 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %8 = builtin.unrealized_conversion_cast %7 : !llvm.ptr<6> to memref<32xi32, 5>
      %9 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %10 = builtin.unrealized_conversion_cast %9 : !llvm.ptr<6> to memref<32xf32, 5>
      %11 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %12 = builtin.unrealized_conversion_cast %11 : !llvm.ptr<6> to memref<i1, 5>
      %13 = "npu.block_id"() : () -> i64
      %14 = emitc.cast %13 : i64 to i32
      %15 = arith.remsi %14, %arg3 : i32
      %16 = emitc.cast %15 : i32 to index
      %c32_0 = arith.constant 32 : index
      %c32_i32 = arith.constant 32 : i32
      %17 = arith.addi %arg2, %c32_i32 : i32
      %18 = arith.addi %17, %c-1_i32 : i32
      %19 = arith.divsi %14, %arg3 : i32
      %20 = arith.muli %19, %arg2 : i32
      %21 = arith.muli %20, %arg3 : i32
      %22 = emitc.cast %21 : i32 to index
      %23 = arith.addi %16, %22 : index
      %24 = arith.divsi %18, %c32_i32 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_1 {
        %26 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %27 = emitc.cast %26 : i64 to i32
        %28 = arith.muli %27, %24 : i32
        %29 = arith.addi %28, %24 : i32
        %30 = func.call @__nv_min(%29, %arg2) : (i32, i32) -> i32
        memref.store %30, %4[%arg4] : memref<32xi32, 5>
        %31 = emitc.cast %30 : i32 to index
        %32 = emitc.cast %28 : i32 to index
        %33 = scf.for %arg5 = %32 to %31 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %34 = builtin.unrealized_conversion_cast %arg5 : index to i64
          %35 = emitc.cast %34 : i64 to i32
          %36 = arith.muli %35, %arg3 : i32
          %37 = emitc.cast %36 : i32 to index
          %38 = arith.addi %37, %23 : index
          %39 = builtin.unrealized_conversion_cast %38 : index to i64
          %40 = llvm.getelementptr %0[%39] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %41 = llvm.bitcast %40 : !llvm.ptr to !llvm.ptr
          %42 = builtin.unrealized_conversion_cast %41 : !llvm.ptr to memref<?xf32>
          %43 = func.call @__nvvm_ldg_f(%42) : (memref<?xf32>) -> f32
          %44 = emitc.add %arg6, %43 : (f32, f32) -> f32
          scf.yield %44 : f32
        }
        memref.store %33, %2[%arg4] : memref<1xf32, 5>
      }
      %c1_2 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_2 {
        memref.store %c1_i32, %6[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        %c1_4 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_4 {
          %27 = memref.load %6[%arg4] : memref<32xi32, 5>
          %28 = arith.cmpi slt, %27, %c32_i32 : i32
          %29 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %29 {
            memref.store %28, %12[] : memref<i1, 5>
          }
          memref.store %27, %8[%arg4] : memref<32xi32, 5>
        }
        %26 = memref.load %12[] : memref<i1, 5>
        scf.condition(%26)
      } do {
        %c1_4 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_4 {
          %26 = builtin.unrealized_conversion_cast %arg4 : index to i64
          %27 = emitc.cast %26 : i64 to i32
          %28 = memref.load %8[%arg4] : memref<32xi32, 5>
          %29 = arith.cmpi sge, %27, %28 : i32
          %30 = scf.if %29 -> (f32) {
            %31 = arith.subi %27, %28 : i32
            %32 = emitc.cast %31 : i32 to index
            %33 = memref.load %2[%32] : memref<1xf32, 5>
            scf.yield %33 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %30, %10[%arg4] : memref<32xf32, 5>
        }
        %c1_5 = arith.constant 1 : index
        scf.for %arg4 = %c0 to %c32 step %c1_5 {
          %26 = memref.load %10[%arg4] : memref<32xf32, 5>
          %27 = memref.load %8[%arg4] : memref<32xi32, 5>
          %28 = memref.load %2[%arg4] : memref<1xf32, 5>
          %29 = emitc.add %28, %26 : (f32, f32) -> f32
          memref.store %29, %2[%arg4] : memref<1xf32, 5>
          %30 = arith.muli %27, %c2_i32 : i32
          memref.store %30, %6[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %25 = emitc.cast %arg3 : i32 to index
      %c1_3 = arith.constant 1 : index
      scf.for %arg4 = %c0 to %c32 step %c1_3 {
        %26 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %27 = emitc.cast %26 : i64 to i32
        %28 = arith.cmpi eq, %27, %c0_i32 : i32
        %29 = memref.load %4[%arg4] : memref<32xi32, 5>
        %30 = emitc.cast %29 : i32 to index
        %31 = arith.muli %27, %24 : i32
        %32 = emitc.cast %31 : i32 to index
        %33 = scf.if %28 -> (f32) {
          scf.yield %cst : f32
        } else {
          %35 = arith.addi %arg4, %c-1 : index
          %36 = memref.load %2[%35] : memref<1xf32, 5>
          scf.yield %36 : f32
        }
        %34 = scf.for %arg5 = %32 to %30 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %35 = builtin.unrealized_conversion_cast %arg5 : index to i64
          %36 = emitc.cast %35 : i64 to i32
          %37 = arith.muli %36, %arg3 : i32
          %38 = emitc.cast %37 : i32 to index
          %39 = arith.addi %38, %23 : index
          %40 = builtin.unrealized_conversion_cast %39 : index to i64
          %41 = llvm.getelementptr %0[%40] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %42 = llvm.bitcast %41 : !llvm.ptr to !llvm.ptr
          %43 = builtin.unrealized_conversion_cast %42 : !llvm.ptr to memref<?xf32>
          %44 = func.call @__nvvm_ldg_f(%43) : (memref<?xf32>) -> f32
          %45 = emitc.add %arg6, %44 : (f32, f32) -> f32
          %46 = emitc.add %45, %33 : (f32, f32) -> f32
          %47 = arith.muli %arg5, %25 : index
          %48 = arith.addi %47, %23 : index
          memref.store %46, %arg1[%48] : memref<?xf32>
          scf.yield %45 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU: end

[ict-debug] driver.cc: Before convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %c32_i32 = arith.constant 32 : i32
      %c32 = arith.constant 32 : index
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %c-1 = arith.constant -1 : index
      %c1_i32 = arith.constant 1 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c2_i32 = arith.constant 2 : i32
      %c0_i32 = arith.constant 0 : i32
      %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xf32> to !llvm.ptr
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %2 = builtin.unrealized_conversion_cast %1 : !llvm.ptr<6> to memref<1xf32, 5>
      %3 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %4 = builtin.unrealized_conversion_cast %3 : !llvm.ptr<6> to memref<32xi32, 5>
      %5 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %6 = builtin.unrealized_conversion_cast %5 : !llvm.ptr<6> to memref<32xi32, 5>
      %7 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %8 = builtin.unrealized_conversion_cast %7 : !llvm.ptr<6> to memref<32xi32, 5>
      %9 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %10 = builtin.unrealized_conversion_cast %9 : !llvm.ptr<6> to memref<32xf32, 5>
      %11 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %12 = builtin.unrealized_conversion_cast %11 : !llvm.ptr<6> to memref<i1, 5>
      %13 = "npu.block_id"() : () -> i64
      %14 = emitc.cast %13 : i64 to i32
      %15 = arith.remsi %14, %arg3 : i32
      %16 = emitc.cast %15 : i32 to index
      %17 = arith.addi %arg2, %c31_i32 : i32
      %18 = arith.divsi %14, %arg3 : i32
      %19 = arith.muli %18, %arg2 : i32
      %20 = arith.muli %19, %arg3 : i32
      %21 = emitc.cast %20 : i32 to index
      %22 = arith.addi %16, %21 : index
      %23 = arith.divsi %17, %c32_i32 : i32
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %25 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %26 = emitc.cast %25 : i64 to i32
        %27 = arith.muli %26, %23 : i32
        %28 = arith.addi %27, %23 : i32
        %29 = func.call @__nv_min(%28, %arg2) : (i32, i32) -> i32
        memref.store %29, %4[%arg4] : memref<32xi32, 5>
        %30 = emitc.cast %29 : i32 to index
        %31 = emitc.cast %27 : i32 to index
        %32 = scf.for %arg5 = %31 to %30 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %33 = builtin.unrealized_conversion_cast %arg5 : index to i64
          %34 = emitc.cast %33 : i64 to i32
          %35 = arith.muli %34, %arg3 : i32
          %36 = emitc.cast %35 : i32 to index
          %37 = arith.addi %36, %22 : index
          %38 = builtin.unrealized_conversion_cast %37 : index to i64
          %39 = llvm.getelementptr %0[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %40 = builtin.unrealized_conversion_cast %39 : !llvm.ptr to memref<?xf32>
          %41 = func.call @__nvvm_ldg_f(%40) : (memref<?xf32>) -> f32
          %42 = emitc.add %arg6, %41 : (f32, f32) -> f32
          scf.yield %42 : f32
        }
        memref.store %32, %2[%arg4] : memref<1xf32, 5>
      }
      scf.for %arg4 = %c0 to %c32 step %c1 {
        memref.store %c1_i32, %6[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %26 = memref.load %6[%arg4] : memref<32xi32, 5>
          %27 = arith.cmpi slt, %26, %c32_i32 : i32
          %28 = arith.cmpi eq, %arg4, %c0 : index
          scf.if %28 {
            memref.store %27, %12[] : memref<i1, 5>
          }
          memref.store %26, %8[%arg4] : memref<32xi32, 5>
        }
        %25 = memref.load %12[] : memref<i1, 5>
        scf.condition(%25)
      } do {
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %25 = builtin.unrealized_conversion_cast %arg4 : index to i64
          %26 = emitc.cast %25 : i64 to i32
          %27 = memref.load %8[%arg4] : memref<32xi32, 5>
          %28 = arith.cmpi sge, %26, %27 : i32
          %29 = scf.if %28 -> (f32) {
            %30 = arith.subi %26, %27 : i32
            %31 = emitc.cast %30 : i32 to index
            %32 = memref.load %2[%31] : memref<1xf32, 5>
            scf.yield %32 : f32
          } else {
            scf.yield %cst : f32
          }
          memref.store %29, %10[%arg4] : memref<32xf32, 5>
        }
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %25 = memref.load %10[%arg4] : memref<32xf32, 5>
          %26 = memref.load %8[%arg4] : memref<32xi32, 5>
          %27 = memref.load %2[%arg4] : memref<1xf32, 5>
          %28 = emitc.add %27, %25 : (f32, f32) -> f32
          memref.store %28, %2[%arg4] : memref<1xf32, 5>
          %29 = arith.muli %26, %c2_i32 : i32
          memref.store %29, %6[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %24 = emitc.cast %arg3 : i32 to index
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %25 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %26 = emitc.cast %25 : i64 to i32
        %27 = arith.cmpi eq, %26, %c0_i32 : i32
        %28 = memref.load %4[%arg4] : memref<32xi32, 5>
        %29 = emitc.cast %28 : i32 to index
        %30 = arith.muli %26, %23 : i32
        %31 = emitc.cast %30 : i32 to index
        %32 = scf.if %27 -> (f32) {
          scf.yield %cst : f32
        } else {
          %34 = arith.addi %arg4, %c-1 : index
          %35 = memref.load %2[%34] : memref<1xf32, 5>
          scf.yield %35 : f32
        }
        %33 = scf.for %arg5 = %31 to %29 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %34 = builtin.unrealized_conversion_cast %arg5 : index to i64
          %35 = emitc.cast %34 : i64 to i32
          %36 = arith.muli %35, %arg3 : i32
          %37 = emitc.cast %36 : i32 to index
          %38 = arith.addi %37, %22 : index
          %39 = builtin.unrealized_conversion_cast %38 : index to i64
          %40 = llvm.getelementptr %0[%39] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %41 = builtin.unrealized_conversion_cast %40 : !llvm.ptr to memref<?xf32>
          %42 = func.call @__nvvm_ldg_f(%41) : (memref<?xf32>) -> f32
          %43 = emitc.add %arg6, %42 : (f32, f32) -> f32
          %44 = emitc.add %43, %32 : (f32, f32) -> f32
          %45 = arith.muli %arg5, %24 : index
          %46 = arith.addi %45, %22 : index
          memref.store %44, %arg1[%46] : memref<?xf32>
          scf.yield %43 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] driver.cc: Before convert to EmitC dialect: end

[ict-debug] driver.cc: After convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>, #dlti.dl_entry<"dlti.endianness", "little">>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z21aligned_cumsum_kernelPKfPfii_0 {
    gpu.func @_Z21aligned_cumsum_kernelPKfPfii(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: i32, %arg3: i32) {
      %c31_i32 = arith.constant 31 : i32
      %c32_i32 = arith.constant 32 : i32
      %c32 = arith.constant 32 : index
      %c1 = arith.constant 1 : index
      %c0 = arith.constant 0 : index
      %c-1 = arith.constant -1 : index
      %c1_i32 = arith.constant 1 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c2_i32 = arith.constant 2 : i32
      %c0_i32 = arith.constant 0 : i32
      %0 = builtin.unrealized_conversion_cast %arg0 : memref<?xf32> to !llvm.ptr
      %1 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %2 = builtin.unrealized_conversion_cast %1 : !llvm.ptr<6> to memref<1xf32, 5>
      %3 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %4 = builtin.unrealized_conversion_cast %3 : !llvm.ptr<6> to memref<32xi32, 5>
      %5 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %6 = builtin.unrealized_conversion_cast %5 : !llvm.ptr<6> to memref<32xi32, 5>
      %7 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %8 = builtin.unrealized_conversion_cast %7 : !llvm.ptr<6> to memref<32xi32, 5>
      %9 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %10 = builtin.unrealized_conversion_cast %9 : !llvm.ptr<6> to memref<32xf32, 5>
      %11 = "npu.alloca"() <{numElems = 32 : i32}> : () -> !llvm.ptr<6>
      %12 = builtin.unrealized_conversion_cast %11 : !llvm.ptr<6> to memref<i1, 5>
      %13 = "npu.block_id"() : () -> i64
      %14 = emitc.cast %13 : i64 to i32
      %15 = arith.remsi %14, %arg3 : i32
      %16 = emitc.cast %15 : i32 to index
      %17 = arith.addi %arg2, %c31_i32 : i32
      %18 = arith.divsi %14, %arg3 : i32
      %19 = arith.muli %18, %arg2 : i32
      %20 = arith.muli %19, %arg3 : i32
      %21 = emitc.cast %20 : i32 to index
      %22 = arith.addi %16, %21 : index
      %23 = arith.divsi %17, %c32_i32 : i32
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %25 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %26 = emitc.cast %25 : i64 to i32
        %27 = arith.muli %26, %23 : i32
        %28 = arith.addi %27, %23 : i32
        %29 = func.call @__nv_min(%28, %arg2) : (i32, i32) -> i32
        memref.store %29, %4[%arg4] : memref<32xi32, 5>
        %30 = emitc.cast %29 : i32 to index
        %31 = emitc.cast %27 : i32 to index
        %32 = scf.for %arg5 = %31 to %30 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %33 = builtin.unrealized_conversion_cast %arg5 : index to i64
          %34 = emitc.cast %33 : i64 to i32
          %35 = arith.muli %34, %arg3 : i32
          %36 = emitc.cast %35 : i32 to index
          %37 = arith.addi %36, %22 : index
          %38 = builtin.unrealized_conversion_cast %37 : index to i64
          %39 = llvm.getelementptr %0[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %40 = builtin.unrealized_conversion_cast %39 : !llvm.ptr to memref<?xf32>
          %41 = func.call @__nvvm_ldg_f(%40) : (memref<?xf32>) -> f32
          %42 = emitc.add %arg6, %41 : (f32, f32) -> f32
          scf.yield %42 : f32
        }
        memref.store %32, %2[%arg4] : memref<1xf32, 5>
      }
      scf.for %arg4 = %c0 to %c32 step %c1 {
        memref.store %c1_i32, %6[%arg4] : memref<32xi32, 5>
      }
      scf.while : () -> () {
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %26 = memref.load %6[%arg4] : memref<32xi32, 5>
          %27 = arith.cmpi slt, %26, %c32_i32 : i32
          %28 = arith.cmpi eq, %arg4, %c0 : index
          emitc.if %28 {
            memref.store %27, %12[] : memref<i1, 5>
          }
          memref.store %26, %8[%arg4] : memref<32xi32, 5>
        }
        %25 = memref.load %12[] : memref<i1, 5>
        scf.condition(%25)
      } do {
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %25 = builtin.unrealized_conversion_cast %arg4 : index to i64
          %26 = emitc.cast %25 : i64 to i32
          %27 = memref.load %8[%arg4] : memref<32xi32, 5>
          %28 = arith.cmpi sge, %26, %27 : i32
          %29 = "emitc.variable"() <{value = #emitc.opaque<"">}> : () -> f32
          emitc.if %28 {
            %30 = arith.subi %26, %27 : i32
            %31 = emitc.cast %30 : i32 to index
            %32 = memref.load %2[%31] : memref<1xf32, 5>
            emitc.assign %32 : f32 to %29 : f32
          } else {
            emitc.assign %cst : f32 to %29 : f32
          }
          memref.store %29, %10[%arg4] : memref<32xf32, 5>
        }
        scf.for %arg4 = %c0 to %c32 step %c1 {
          %25 = memref.load %10[%arg4] : memref<32xf32, 5>
          %26 = memref.load %8[%arg4] : memref<32xi32, 5>
          %27 = memref.load %2[%arg4] : memref<1xf32, 5>
          %28 = emitc.add %27, %25 : (f32, f32) -> f32
          memref.store %28, %2[%arg4] : memref<1xf32, 5>
          %29 = arith.muli %26, %c2_i32 : i32
          memref.store %29, %6[%arg4] : memref<32xi32, 5>
        }
        scf.yield
      }
      %24 = emitc.cast %arg3 : i32 to index
      scf.for %arg4 = %c0 to %c32 step %c1 {
        %25 = builtin.unrealized_conversion_cast %arg4 : index to i64
        %26 = emitc.cast %25 : i64 to i32
        %27 = arith.cmpi eq, %26, %c0_i32 : i32
        %28 = memref.load %4[%arg4] : memref<32xi32, 5>
        %29 = emitc.cast %28 : i32 to index
        %30 = arith.muli %26, %23 : i32
        %31 = emitc.cast %30 : i32 to index
        %32 = "emitc.variable"() <{value = #emitc.opaque<"">}> : () -> f32
        emitc.if %27 {
          emitc.assign %cst : f32 to %32 : f32
        } else {
          %34 = arith.addi %arg4, %c-1 : index
          %35 = memref.load %2[%34] : memref<1xf32, 5>
          emitc.assign %35 : f32 to %32 : f32
        }
        %33 = scf.for %arg5 = %31 to %29 step %c1 iter_args(%arg6 = %cst) -> (f32) {
          %34 = builtin.unrealized_conversion_cast %arg5 : index to i64
          %35 = emitc.cast %34 : i64 to i32
          %36 = arith.muli %35, %arg3 : i32
          %37 = emitc.cast %36 : i32 to index
          %38 = arith.addi %37, %22 : index
          %39 = builtin.unrealized_conversion_cast %38 : index to i64
          %40 = llvm.getelementptr %0[%39] : (!llvm.ptr, i64) -> !llvm.ptr, f32
          %41 = builtin.unrealized_conversion_cast %40 : !llvm.ptr to memref<?xf32>
          %42 = func.call @__nvvm_ldg_f(%41) : (memref<?xf32>) -> f32
          %43 = emitc.add %arg6, %42 : (f32, f32) -> f32
          %44 = emitc.add %43, %32 : (f32, f32) -> f32
          %45 = arith.muli %arg5, %24 : index
          %46 = arith.addi %45, %22 : index
          memref.store %44, %arg1[%46] : memref<?xf32>
          scf.yield %43 : f32
        }
      }
      gpu.return
    }
    func.func private @__nvvm_ldg_f(memref<?xf32>) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
    func.func private @__nv_min(i32, i32) -> i32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] driver.cc: After convert to EmitC dialect: end

loc(callsite("/CUDA2BANG/cuda2bang/polygeist/mlir-build/lib/clang/18/include/__clang_cuda_math.h":197:47 at "./cuda_ops/89_cumsum.cu":34:15)): error: ICT_ERROR(): cannot emit MemRef element type: 'memref<32xi32, 5>'
[ict-debug] driver.cc: After emitc::translateToCpp:

