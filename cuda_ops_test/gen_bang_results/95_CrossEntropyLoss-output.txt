warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z40__device_stub__cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0, %arg1, %arg2, %arg3, %arg4) : (memref<?xf32>, memref<?xi64>, memref<?xf32>, i32, i32) -> ()
    return
  }
  func.func private @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.muli %8, %arg4 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %9 : i32 to index
    %12 = arith.index_cast %9 : i32 to index
    %13 = arith.index_cast %9 : i32 to index
    %14 = arith.index_cast %8 : i32 to index
    %15 = arith.cmpi slt, %8, %arg3 : i32
    scf.if %15 {
      %16 = arith.index_cast %9 : i32 to index
      %17 = affine.load %arg1[symbol(%14)] : memref<?xi64>
      %18 = affine.load %arg0[symbol(%13)] : memref<?xf32>
      %19 = affine.for %arg5 = 1 to %0 iter_args(%arg6 = %18) -> (f32) {
        %28 = affine.load %arg0[%arg5 + symbol(%10)] : memref<?xf32>
        %29 = arith.cmpf ogt, %28, %arg6 : f32
        %30 = scf.if %29 -> (f32) {
          %31 = affine.load %arg0[%arg5 + symbol(%11)] : memref<?xf32>
          scf.yield %31 : f32
        } else {
          scf.yield %arg6 : f32
        }
        affine.yield %30 : f32
      }
      %20 = affine.for %arg5 = 0 to %0 iter_args(%arg6 = %cst) -> (f32) {
        %28 = affine.load %arg0[%arg5 + symbol(%12)] : memref<?xf32>
        %29 = arith.subf %28, %19 : f32
        %30 = math.exp %29 : f32
        %31 = arith.addf %arg6, %30 : f32
        affine.yield %31 : f32
      }
      %21 = func.call @_ZL4logff(%20) : (f32) -> f32
      %22 = arith.index_cast %17 : i64 to index
      %23 = arith.addi %22, %16 : index
      %24 = memref.load %arg0[%23] : memref<?xf32>
      %25 = arith.subf %24, %19 : f32
      %26 = arith.subf %25, %21 : f32
      %27 = arith.negf %26 : f32
      affine.store %27, %arg2[symbol(%14)] : memref<?xf32>
    }
    return
  }
  func.func private @_ZL4logff(%arg0: f32) -> f32 attributes {llvm.linkage = #llvm.linkage<internal>, polygeist.device_only_func = "1"} {
    %0 = call @__nv_logf(%arg0) : (f32) -> f32
    return %0 : f32
  }
  func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.muli %8, %arg4 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %8 : i32 to index
    %12 = arith.cmpi slt, %8, %arg3 : i32
    scf.if %12 {
      %13 = affine.load %arg1[symbol(%11)] : memref<?xi64>
      %14 = affine.load %arg0[symbol(%10)] : memref<?xf32>
      %15 = affine.for %arg5 = 1 to %0 iter_args(%arg6 = %14) -> (f32) {
        %24 = affine.load %arg0[%arg5 + symbol(%10)] : memref<?xf32>
        %25 = arith.cmpf ogt, %24, %arg6 : f32
        %26 = scf.if %25 -> (f32) {
          %27 = affine.load %arg0[%arg5 + symbol(%10)] : memref<?xf32>
          scf.yield %27 : f32
        } else {
          scf.yield %arg6 : f32
        }
        affine.yield %26 : f32
      }
      %16 = affine.for %arg5 = 0 to %0 iter_args(%arg6 = %cst) -> (f32) {
        %24 = affine.load %arg0[%arg5 + symbol(%10)] : memref<?xf32>
        %25 = arith.subf %24, %15 : f32
        %26 = math.exp %25 : f32
        %27 = arith.addf %arg6, %26 : f32
        affine.yield %27 : f32
      }
      %17 = func.call @__nv_logf(%16) : (f32) -> f32
      %18 = arith.index_cast %13 : i64 to index
      %19 = arith.addi %18, %10 : index
      %20 = memref.load %arg0[%19] : memref<?xf32>
      %21 = arith.subf %20, %15 : f32
      %22 = arith.subf %21, %17 : f32
      %23 = arith.negf %22 : f32
      affine.store %23, %arg2[symbol(%11)] : memref<?xf32>
    }
    return
  }
  func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func private @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    %6 = gpu.thread_id  x
    %7 = arith.index_cast %6 : index to i32
    %8 = arith.addi %5, %7 : i32
    %9 = arith.muli %8, %arg4 : i32
    %10 = arith.index_cast %9 : i32 to index
    %11 = arith.index_cast %8 : i32 to index
    %12 = arith.cmpi slt, %8, %arg3 : i32
    scf.if %12 {
      %13 = memref.load %arg1[%11] : memref<?xi64>
      %14 = memref.load %arg0[%10] : memref<?xf32>
      %15 = scf.for %arg5 = %c1 to %0 step %c1 iter_args(%arg6 = %14) -> (f32) {
        %24 = arith.addi %arg5, %10 : index
        %25 = memref.load %arg0[%24] : memref<?xf32>
        %26 = arith.cmpf ogt, %25, %arg6 : f32
        %27 = scf.if %26 -> (f32) {
          %28 = memref.load %arg0[%24] : memref<?xf32>
          scf.yield %28 : f32
        } else {
          scf.yield %arg6 : f32
        }
        scf.yield %27 : f32
      }
      %16 = scf.for %arg5 = %c0 to %0 step %c1 iter_args(%arg6 = %cst) -> (f32) {
        %24 = arith.addi %arg5, %10 : index
        %25 = memref.load %arg0[%24] : memref<?xf32>
        %26 = arith.subf %25, %15 : f32
        %27 = math.exp %26 : f32
        %28 = arith.addf %arg6, %27 : f32
        scf.yield %28 : f32
      }
      %17 = func.call @__nv_logf(%16) : (f32) -> f32
      %18 = arith.index_cast %13 : i64 to index
      %19 = arith.addi %18, %10 : index
      %20 = memref.load %arg0[%19] : memref<?xf32>
      %21 = arith.subf %20, %15 : f32
      %22 = arith.subf %21, %17 : f32
      %23 = arith.negf %22 : f32
      memref.store %23, %arg2[%11] : memref<?xf32>
    }
    return
  }
  func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-debug] WrapAndReplaceBarrierPass::runOnOperation(): Function name: __nv_logf. func.getBlocks().size() == 0! this function is empty, skip it.

WrapAndReplaceBarrierPass::runOnOperation(): after execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
      %c0_0 = arith.constant 0 : index
      %c1_1 = arith.constant 1 : index
      %cst = arith.constant 0.000000e+00 : f32
      %0 = arith.index_cast %arg4 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      %6 = arith.index_cast %arg5 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.muli %7, %arg4 : i32
      %9 = arith.index_cast %8 : i32 to index
      %10 = arith.index_cast %7 : i32 to index
      %11 = arith.cmpi slt, %7, %arg3 : i32
      scf.if %11 {
        %12 = memref.load %arg1[%10] : memref<?xi64>
        %13 = memref.load %arg0[%9] : memref<?xf32>
        %14 = scf.for %arg6 = %c1_1 to %0 step %c1_1 iter_args(%arg7 = %13) -> (f32) {
          %23 = arith.addi %arg6, %9 : index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.cmpf ogt, %24, %arg7 : f32
          %26 = scf.if %25 -> (f32) {
            %27 = memref.load %arg0[%23] : memref<?xf32>
            scf.yield %27 : f32
          } else {
            scf.yield %arg7 : f32
          }
          scf.yield %26 : f32
        }
        %15 = scf.for %arg6 = %c0_0 to %0 step %c1_1 iter_args(%arg7 = %cst) -> (f32) {
          %23 = arith.addi %arg6, %9 : index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.subf %24, %14 : f32
          %26 = math.exp %25 : f32
          %27 = arith.addf %arg7, %26 : f32
          scf.yield %27 : f32
        }
        %16 = func.call @__nv_logf(%15) : (f32) -> f32
        %17 = arith.index_cast %12 : i64 to index
        %18 = arith.addi %17, %9 : index
        %19 = memref.load %arg0[%18] : memref<?xf32>
        %20 = arith.subf %19, %14 : f32
        %21 = arith.subf %20, %16 : f32
        %22 = arith.negf %21 : f32
        memref.store %22, %arg2[%10] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
  func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
WrapAndReplaceBarrierPass::runOnOperation(): after execute: end
[ict-debug] driver.cc: After return 7, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
      %c0_0 = arith.constant 0 : index
      %c1_1 = arith.constant 1 : index
      %cst = arith.constant 0.000000e+00 : f32
      %0 = arith.index_cast %arg4 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      %6 = arith.index_cast %arg5 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.muli %7, %arg4 : i32
      %9 = arith.index_cast %8 : i32 to index
      %10 = arith.index_cast %7 : i32 to index
      %11 = arith.cmpi slt, %7, %arg3 : i32
      scf.if %11 {
        %12 = memref.load %arg1[%10] : memref<?xi64>
        %13 = memref.load %arg0[%9] : memref<?xf32>
        %14 = scf.for %arg6 = %c1_1 to %0 step %c1_1 iter_args(%arg7 = %13) -> (f32) {
          %23 = arith.addi %arg6, %9 : index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.cmpf ogt, %24, %arg7 : f32
          %26 = scf.if %25 -> (f32) {
            %27 = memref.load %arg0[%23] : memref<?xf32>
            scf.yield %27 : f32
          } else {
            scf.yield %arg7 : f32
          }
          scf.yield %26 : f32
        }
        %15 = scf.for %arg6 = %c0_0 to %0 step %c1_1 iter_args(%arg7 = %cst) -> (f32) {
          %23 = arith.addi %arg6, %9 : index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.subf %24, %14 : f32
          %26 = math.exp %25 : f32
          %27 = arith.addf %arg7, %26 : f32
          scf.yield %27 : f32
        }
        %16 = func.call @__nv_logf(%15) : (f32) -> f32
        %17 = arith.index_cast %12 : i64 to index
        %18 = arith.addi %17, %9 : index
        %19 = memref.load %arg0[%18] : memref<?xf32>
        %20 = arith.subf %19, %14 : f32
        %21 = arith.subf %20, %16 : f32
        %22 = arith.negf %21 : f32
        memref.store %22, %arg2[%10] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
  func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: After return 7, module: end

[ict-debug] driver.cc: Before my pass process:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  func.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %cst = arith.constant 0.000000e+00 : f32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c32 = arith.constant 32 : index
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = gpu.block_id  x
    %2 = arith.index_cast %1 : index to i32
    %3 = gpu.block_dim  x
    %4 = arith.index_cast %3 : index to i32
    %5 = arith.muli %2, %4 : i32
    scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
      %6 = arith.index_cast %arg5 : index to i32
      %7 = arith.addi %5, %6 : i32
      %8 = arith.muli %7, %arg4 : i32
      %9 = arith.index_cast %8 : i32 to index
      %10 = arith.index_cast %7 : i32 to index
      %11 = arith.cmpi slt, %7, %arg3 : i32
      scf.if %11 {
        %12 = memref.load %arg1[%10] : memref<?xi64>
        %13 = memref.load %arg0[%9] : memref<?xf32>
        %14 = scf.for %arg6 = %c1 to %0 step %c1 iter_args(%arg7 = %13) -> (f32) {
          %23 = arith.addi %arg6, %9 : index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.cmpf ogt, %24, %arg7 : f32
          %26 = scf.if %25 -> (f32) {
            %27 = memref.load %arg0[%23] : memref<?xf32>
            scf.yield %27 : f32
          } else {
            scf.yield %arg7 : f32
          }
          scf.yield %26 : f32
        }
        %15 = scf.for %arg6 = %c0 to %0 step %c1 iter_args(%arg7 = %cst) -> (f32) {
          %23 = arith.addi %arg6, %9 : index
          %24 = memref.load %arg0[%23] : memref<?xf32>
          %25 = arith.subf %24, %14 : f32
          %26 = math.exp %25 : f32
          %27 = arith.addf %arg7, %26 : f32
          scf.yield %27 : f32
        }
        %16 = func.call @__nv_logf(%15) : (f32) -> f32
        %17 = arith.index_cast %12 : i64 to index
        %18 = arith.addi %17, %9 : index
        %19 = memref.load %arg0[%18] : memref<?xf32>
        %20 = arith.subf %19, %14 : f32
        %21 = arith.subf %20, %16 : f32
        %22 = arith.negf %21 : f32
        memref.store %22, %arg2[%10] : memref<?xf32>
      }
      scf.yield
    }
    return
  }
  func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
}
[ict-debug] driver.cc: Before my pass process: end

[ict-debug] driver.cc: vectorizeSize = 1

[ict-debug] WrapAndReplaceBarrierPass::runOnOperation(): Function name: __nv_logf. func.getBlocks().size() == 0! this function is empty, skip it.

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z25cross_entropy_loss_kernelPKfPKlPfii_0 {
    gpu.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = arith.index_cast %arg4 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %3 = gpu.block_dim  x
      %4 = arith.index_cast %3 : index to i32
      %5 = arith.muli %2, %4 : i32
      scf.parallel (%arg5) = (%c0) to (%c32) step (%c1) {
        %6 = arith.index_cast %arg5 : index to i32
        %7 = arith.addi %5, %6 : i32
        %8 = arith.muli %7, %arg4 : i32
        %9 = arith.index_cast %8 : i32 to index
        %10 = arith.index_cast %7 : i32 to index
        %11 = arith.cmpi slt, %7, %arg3 : i32
        scf.if %11 {
          %12 = memref.load %arg1[%10] : memref<?xi64>
          %13 = memref.load %arg0[%9] : memref<?xf32>
          %14 = scf.for %arg6 = %c1 to %0 step %c1 iter_args(%arg7 = %13) -> (f32) {
            %23 = arith.addi %arg6, %9 : index
            %24 = memref.load %arg0[%23] : memref<?xf32>
            %25 = arith.cmpf ogt, %24, %arg7 : f32
            %26 = scf.if %25 -> (f32) {
              %27 = memref.load %arg0[%23] : memref<?xf32>
              scf.yield %27 : f32
            } else {
              scf.yield %arg7 : f32
            }
            scf.yield %26 : f32
          }
          %15 = scf.for %arg6 = %c0 to %0 step %c1 iter_args(%arg7 = %cst) -> (f32) {
            %23 = arith.addi %arg6, %9 : index
            %24 = memref.load %arg0[%23] : memref<?xf32>
            %25 = arith.subf %24, %14 : f32
            %26 = math.exp %25 : f32
            %27 = arith.addf %arg7, %26 : f32
            scf.yield %27 : f32
          }
          %16 = func.call @__nv_logf(%15) : (f32) -> f32
          %17 = arith.index_cast %12 : i64 to index
          %18 = arith.addi %17, %9 : index
          %19 = memref.load %arg0[%18] : memref<?xf32>
          %20 = arith.subf %19, %14 : f32
          %21 = arith.subf %20, %16 : f32
          %22 = arith.negf %21 : f32
          memref.store %22, %arg2[%10] : memref<?xf32>
        }
        scf.yield
      }
      gpu.return
    }
    func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): Before execute: end

[ict-debug] ConvertPolygeistToNPU:convertScfParallelToScfFor(): replace gpu.block_dim op with thread loop bound

[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z25cross_entropy_loss_kernelPKfPKlPfii_0 {
    gpu.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = arith.index_cast %arg4 : i32 to index
      %1 = gpu.block_id  x
      %2 = arith.index_cast %1 : index to i32
      %c32_0 = arith.constant 32 : index
      %3 = arith.index_cast %c32_0 : index to i32
      %4 = arith.muli %2, %3 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg5 = %c0 to %c32 step %c1_1 {
        %5 = arith.index_cast %arg5 : index to i32
        %6 = arith.addi %4, %5 : i32
        %7 = arith.muli %6, %arg4 : i32
        %8 = arith.index_cast %7 : i32 to index
        %9 = arith.index_cast %6 : i32 to index
        %10 = arith.cmpi slt, %6, %arg3 : i32
        scf.if %10 {
          %11 = memref.load %arg1[%9] : memref<?xi64>
          %12 = memref.load %arg0[%8] : memref<?xf32>
          %13 = scf.for %arg6 = %c1 to %0 step %c1 iter_args(%arg7 = %12) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.cmpf ogt, %23, %arg7 : f32
            %25 = scf.if %24 -> (f32) {
              %26 = memref.load %arg0[%22] : memref<?xf32>
              scf.yield %26 : f32
            } else {
              scf.yield %arg7 : f32
            }
            scf.yield %25 : f32
          }
          %14 = scf.for %arg6 = %c0 to %0 step %c1 iter_args(%arg7 = %cst) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.subf %23, %13 : f32
            %25 = math.exp %24 : f32
            %26 = arith.addf %arg7, %25 : f32
            scf.yield %26 : f32
          }
          %15 = func.call @__nv_logf(%14) : (f32) -> f32
          %16 = arith.index_cast %11 : i64 to index
          %17 = arith.addi %16, %8 : index
          %18 = memref.load %arg0[%17] : memref<?xf32>
          %19 = arith.subf %18, %13 : f32
          %20 = arith.subf %19, %15 : f32
          %21 = arith.negf %20 : f32
          memref.store %21, %arg2[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
    func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After vectorize: end

[ict-debug] CastLikeOpToNPULowering: process op: 

%0 = arith.index_cast %arg4 : i32 to index
[ict-debug] GPUBlockIdToNPULowering: process op: 

%2 = gpu.block_id  x
[ict-debug] CastLikeOpToNPULowering: process op: 

%4 = arith.index_cast %3 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%9 = arith.index_cast %arg5 : index to i32
[ict-debug] CastLikeOpToNPULowering: process op: 

%13 = arith.index_cast %12 : i32 to index
[ict-debug] CastLikeOpToNPULowering: process op: 

%15 = arith.index_cast %11 : i32 to index
[ict-debug] ArithUnaryOpToNPULowering: process op: 

%33 = math.exp %32 : f32
[ict-debug] ArithUnaryOpToNPULowering: met scalar unary op, need vector help process.

[ict-debug] CastLikeOpToNPULowering: process op: 

%23 = arith.index_cast %18 : i64 to index
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z25cross_entropy_loss_kernelPKfPKlPfii_0 {
    gpu.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) {
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = emitc.cast %arg4 : i32 to index
      %1 = "npu.block_id"() : () -> i64
      %2 = emitc.cast %1 : i64 to i32
      %c32_0 = arith.constant 32 : index
      %c32_i32 = arith.constant 32 : i32
      %3 = arith.muli %2, %c32_i32 : i32
      %c1_1 = arith.constant 1 : index
      scf.for %arg5 = %c0 to %c32 step %c1_1 {
        %4 = builtin.unrealized_conversion_cast %arg5 : index to i64
        %5 = emitc.cast %4 : i64 to i32
        %6 = arith.addi %3, %5 : i32
        %7 = arith.muli %6, %arg4 : i32
        %8 = emitc.cast %7 : i32 to index
        %9 = emitc.cast %6 : i32 to index
        %10 = arith.cmpi slt, %6, %arg3 : i32
        scf.if %10 {
          %11 = memref.load %arg1[%9] : memref<?xi64>
          %12 = memref.load %arg0[%8] : memref<?xf32>
          %13 = scf.for %arg6 = %c1 to %0 step %c1 iter_args(%arg7 = %12) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.cmpf ogt, %23, %arg7 : f32
            %25 = scf.if %24 -> (f32) {
              %26 = memref.load %arg0[%22] : memref<?xf32>
              scf.yield %26 : f32
            } else {
              scf.yield %arg7 : f32
            }
            scf.yield %25 : f32
          }
          %14 = scf.for %arg6 = %c0 to %0 step %c1 iter_args(%arg7 = %cst) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = emitc.sub %23, %13 : (f32, f32) -> f32
            %25 = emitc.call "expf"(%24) : (f32) -> f32
            %26 = emitc.add %arg7, %25 : (f32, f32) -> f32
            scf.yield %26 : f32
          }
          %15 = func.call @__nv_logf(%14) : (f32) -> f32
          %16 = emitc.cast %11 : i64 to index
          %17 = arith.addi %16, %8 : index
          %18 = memref.load %arg0[%17] : memref<?xf32>
          %19 = emitc.sub %18, %13 : (f32, f32) -> f32
          %20 = emitc.sub %19, %15 : (f32, f32) -> f32
          %21 = arith.negf %20 : f32
          memref.store %21, %arg2[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
    func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] ConvertPolygeistToNPUPass::runOnOperation(): After convert to NPU: end

[ict-debug] driver.cc: Before convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z25cross_entropy_loss_kernelPKfPKlPfii_0 {
    gpu.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) {
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = emitc.cast %arg4 : i32 to index
      %1 = "npu.block_id"() : () -> i64
      %2 = emitc.cast %1 : i64 to i32
      %3 = arith.muli %2, %c32_i32 : i32
      scf.for %arg5 = %c0 to %c32 step %c1 {
        %4 = builtin.unrealized_conversion_cast %arg5 : index to i64
        %5 = emitc.cast %4 : i64 to i32
        %6 = arith.addi %3, %5 : i32
        %7 = arith.muli %6, %arg4 : i32
        %8 = emitc.cast %7 : i32 to index
        %9 = emitc.cast %6 : i32 to index
        %10 = arith.cmpi slt, %6, %arg3 : i32
        scf.if %10 {
          %11 = memref.load %arg1[%9] : memref<?xi64>
          %12 = memref.load %arg0[%8] : memref<?xf32>
          %13 = scf.for %arg6 = %c1 to %0 step %c1 iter_args(%arg7 = %12) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.cmpf ogt, %23, %arg7 : f32
            %25 = scf.if %24 -> (f32) {
              %26 = memref.load %arg0[%22] : memref<?xf32>
              scf.yield %26 : f32
            } else {
              scf.yield %arg7 : f32
            }
            scf.yield %25 : f32
          }
          %14 = scf.for %arg6 = %c0 to %0 step %c1 iter_args(%arg7 = %cst) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = emitc.sub %23, %13 : (f32, f32) -> f32
            %25 = emitc.call "expf"(%24) : (f32) -> f32
            %26 = emitc.add %arg7, %25 : (f32, f32) -> f32
            scf.yield %26 : f32
          }
          %15 = func.call @__nv_logf(%14) : (f32) -> f32
          %16 = emitc.cast %11 : i64 to index
          %17 = arith.addi %16, %8 : index
          %18 = memref.load %arg0[%17] : memref<?xf32>
          %19 = emitc.sub %18, %13 : (f32, f32) -> f32
          %20 = emitc.sub %19, %15 : (f32, f32) -> f32
          %21 = arith.negf %20 : f32
          memref.store %21, %arg2[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
    func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] driver.cc: Before convert to EmitC dialect: end

[ict-debug] driver.cc: After convert to EmitC dialect:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  gpu.module @_Z25cross_entropy_loss_kernelPKfPKlPfii_0 {
    gpu.func @_Z25cross_entropy_loss_kernelPKfPKlPfii(%arg0: memref<?xf32>, %arg1: memref<?xi64>, %arg2: memref<?xf32>, %arg3: i32, %arg4: i32) {
      %c32_i32 = arith.constant 32 : i32
      %cst = arith.constant 0.000000e+00 : f32
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c32 = arith.constant 32 : index
      %0 = emitc.cast %arg4 : i32 to index
      %1 = "npu.block_id"() : () -> i64
      %2 = emitc.cast %1 : i64 to i32
      %3 = arith.muli %2, %c32_i32 : i32
      scf.for %arg5 = %c0 to %c32 step %c1 {
        %4 = builtin.unrealized_conversion_cast %arg5 : index to i64
        %5 = emitc.cast %4 : i64 to i32
        %6 = arith.addi %3, %5 : i32
        %7 = arith.muli %6, %arg4 : i32
        %8 = emitc.cast %7 : i32 to index
        %9 = emitc.cast %6 : i32 to index
        %10 = arith.cmpi slt, %6, %arg3 : i32
        emitc.if %10 {
          %11 = memref.load %arg1[%9] : memref<?xi64>
          %12 = memref.load %arg0[%8] : memref<?xf32>
          %13 = scf.for %arg6 = %c1 to %0 step %c1 iter_args(%arg7 = %12) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = arith.cmpf ogt, %23, %arg7 : f32
            %25 = "emitc.variable"() <{value = #emitc.opaque<"">}> : () -> f32
            emitc.if %24 {
              %26 = memref.load %arg0[%22] : memref<?xf32>
              emitc.assign %26 : f32 to %25 : f32
            } else {
              emitc.assign %arg7 : f32 to %25 : f32
            }
            scf.yield %25 : f32
          }
          %14 = scf.for %arg6 = %c0 to %0 step %c1 iter_args(%arg7 = %cst) -> (f32) {
            %22 = arith.addi %arg6, %8 : index
            %23 = memref.load %arg0[%22] : memref<?xf32>
            %24 = emitc.sub %23, %13 : (f32, f32) -> f32
            %25 = emitc.call "expf"(%24) : (f32) -> f32
            %26 = emitc.add %arg7, %25 : (f32, f32) -> f32
            scf.yield %26 : f32
          }
          %15 = func.call @__nv_logf(%14) : (f32) -> f32
          %16 = emitc.cast %11 : i64 to index
          %17 = arith.addi %16, %8 : index
          %18 = memref.load %arg0[%17] : memref<?xf32>
          %19 = emitc.sub %18, %13 : (f32, f32) -> f32
          %20 = emitc.sub %19, %15 : (f32, f32) -> f32
          %21 = arith.negf %20 : f32
          memref.store %21, %arg2[%9] : memref<?xf32>
        }
      }
      gpu.return
    }
    func.func private @__nv_logf(f32) -> f32 attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"}
  }
}
[ict-debug] driver.cc: After convert to EmitC dialect: end

loc("./cuda_ops/95_CrossEntropyLoss.cu":3:17): error: ICT_ERROR(): cannot emit MemRef element type: 'memref<?xi64, 1>'
[ict-debug] driver.cc: After emitc::translateToCpp:

