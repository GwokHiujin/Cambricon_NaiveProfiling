warning: CUDA version 12.1 is only partially supported
warning: CUDA version 12.1 is only partially supported
[ict-debug] driver.cc: After return 5, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  memref.global @const_trans : memref<2xi8> = uninitialized {polygeist.cuda_constant}
  memref.global @const_dims : memref<6xi32> = uninitialized {polygeist.cuda_constant}
  func.func private @_Z37__device_stub__unrolled_matmul_kernelPKfS0_Pf(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    call @_Z22unrolled_matmul_kernelPKfS0_Pf(%arg0, %arg1, %arg2) : (memref<?xf32>, memref<?xf32>, memref<?xf32>) -> ()
    return
  }
  func.func private @_Z22unrolled_matmul_kernelPKfS0_Pf(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %true = arith.constant true
    %c15_i32 = arith.constant 15 : i32
    %false = arith.constant false
    %cst = arith.constant 0.000000e+00 : f32
    %c16_i32 = arith.constant 16 : i32
    %c64_i32 = arith.constant 64 : i32
    %alloca = memref.alloca() : memref<4xf32>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %alloca_1 = memref.alloca() : memref<4x16x16xf32, 5>
    %0 = memref.get_global @const_dims : memref<6xi32>
    %1 = affine.load %0[0] : memref<6xi32>
    %2 = arith.index_cast %1 : i32 to index
    %3 = memref.get_global @const_dims : memref<6xi32>
    %4 = affine.load %3[1] : memref<6xi32>
    %5 = arith.index_cast %4 : i32 to index
    %6 = memref.get_global @const_dims : memref<6xi32>
    %7 = affine.load %6[2] : memref<6xi32>
    %8 = arith.index_cast %7 : i32 to index
    %9 = memref.get_global @const_dims : memref<6xi32>
    %10 = affine.load %9[3] : memref<6xi32>
    %11 = memref.get_global @const_dims : memref<6xi32>
    %12 = affine.load %11[4] : memref<6xi32>
    %13 = memref.get_global @const_dims : memref<6xi32>
    %14 = affine.load %13[5] : memref<6xi32>
    %15 = arith.index_cast %14 : i32 to index
    %16 = memref.get_global @const_trans : memref<2xi8>
    %17 = affine.load %16[0] : memref<2xi8>
    %18 = memref.get_global @const_trans : memref<2xi8>
    %19 = affine.load %18[1] : memref<2xi8>
    %20 = gpu.block_id  y
    %21 = arith.index_cast %20 : index to i32
    %22 = arith.muli %21, %c64_i32 : i32
    %23 = gpu.block_id  x
    %24 = arith.index_cast %23 : index to i32
    %25 = arith.muli %24, %c16_i32 : i32
    %26 = gpu.thread_id  y
    %27 = arith.index_cast %26 : index to i32
    %28 = gpu.thread_id  x
    %29 = arith.index_cast %28 : index to i32
    affine.store %cst, %alloca[0] : memref<4xf32>
    affine.store %cst, %alloca[1] : memref<4xf32>
    affine.store %cst, %alloca[2] : memref<4xf32>
    affine.store %cst, %alloca[3] : memref<4xf32>
    %30 = arith.addi %7, %c15_i32 : i32
    %31 = arith.divsi %30, %c16_i32 : i32
    %32 = arith.index_cast %31 : i32 to index
    %33 = arith.addi %25, %29 : i32
    %34 = arith.cmpi slt, %33, %4 : i32
    %35 = arith.addi %25, %29 : i32
    affine.for %arg3 = 0 to %32 {
      %38 = arith.index_cast %arg3 : index to i32
      %39 = arith.muli %38, %c16_i32 : i32
      %40 = arith.addi %39, %27 : i32
      %41 = affine.if affine_set<(d0)[s0, s1] : (d0 * -16 - s0 + s1 - 1 >= 0)>(%arg3)[%26, %8] -> i1 {
        affine.yield %34 : i1
      } else {
        affine.yield %false : i1
      }
      scf.if %41 {
        %45 = func.call @_Z11get_elementPKfiiib(%arg1, %40, %35, %12, %19) : (memref<?xf32>, i32, i32, i32, i8) -> f32
        affine.store %45, %alloca_0[symbol(%26), symbol(%28)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%26), symbol(%28)] : memref<16x16xf32, 5>
      }
      %42 = arith.addi %39, %29 : i32
      %43 = arith.cmpi slt, %42, %7 : i32
      %44 = arith.addi %39, %29 : i32
      affine.for %arg4 = 0 to 4 {
        %45 = arith.index_cast %arg4 : index to i32
        %46 = arith.muli %45, %c16_i32 : i32
        %47 = arith.addi %22, %46 : i32
        %48 = arith.addi %47, %27 : i32
        %49 = affine.if affine_set<(d0)[s0, s1, s2] : (d0 * -16 - s0 * 64 - s1 + s2 - 1 >= 0)>(%arg4)[%20, %26, %2] -> i1 {
          affine.yield %43 : i1
        } else {
          affine.yield %false : i1
        }
        scf.if %49 {
          %50 = func.call @_Z11get_elementPKfiiib(%arg0, %48, %44, %10, %17) : (memref<?xf32>, i32, i32, i32, i8) -> f32
          affine.store %50, %alloca_1[%arg4, symbol(%26), symbol(%28)] : memref<4x16x16xf32, 5>
        } else {
          affine.store %cst, %alloca_1[%arg4, symbol(%26), symbol(%28)] : memref<4x16x16xf32, 5>
        }
      }
      nvvm.barrier0
      affine.for %arg4 = 0 to 16 {
        scf.if %true {
          %45 = affine.load %alloca_0[%arg4, symbol(%28)] : memref<16x16xf32, 5>
          affine.for %arg5 = 0 to 4 {
            %46 = affine.load %alloca_1[%arg5, symbol(%26), %arg4] : memref<4x16x16xf32, 5>
            %47 = arith.mulf %46, %45 : f32
            %48 = affine.load %alloca[%arg5] : memref<4xf32>
            %49 = arith.addf %48, %47 : f32
            affine.store %49, %alloca[%arg5] : memref<4xf32>
          }
        }
      }
      nvvm.barrier0
    }
    %36 = arith.addi %25, %29 : i32
    %37 = arith.index_cast %36 : i32 to index
    affine.for %arg3 = 0 to 4 {
      affine.if affine_set<(d0)[s0, s1, s2, s3, s4] : (d0 * -16 - s0 * 64 - s1 + s2 - 1 >= 0, -s3 + s4 - 1 >= 0)>(%arg3)[%20, %26, %2, %37, %5] {
        %38 = affine.load %alloca[%arg3] : memref<4xf32>
        affine.store %38, %arg2[(%arg3 * 16 + symbol(%20) * 64 + symbol(%26)) * symbol(%15) + symbol(%37)] : memref<?xf32>
      }
    }
    return
  }
  func.func private @_Z11get_elementPKfiiib(%arg0: memref<?xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i8) -> f32 attributes {llvm.linkage = #llvm.linkage<linkonce_odr>, polygeist.device_only_func = "1"} {
    %c0_i8 = arith.constant 0 : i8
    %0 = arith.cmpi ne, %arg4, %c0_i8 : i8
    %1 = scf.if %0 -> (memref<?xf32>) {
      %3 = arith.muli %arg2, %arg3 : i32
      %4 = arith.addi %3, %arg1 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = "polygeist.subindex"(%arg0, %5) : (memref<?xf32>, index) -> memref<?xf32>
      scf.yield %6 : memref<?xf32>
    } else {
      %3 = arith.muli %arg1, %arg3 : i32
      %4 = arith.addi %3, %arg2 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = "polygeist.subindex"(%arg0, %5) : (memref<?xf32>, index) -> memref<?xf32>
      scf.yield %6 : memref<?xf32>
    }
    %2 = affine.load %1[0] : memref<?xf32>
    return %2 : f32
  }
}
[ict-debug] driver.cc: After return 5, module: end

[ict-debug] driver.cc: After return 6, module:

module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  memref.global @const_trans : memref<2xi8> = uninitialized {polygeist.cuda_constant}
  memref.global @const_dims : memref<6xi32> = uninitialized {polygeist.cuda_constant}
  func.func private @_Z22unrolled_matmul_kernelPKfS0_Pf(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c15_i32 = arith.constant 15 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c16_i32 = arith.constant 16 : i32
    %c64_i32 = arith.constant 64 : i32
    %alloca = memref.alloca() : memref<4xf32>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %alloca_1 = memref.alloca() : memref<4x16x16xf32, 5>
    %0 = memref.get_global @const_dims : memref<6xi32>
    %1 = affine.load %0[0] : memref<6xi32>
    %2 = arith.index_cast %1 : i32 to index
    %3 = affine.load %0[1] : memref<6xi32>
    %4 = arith.index_cast %3 : i32 to index
    %5 = affine.load %0[2] : memref<6xi32>
    %6 = arith.index_cast %5 : i32 to index
    %7 = affine.load %0[3] : memref<6xi32>
    %8 = affine.load %0[4] : memref<6xi32>
    %9 = affine.load %0[5] : memref<6xi32>
    %10 = arith.index_cast %9 : i32 to index
    %11 = memref.get_global @const_trans : memref<2xi8>
    %12 = affine.load %11[0] : memref<2xi8>
    %13 = affine.load %11[1] : memref<2xi8>
    %14 = gpu.block_id  y
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %15, %c64_i32 : i32
    %17 = gpu.block_id  x
    %18 = arith.index_cast %17 : index to i32
    %19 = arith.muli %18, %c16_i32 : i32
    %20 = gpu.thread_id  y
    %21 = arith.index_cast %20 : index to i32
    %22 = gpu.thread_id  x
    %23 = arith.index_cast %22 : index to i32
    affine.store %cst, %alloca[0] : memref<4xf32>
    affine.store %cst, %alloca[1] : memref<4xf32>
    affine.store %cst, %alloca[2] : memref<4xf32>
    affine.store %cst, %alloca[3] : memref<4xf32>
    %24 = arith.addi %5, %c15_i32 : i32
    %25 = arith.divsi %24, %c16_i32 : i32
    %26 = arith.index_cast %25 : i32 to index
    %27 = arith.addi %19, %23 : i32
    %28 = arith.index_cast %27 : i32 to index
    affine.for %arg3 = 0 to %26 {
      %29 = arith.index_cast %arg3 : index to i32
      %30 = arith.muli %29, %c16_i32 : i32
      %31 = arith.addi %30, %21 : i32
      affine.if affine_set<(d0)[s0, s1, s2, s3] : (d0 * -16 - s0 + s1 - 1 >= 0, -s2 + s3 - 1 >= 0)>(%arg3)[%20, %6, %28, %4] {
        %33 = func.call @_Z11get_elementPKfiiib(%arg1, %31, %27, %8, %13) : (memref<?xf32>, i32, i32, i32, i8) -> f32
        affine.store %33, %alloca_0[symbol(%20), symbol(%22)] : memref<16x16xf32, 5>
      } else {
        affine.store %cst, %alloca_0[symbol(%20), symbol(%22)] : memref<16x16xf32, 5>
      }
      %32 = arith.addi %30, %23 : i32
      affine.for %arg4 = 0 to 4 {
        %33 = arith.index_cast %arg4 : index to i32
        %34 = arith.muli %33, %c16_i32 : i32
        %35 = arith.addi %16, %34 : i32
        %36 = arith.addi %35, %21 : i32
        affine.if affine_set<(d0, d1)[s0, s1, s2, s3, s4] : (d1 * -16 - s0 * 64 - s1 + s2 - 1 >= 0, d0 * -16 - s3 + s4 - 1 >= 0)>(%arg3, %arg4)[%14, %20, %2, %22, %6] {
          %37 = func.call @_Z11get_elementPKfiiib(%arg0, %36, %32, %7, %12) : (memref<?xf32>, i32, i32, i32, i8) -> f32
          affine.store %37, %alloca_1[%arg4, symbol(%20), symbol(%22)] : memref<4x16x16xf32, 5>
        } else {
          affine.store %cst, %alloca_1[%arg4, symbol(%20), symbol(%22)] : memref<4x16x16xf32, 5>
        }
      }
      nvvm.barrier0
      affine.for %arg4 = 0 to 16 {
        %33 = affine.load %alloca_0[%arg4, symbol(%22)] : memref<16x16xf32, 5>
        affine.for %arg5 = 0 to 4 {
          %34 = affine.load %alloca_1[%arg5, symbol(%20), %arg4] : memref<4x16x16xf32, 5>
          %35 = arith.mulf %34, %33 : f32
          %36 = affine.load %alloca[%arg5] : memref<4xf32>
          %37 = arith.addf %36, %35 : f32
          affine.store %37, %alloca[%arg5] : memref<4xf32>
        }
      }
      nvvm.barrier0
    }
    affine.for %arg3 = 0 to 4 {
      affine.if affine_set<(d0)[s0, s1, s2, s3, s4] : (d0 * -16 - s0 * 64 - s1 + s2 - 1 >= 0, s3 - s4 - 1 >= 0)>(%arg3)[%14, %20, %2, %4, %28] {
        %29 = affine.load %alloca[%arg3] : memref<4xf32>
        affine.store %29, %arg2[(%arg3 * 16 + symbol(%14) * 64 + symbol(%20)) * symbol(%10) + symbol(%28)] : memref<?xf32>
      }
    }
    return
  }
  func.func private @_Z11get_elementPKfiiib(%arg0: memref<?xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i8) -> f32 attributes {llvm.linkage = #llvm.linkage<linkonce_odr>, polygeist.device_only_func = "1"} {
    %c0_i8 = arith.constant 0 : i8
    %0 = arith.cmpi ne, %arg4, %c0_i8 : i8
    %1 = scf.if %0 -> (memref<?xf32>) {
      %3 = arith.muli %arg2, %arg3 : i32
      %4 = arith.addi %3, %arg1 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = "polygeist.subindex"(%arg0, %5) : (memref<?xf32>, index) -> memref<?xf32>
      scf.yield %6 : memref<?xf32>
    } else {
      %3 = arith.muli %arg1, %arg3 : i32
      %4 = arith.addi %3, %arg2 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = "polygeist.subindex"(%arg0, %5) : (memref<?xf32>, index) -> memref<?xf32>
      scf.yield %6 : memref<?xf32>
    }
    %2 = affine.load %1[0] : memref<?xf32>
    return %2 : f32
  }
}
[ict-debug] driver.cc: After return 6, module: end

WrapAndReplaceBarrierPass::runOnOperation(): before execute: 
module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<f128, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<270>, dense<32> : vector<4xi32>>, #dlti.dl_entry<f16, dense<16> : vector<2xi32>>, #dlti.dl_entry<f64, dense<64> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr<272>, dense<64> : vector<4xi32>>, #dlti.dl_entry<!llvm.ptr<271>, dense<32> : vector<4xi32>>, #dlti.dl_entry<i64, dense<64> : vector<2xi32>>, #dlti.dl_entry<f80, dense<128> : vector<2xi32>>, #dlti.dl_entry<!llvm.ptr, dense<64> : vector<4xi32>>, #dlti.dl_entry<i8, dense<8> : vector<2xi32>>, #dlti.dl_entry<i1, dense<8> : vector<2xi32>>, #dlti.dl_entry<i32, dense<32> : vector<2xi32>>, #dlti.dl_entry<i16, dense<16> : vector<2xi32>>, #dlti.dl_entry<"dlti.endianness", "little">, #dlti.dl_entry<"dlti.stack_alignment", 128 : i32>>, llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-linux-gnu", polygeist.gpu_module.llvm.data_layout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64", polygeist.gpu_module.llvm.target_triple = "nvptx64-nvidia-cuda", "polygeist.target-cpu" = "x86-64", "polygeist.target-features" = "+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87", "polygeist.tune-cpu" = "generic"} {
  memref.global @const_trans : memref<2xi8> = uninitialized {polygeist.cuda_constant}
  memref.global @const_dims : memref<6xi32> = uninitialized {polygeist.cuda_constant}
  func.func private @_Z22unrolled_matmul_kernelPKfS0_Pf(%arg0: memref<?xf32>, %arg1: memref<?xf32>, %arg2: memref<?xf32>) attributes {llvm.linkage = #llvm.linkage<external>, polygeist.device_only_func = "1"} {
    %c64 = arith.constant 64 : index
    %c16 = arith.constant 16 : index
    %c-64 = arith.constant -64 : index
    %c-1 = arith.constant -1 : index
    %c-16 = arith.constant -16 : index
    %c5 = arith.constant 5 : index
    %c4 = arith.constant 4 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c15_i32 = arith.constant 15 : i32
    %cst = arith.constant 0.000000e+00 : f32
    %c16_i32 = arith.constant 16 : i32
    %c64_i32 = arith.constant 64 : i32
    %alloca = memref.alloca() : memref<4xf32>
    %alloca_0 = memref.alloca() : memref<16x16xf32, 5>
    %alloca_1 = memref.alloca() : memref<4x16x16xf32, 5>
    %0 = memref.get_global @const_dims : memref<6xi32>
    %1 = memref.load %0[%c0] : memref<6xi32>
    %2 = arith.index_cast %1 : i32 to index
    %3 = memref.load %0[%c1] : memref<6xi32>
    %4 = arith.index_cast %3 : i32 to index
    %5 = memref.load %0[%c2] : memref<6xi32>
    %6 = arith.index_cast %5 : i32 to index
    %7 = memref.load %0[%c3] : memref<6xi32>
    %8 = memref.load %0[%c4] : memref<6xi32>
    %9 = memref.load %0[%c5] : memref<6xi32>
    %10 = arith.index_cast %9 : i32 to index
    %11 = memref.get_global @const_trans : memref<2xi8>
    %12 = memref.load %11[%c0] : memref<2xi8>
    %13 = memref.load %11[%c1] : memref<2xi8>
    %14 = gpu.block_id  y
    %15 = arith.index_cast %14 : index to i32
    %16 = arith.muli %15, %c64_i32 : i32
    %17 = gpu.block_id  x
    %18 = arith.index_cast %17 : index to i32
    %19 = arith.muli %18, %c16_i32 : i32
    %20 = gpu.thread_id  y
    %21 = arith.index_cast %20 : index to i32
    %22 = gpu.thread_id  x
    %23 = arith.index_cast %22 : index to i32
    memref.store %cst, %alloca[%c0] : memref<4xf32>
    memref.store %cst, %alloca[%c1] : memref<4xf32>
    memref.store %cst, %alloca[%c2] : memref<4xf32>
    memref.store %cst, %alloca[%c3] : memref<4xf32>
    %24 = arith.addi %5, %c15_i32 : i32
    %25 = arith.divsi %24, %c16_i32 : i32
    %26 = arith.index_cast %25 : i32 to index
    %27 = arith.addi %19, %23 : i32
    %28 = arith.index_cast %27 : i32 to index
    scf.for %arg3 = %c0 to %26 step %c1 {
      %29 = arith.index_cast %arg3 : index to i32
      %30 = arith.muli %29, %c16_i32 : i32
      %31 = arith.addi %30, %21 : i32
      %32 = arith.muli %arg3, %c-16 : index
      %33 = arith.subi %32, %20 : index
      %34 = arith.addi %33, %6 : index
      %35 = arith.addi %34, %c-1 : index
      %36 = arith.cmpi sge, %35, %c0 : index
      %37 = arith.subi %4, %28 : index
      %38 = arith.addi %37, %c-1 : index
      %39 = arith.cmpi sge, %38, %c0 : index
      %40 = arith.andi %36, %39 : i1
      scf.if %40 {
        %42 = func.call @_Z11get_elementPKfiiib(%arg1, %31, %27, %8, %13) : (memref<?xf32>, i32, i32, i32, i8) -> f32
        memref.store %42, %alloca_0[%20, %22] : memref<16x16xf32, 5>
      } else {
        memref.store %cst, %alloca_0[%20, %22] : memref<16x16xf32, 5>
      }
      %41 = arith.addi %30, %23 : i32
      scf.for %arg4 = %c0 to %c4 step %c1 {
        %42 = arith.index_cast %arg4 : index to i32
        %43 = arith.muli %42, %c16_i32 : i32
        %44 = arith.addi %16, %43 : i32
        %45 = arith.addi %44, %21 : i32
        %46 = arith.muli %arg4, %c-16 : index
        %47 = arith.muli %14, %c-64 : index
        %48 = arith.addi %46, %47 : index
        %49 = arith.subi %48, %20 : index
        %50 = arith.addi %49, %2 : index
        %51 = arith.addi %50, %c-1 : index
        %52 = arith.cmpi sge, %51, %c0 : index
        %53 = arith.subi %32, %22 : index
        %54 = arith.addi %53, %6 : index
        %55 = arith.addi %54, %c-1 : index
        %56 = arith.cmpi sge, %55, %c0 : index
        %57 = arith.andi %52, %56 : i1
        scf.if %57 {
          %58 = func.call @_Z11get_elementPKfiiib(%arg0, %45, %41, %7, %12) : (memref<?xf32>, i32, i32, i32, i8) -> f32
          memref.store %58, %alloca_1[%arg4, %20, %22] : memref<4x16x16xf32, 5>
        } else {
          memref.store %cst, %alloca_1[%arg4, %20, %22] : memref<4x16x16xf32, 5>
        }
      }
      nvvm.barrier0
      scf.for %arg4 = %c0 to %c16 step %c1 {
        %42 = memref.load %alloca_0[%arg4, %22] : memref<16x16xf32, 5>
        scf.for %arg5 = %c0 to %c4 step %c1 {
          %43 = memref.load %alloca_1[%arg5, %20, %arg4] : memref<4x16x16xf32, 5>
          %44 = arith.mulf %43, %42 : f32
          %45 = memref.load %alloca[%arg5] : memref<4xf32>
          %46 = arith.addf %45, %44 : f32
          memref.store %46, %alloca[%arg5] : memref<4xf32>
        }
      }
      nvvm.barrier0
    }
    scf.for %arg3 = %c0 to %c4 step %c1 {
      %29 = arith.muli %arg3, %c-16 : index
      %30 = arith.muli %14, %c-64 : index
      %31 = arith.addi %29, %30 : index
      %32 = arith.subi %31, %20 : index
      %33 = arith.addi %32, %2 : index
      %34 = arith.addi %33, %c-1 : index
      %35 = arith.cmpi sge, %34, %c0 : index
      %36 = arith.subi %4, %28 : index
      %37 = arith.addi %36, %c-1 : index
      %38 = arith.cmpi sge, %37, %c0 : index
      %39 = arith.andi %35, %38 : i1
      scf.if %39 {
        %40 = memref.load %alloca[%arg3] : memref<4xf32>
        %41 = arith.muli %arg3, %c16 : index
        %42 = arith.muli %14, %c64 : index
        %43 = arith.addi %41, %42 : index
        %44 = arith.addi %43, %20 : index
        %45 = arith.muli %44, %10 : index
        %46 = arith.addi %45, %28 : index
        memref.store %40, %arg2[%46] : memref<?xf32>
      }
    }
    return
  }
  func.func private @_Z11get_elementPKfiiib(%arg0: memref<?xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i8) -> f32 attributes {llvm.linkage = #llvm.linkage<linkonce_odr>, polygeist.device_only_func = "1"} {
    %c0 = arith.constant 0 : index
    %c0_i8 = arith.constant 0 : i8
    %0 = arith.cmpi ne, %arg4, %c0_i8 : i8
    %1 = scf.if %0 -> (memref<?xf32>) {
      %3 = arith.muli %arg2, %arg3 : i32
      %4 = arith.addi %3, %arg1 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = "polygeist.subindex"(%arg0, %5) : (memref<?xf32>, index) -> memref<?xf32>
      scf.yield %6 : memref<?xf32>
    } else {
      %3 = arith.muli %arg1, %arg3 : i32
      %4 = arith.addi %3, %arg2 : i32
      %5 = arith.index_cast %4 : i32 to index
      %6 = "polygeist.subindex"(%arg0, %5) : (memref<?xf32>, index) -> memref<?xf32>
      scf.yield %6 : memref<?xf32>
    }
    %2 = memref.load %1[%c0] : memref<?xf32>
    return %2 : f32
  }
}
WrapAndReplaceBarrierPass::runOnOperation(): before execute: end
[ict-error] WrapAndReplaceBarrierPass::runOnOperation(): gpuThreadIdOp.getDimension() != gpu::Dimension::x

