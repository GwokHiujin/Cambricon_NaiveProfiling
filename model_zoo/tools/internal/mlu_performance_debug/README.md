# 网络训练性能优化checklist


## 文档修改记录

| 日期 | 版本 | 修改内容 |
| ---- | ---- | -------- |
| 2021.04.08     |   v0.1   |     出版     |

## 1. CheckList

### 2.1. 网络模型

- 检查网络模型中是否算子强制放置在了CPU设备上。

- 检查num_works的值，一般设置为4或者8，可以使用fake_data比较和真实数据的差异。

- 检查超参是否和GPU对齐。

- 模型中是否使用Dali这种GPU特有的加速库。

- 模型中是否有APEX特有的GPU定制化大算子, MLU需要考虑对齐。

### 2.2. 框架代码

- 检查网络中的同步点是否可以消除，是否与GPU对齐。

- 减少框架Host侧开销，保证host侧所有操作和GPU对齐。

- 算子中是否存在同步点。

- 算子适配是否基于最优的cnnl算子方案。

- 算子适配减少transpose，broadcast，cast等耗时的IO操作。

- 减少算子kernel数量，避免小算子集中到一起，例如优化器部分。

- 框架需要优化逻辑，例如量化复用，量化融合。

- 框架需要保证计算图和GPU对齐，不引入额外的算子。

### 2.3. CNNL算子

- 同种规模下cnnl和gpu的性能差距。

- 需要支持真实的stride操作，减少view类算子开销。

- cnnl算子内部避免有transpose，broadcast，cast等耗时的IO操作。

- cnnl算子内部避免同步操作。

- cnnl算子设计阶段考虑pytorch的NCHW摆数，框架适配的时候不需要引入额外的transpose。

- 需要优化算子int31模式下的性能。

- cnnl算子字节对齐，需要考虑最优的补齐方案。

- 增强算子性能的泛化能力。

